{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fd4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, os\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809f6ce3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>exercise</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>16</td>\n",
       "      <td>adding_and_subtracting_negative_numbers</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>52</td>\n",
       "      <td>alternate_exterior_angles</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>52</td>\n",
       "      <td>alternate_interior_angles</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>52</td>\n",
       "      <td>metric_weight_unit_conversion</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>64</td>\n",
       "      <td>reading_fractions_in_chinese</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288785</th>\n",
       "      <td>247492</td>\n",
       "      <td>multiplication_0.5</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288786</th>\n",
       "      <td>247492</td>\n",
       "      <td>multiplication_1</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288888</th>\n",
       "      <td>247507</td>\n",
       "      <td>subtraction_1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289046</th>\n",
       "      <td>247529</td>\n",
       "      <td>addition_1</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289368</th>\n",
       "      <td>247569</td>\n",
       "      <td>divisibility_0.5</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id                                 exercise  count\n",
       "98            16  adding_and_subtracting_negative_numbers    118\n",
       "387           52                alternate_exterior_angles    119\n",
       "388           52                alternate_interior_angles    101\n",
       "492           52            metric_weight_unit_conversion    136\n",
       "654           64             reading_fractions_in_chinese    148\n",
       "...          ...                                      ...    ...\n",
       "2288785   247492                       multiplication_0.5    741\n",
       "2288786   247492                         multiplication_1    266\n",
       "2288888   247507                            subtraction_1    113\n",
       "2289046   247529                               addition_1    119\n",
       "2289368   247569                         divisibility_0.5    201\n",
       "\n",
       "[15060 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################## load data from junyi log\n",
    "bath_path = '/mnt/qb/work/mlcolab/hzhou52/kt/junyi/'\n",
    "\n",
    "# exercise 837, topic 41, area 9\n",
    "# exercise = pd.read_csv(bath_path+'junyi_Exercise_table.csv', encoding = \"utf-8\",low_memory=False) \n",
    "# relation = pd.read_csv(bath_path+'relationship_annotation_training.csv', encoding = \"utf-8\",low_memory=False)\n",
    "log = pd.read_csv(bath_path+'junyi_ProblemLog_original.csv', encoding = \"utf-8\",low_memory=False)\n",
    "\n",
    "users = log.groupby(['user_id', 'exercise']).size().reset_index(name='count')\n",
    "users[users['count']>100]\n",
    "# users = users.sort_values('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4684841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### find specific data\n",
    "user201 = log.loc[(log.user_id == 247569) & (log.exercise == 'divisibility_0.5')]\n",
    "user118 = log.loc[(log.user_id == 16) & (log.exercise == 'adding_and_subtracting_negative_numbers')]\n",
    "user384 = log.loc[(log.user_id == 945) & (log.exercise == 'number_line_3')]\n",
    "\n",
    "user118 = user118.sort_values('time_done')\n",
    "user201 = user201.sort_values('time_done')\n",
    "user384 = user384.sort_values('time_done')\n",
    "\n",
    "# first = log.loc[(log.user_id == 88703) & (log.exercise == 'telling_time_comparing')]\n",
    "# second = log.loc[(log.user_id == 88703) & (log.exercise == 'time_units_transformation_1')]\n",
    "# third = log.loc[(log.user_id == 52504) & (log.exercise == 'radical_equations')]\n",
    "# first = first.sort_values('time_done')\n",
    "\n",
    "user118.to_csv('user118.csv', sep='\\t')\n",
    "user201.to_csv('user201.csv', sep='\\t')\n",
    "user384.to_csv('user384.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## load data from pre-defined user-specific log\n",
    "user118 = pd.read_csv('user118.csv', sep='\\t')\n",
    "\n",
    "num_seq = 1\n",
    "num_node = 1\n",
    "\n",
    "t_data = torch.tensor(np.array(user118['time_done'].values), device=device).reshape(1, -1)\n",
    "x_data = torch.tensor(np.array(user118['correct'].values*1), device=device).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bd77171",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m################### rescale time data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m log_t_data \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# so that the log(diff(t_data)) = diff(log_t_data)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mdiff(t_data))\n\u001b[1;32m      4\u001b[0m log_t_data\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mzeros_like(dt[:,\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, dt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n",
      "\u001b[0;31mNameError\u001b[0m: name 't_data' is not defined"
     ]
    }
   ],
   "source": [
    "################### rescale time data\n",
    "log_t_data = [] # so that the log(diff(t_data)) = diff(log_t_data)\n",
    "dt = torch.log(torch.diff(t_data))\n",
    "log_t_data.append(torch.zeros_like(dt[:,0]))\n",
    "for i in range(0, dt.shape[-1]):\n",
    "    log_t_data.append(log_t_data[-1] + dt[:, i])\n",
    "log_t_data = torch.stack(log_t_data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3921f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c605b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6f61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de9b4099",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n"
     ]
    }
   ],
   "source": [
    "######################################## single_user_single_exercise\n",
    "useful_log = log[['user_id', 'exercise', 'time_done', 'correct']]\n",
    "max_num = 200\n",
    "interaction = pd.DataFrame(['user_id', 'skill', 'time_seq', 'correct_seq'])\n",
    "\n",
    "users[users['count']>max_num]\n",
    "users_with_threshold = users[users['count']>max_num]\n",
    "\n",
    "single_user_single_exercise = dict({\n",
    "    'user_id': [],\n",
    "    'skill': [],\n",
    "    'time_seq': [],\n",
    "    'correct_seq': [],\n",
    "})\n",
    "\n",
    "sk_dfs = []\n",
    "for i in range(len(users_with_threshold)):\n",
    "    if i % 50==0:\n",
    "        print(i)\n",
    "    id = users_with_threshold.user_id.iloc[i]\n",
    "    ex = users_with_threshold.exercise.iloc[i]\n",
    "\n",
    "    single_user_exercise = useful_log.loc[(useful_log.user_id == id) & (useful_log.exercise == ex)]\n",
    "    single_user_exercise = single_user_exercise.sort_values('time_done')[:max_num]\n",
    "\n",
    "    sk_dfs.append(single_user_exercise)\n",
    "    \n",
    "# single_user_single_exercise = pd.DataFrame.from_dict(single_user_single_exercise)\n",
    "# single_user_single_exercise.to_csv('single_user_single_exercise_junyi_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## exercise-id re-match\n",
    "# same as preprocessing\n",
    "exercise = pd.read_csv(bath_path+'junyi_Exercise_table.csv', encoding = \"utf-8\",low_memory=False) \n",
    "num_ex = len(exercise)\n",
    "\n",
    "ex_new_id = pd.DataFrame(columns=['exercise_name', 'exercise_id', 'prerequisite_name', 'prerequisite_id'])\n",
    "ex_new_id['exercise_name'] = exercise.name\n",
    "ex_new_id['exercise_id'] = np.arange(len(exercise))\n",
    "ex_new_id['prerequisite_name'] = exercise.prerequisites\n",
    "\n",
    "for i in range(len(ex_new_id.prerequisite_name)):\n",
    "    pre = ex_new_id['prerequisite_name'][i]\n",
    "    ind = exercise.loc[exercise.name == pre].index\n",
    "    if len(ind) == 0:\n",
    "        ex_new_id.prerequisite_id[i] = np.nan\n",
    "    else:\n",
    "        ex_new_id.prerequisite_id[i] = ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee31897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sk_dfs, open('sk_dfs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c145046",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sk_dfs\n",
    "test = pd.concat(test, axis=0)\n",
    "test.columns = ['original_user_id', 'skill_name', 'timestamp', 'correct']\n",
    "\n",
    "new_id = [[i] * max_num for i in range(len(sk_dfs))]\n",
    "new_user_id = [item for sublist in new_id for item in sublist]\n",
    "test['user_id'] = new_user_id\n",
    "\n",
    "skill_dict = dict(zip(ex_new_id.exercise_name, ex_new_id.exercise_id))\n",
    "test['skill_id'] = test['skill_name'].apply(lambda x: skill_dict[x])\n",
    "\n",
    "test['problem_id'] = test.skill_id\n",
    "\n",
    "test = test.astype({\n",
    "    'timestamp': np.float64,\n",
    "    # 'dwell_time': np.float64,\n",
    "    'correct': np.float64,\n",
    "    'problem_id': np.int64,\n",
    "    'skill_id': np.int64,\n",
    "    'user_id': np.int64,\n",
    "    })\n",
    "\n",
    "# Save\n",
    "bath_path = '/mnt/qb/work/mlcolab/hzhou52/kt/junyi/single_user_single_skill/'\n",
    "test.to_csv(bath_path+'interactions_{}.csv'.format(max_num), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbb1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e7818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "430b8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## add statistics\n",
    "num_seq = 1\n",
    "num_node = 1\n",
    "def add_statistics(x_data, time_step):\n",
    "    num_total = np.arange(time_step) # how many times in total has the learner tried\n",
    "    success = 0\n",
    "    num_success = []\n",
    "    for i in range(time_step):\n",
    "        if x_data[i] == 1:\n",
    "            success += 1\n",
    "        num_success.append(success)\n",
    "    num_failure = num_total-num_success\n",
    "\n",
    "    stats = np.stack([num_total, num_success, num_failure], -1).reshape(num_seq, num_node, -1, 3)\n",
    "    # stats = torch.tensor(stats, device=device)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa766ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, single_user_single_exercise, device):\n",
    "        self.pd_data = single_user_single_exercise\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pd_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.pd_data.user_id.iloc[idx]\n",
    "        time_seq = [int(s) for s in self.pd_data.time_seq.iloc[idx][1:-1].split(',')] \n",
    "        time_seq = np.array(time_seq)\n",
    "        correct_seq = [int(s) for s in self.pd_data.correct_seq.iloc[idx][1:-1].split(',')] \n",
    "        correct_seq = np.array(correct_seq)\n",
    "        stats = add_statistics(correct_seq, len(correct_seq))[0]\n",
    "        return user_id, time_seq, correct_seq, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b3484ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(single_user_single_exercise, device)\n",
    "batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler,\n",
    "                                          collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler,\n",
    "                                            collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7cca0c46",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7165, 0.7167, 0.7130]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7179, 0.7141, 0.7176]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7050, 0.6996, 0.7064]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6183, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0296,  1.1021, -0.8681], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5026,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5009, 0.5007,  ..., 0.7186, 0.7183, 0.7199]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6383, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0287,  1.1029, -0.8681], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5001, 0.5000,  ..., 0.7213, 0.7010, 0.7199]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5011, 0.5093, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6149, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0275,  1.1041, -0.8681], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6113, 0.6237, 0.6415]],\n",
      "\n",
      "        [[1.0000, 0.5007, 0.5002,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5006, 0.5000,  ..., 0.7045, 0.7081, 0.7095]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5004, 0.5019,  ..., 0.7195, 0.7200, 0.7188]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5793, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0255,  1.1061, -0.8680], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5019, 0.5024,  ..., 0.6343, 0.7218, 0.7214]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7083, 0.6972, 0.7053]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5001, 0.5000,  ..., 0.7071, 0.7041, 0.5855]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.7074]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6100, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0244,  1.1072, -0.8680], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5001,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5001,  ..., 0.7118, 0.6843, 0.6954]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7234, 0.7193, 0.7070]],\n",
      "\n",
      "        [[1.0000, 0.5012, 0.5016,  ..., 0.7230, 0.7247, 0.7178]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6293, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0232,  1.1083, -0.8680], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.5187, 0.5296, 0.5126]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6027, 0.7122, 0.7048]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5011, 0.5013,  ..., 0.7153, 0.7185, 0.7165]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5951, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0218,  1.1097, -0.8680], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5459, 0.5892, 0.5505]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7185, 0.7195, 0.6998]],\n",
      "\n",
      "        [[1.0000, 0.5002, 0.5004,  ..., 0.6992, 0.7038, 0.7008]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6327, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0209,  1.1106, -0.8680], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5013,  ..., 0.5603, 0.7175, 0.7196]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7074, 0.7073, 0.6968]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0199,  1.1116, -0.8680], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5014, 0.5002,  ..., 0.5285, 0.5491, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7119, 0.7126, 0.7060]],\n",
      "\n",
      "        [[1.0000, 0.5002, 0.5010,  ..., 0.7138, 0.6879, 0.6590]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7163, 0.7166, 0.5499]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6035, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0184,  1.1131, -0.8679], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.6913, 0.6968, 0.7001]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6911, 0.7229, 0.6944]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5006, 0.5001,  ..., 0.7210, 0.7187, 0.7217]],\n",
      "\n",
      "        [[1.0000, 0.5002, 0.5038,  ..., 0.7125, 0.7094, 0.6335]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0169,  1.1146, -0.8679], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7165, 0.7052, 0.7010]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5012,  ..., 0.6670, 0.6642, 0.6640]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7038, 0.6990, 0.6553]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5001,  ..., 0.7155, 0.7184, 0.7151]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5902, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0157,  1.1157, -0.8679], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.6687, 0.7164, 0.7189]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7118, 0.7063, 0.6930]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5930, 0.5701, 0.6166]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6311, 0.7232, 0.7221]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7039, 0.7101, 0.6994]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5015, 0.5258, 0.5377]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5551, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0142,  1.1172, -0.8678], device='cuda:0', grad_fn=<CloneBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.7067, 0.6732, 0.5749]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5178, 0.5136]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7184, 0.7007, 0.6725]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5011, 0.5016,  ..., 0.7180, 0.7171, 0.7167]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7073, 0.7077, 0.7053]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6268, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0131,  1.1183, -0.8678], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7065, 0.7118, 0.7154]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5002, 0.5038,  ..., 0.7198, 0.7195, 0.7190]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7157, 0.7194, 0.7162]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5680, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0124,  1.1189, -0.8678], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7168, 0.7183, 0.7190]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7217, 0.7208, 0.7208]],\n",
      "\n",
      "        [[1.0000, 0.5001, 0.5001,  ..., 0.7174, 0.7158, 0.7144]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6434, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0119,  1.1194, -0.8678], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5003, 0.5002,  ..., 0.7176, 0.7130, 0.7204]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7185, 0.7093, 0.6654]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5937, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0114,  1.1200, -0.8678], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7118, 0.7074, 0.7117]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6927, 0.6884, 0.6885]],\n",
      "\n",
      "        [[1.0000, 0.5005, 0.5007,  ..., 0.7116, 0.6816, 0.7147]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5001,  ..., 0.7197, 0.7165, 0.7190]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5002, 0.5008, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0098,  1.1215, -0.8677], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7133, 0.7122, 0.7156]],\n",
      "\n",
      "        [[1.0000, 0.5069, 0.5004,  ..., 0.7184, 0.7192, 0.7188]],\n",
      "\n",
      "        [[1.0000, 0.5001, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6581, 0.6535, 0.6744]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5012, 0.5023, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5970, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0082,  1.1231, -0.8677], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5001, 0.5015,  ..., 0.7083, 0.6114, 0.7004]],\n",
      "\n",
      "        [[1.0000, 0.5001, 0.5009,  ..., 0.7148, 0.7178, 0.7098]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5002,  ..., 0.7102, 0.7135, 0.6682]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5009,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7206, 0.7200, 0.7214]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0079,  1.1234, -0.8677], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7205, 0.7213, 0.7218]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6848, 0.7104, 0.7200]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7071, 0.7146, 0.6959]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5813, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0073,  1.1239, -0.8677], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6802, 0.6918, 0.6912]],\n",
      "\n",
      "        [[1.0000, 0.5010, 0.5036,  ..., 0.7211, 0.6256, 0.6983]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5651, 0.5957, 0.5846]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0064,  1.1248, -0.8677], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5001,  ..., 0.7098, 0.7139, 0.7130]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6501, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0061,  1.1251, -0.8677], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7214, 0.6791, 0.7193]],\n",
      "\n",
      "        [[1.0000, 0.5008, 0.5000,  ..., 0.5000, 0.5000, 0.5004]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7176, 0.6896, 0.7145]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5004, 0.5002,  ..., 0.7176, 0.7194, 0.7197]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5761, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0053,  1.1259, -0.8676], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7186, 0.7186, 0.7193]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7171, 0.6745, 0.7171]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7022, 0.6942, 0.7148]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7178, 0.7118, 0.7152]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7142, 0.7154, 0.7132]],\n",
      "\n",
      "        [[1.0000, 0.5010, 0.5000,  ..., 0.7131, 0.7189, 0.7186]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5372, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0041,  1.1270, -0.8676], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5013, 0.5009,  ..., 0.7170, 0.7205, 0.7074]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5455, 0.5146, 0.5354]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5455, 0.5425, 0.5488]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5291, 0.6978, 0.7122]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5859, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0032,  1.1279, -0.8676], device='cuda:0', grad_fn=<CloneBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5004,  ..., 0.6801, 0.7212, 0.7201]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5576, 0.5351, 0.6269]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5023, 0.5000,  ..., 0.6784, 0.7105, 0.7078]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5005,  ..., 0.7192, 0.7170, 0.7177]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5920, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0020,  1.1291, -0.8675], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6946, 0.6863, 0.6961]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7159, 0.7189, 0.7071]],\n",
      "\n",
      "        [[1.0000, 0.5004, 0.5020,  ..., 0.7191, 0.7198, 0.7181]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5294, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0011,  1.1299, -0.8675], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7006, 0.6904, 0.6989]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7246, 0.7168, 0.7210]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5003,  ..., 0.7128, 0.7093, 0.7039]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5010,  ..., 0.7092, 0.7212, 0.7191]],\n",
      "\n",
      "        [[1.0000, 0.5001, 0.5001,  ..., 0.7078, 0.7075, 0.7141]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5155, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-1.0006,  1.1304, -0.8675], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.6853, 0.6552, 0.6828]],\n",
      "\n",
      "        [[1.0000, 0.5008, 0.5008,  ..., 0.7123, 0.7180, 0.6951]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6378, 0.7213, 0.7125]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5003, 0.5001,  ..., 0.6857, 0.7250, 0.7180]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5655, 0.6960, 0.6437]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5155, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9999,  1.1311, -0.8675], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7122, 0.7148, 0.7053]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5006,  ..., 0.7207, 0.7213, 0.7160]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7106, 0.7060, 0.6945]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5747, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9992,  1.1319, -0.8675], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5002, 0.5001,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5012,  ..., 0.6822, 0.7049, 0.7190]],\n",
      "\n",
      "        [[1.0000, 0.5015, 0.5055,  ..., 0.7126, 0.7169, 0.7230]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6631, 0.7161, 0.7153]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5437, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9988,  1.1322, -0.8675], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5001, 0.5001,  ..., 0.7102, 0.7141, 0.7125]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7037, 0.7030, 0.6970]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5004, 0.5001,  ..., 0.7044, 0.7068, 0.7078]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5001,  ..., 0.7188, 0.7164, 0.7127]],\n",
      "\n",
      "        [[1.0000, 0.5003, 0.5000,  ..., 0.7183, 0.7202, 0.6906]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5407, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9980,  1.1330, -0.8675], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5005, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6972, 0.6872, 0.6917]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5003,  ..., 0.7118, 0.7117, 0.6994]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5247, 0.5526, 0.6217]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7136, 0.6938, 0.7110]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5775, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9973,  1.1337, -0.8674], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5004,  ..., 0.6363, 0.6440, 0.6937]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7080, 0.6876, 0.7176]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5006, 0.5036,  ..., 0.7222, 0.7200, 0.7219]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5008,  ..., 0.7186, 0.7131, 0.7185]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5287, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9967,  1.1343, -0.8674], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.6728, 0.6578, 0.6253]],\n",
      "\n",
      "        [[1.0000, 0.5001, 0.5000,  ..., 0.6961, 0.7162, 0.7160]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5003,  ..., 0.7169, 0.7192, 0.7167]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5081,  ..., 0.7131, 0.7030, 0.7135]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7163, 0.7172, 0.7166]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5648, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9961,  1.1348, -0.8674], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5002, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5011,  ..., 0.7103, 0.7196, 0.7139]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5651, 0.5832, 0.6067]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5979, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9954,  1.1355, -0.8674], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7196, 0.7167, 0.7165]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5019,  ..., 0.7128, 0.7149, 0.7040]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.6491, 0.6567, 0.6540]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5985, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9952,  1.1357, -0.8674], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5040,  ..., 0.7169, 0.7077, 0.7137]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7103, 0.7130, 0.7054]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.6089, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9948,  1.1361, -0.8674], device='cuda:0', grad_fn=<CloneBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[1.0000, 0.5004, 0.5008,  ..., 0.7053, 0.7131, 0.7148]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5145, 0.5001, 0.5607]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9938,  1.1371, -0.8673], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.7062, 0.7070, 0.6945]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7170, 0.6568, 0.7186]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5010,  ..., 0.7177, 0.7177, 0.7163]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7073, 0.7054, 0.7036]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6779, 0.7003, 0.6542]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5440, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9933,  1.1375, -0.8673], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5022, 0.5005,  ..., 0.7128, 0.7145, 0.6869]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5220, 0.6071]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5487, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9922,  1.1386, -0.8673], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7038, 0.7119, 0.7127]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5010, 0.5080,  ..., 0.6823, 0.7188, 0.7165]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5028, 0.5053,  ..., 0.7156, 0.7179, 0.7200]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6857, 0.5000, 0.7126]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5390, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9918,  1.1391, -0.8673], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7012, 0.6912, 0.7154]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5003, 0.5010,  ..., 0.7233, 0.7249, 0.7157]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5780, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9913,  1.1395, -0.8673], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6984, 0.6926, 0.6793]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5917, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9907,  1.1400, -0.8672], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.6076, 0.6833, 0.7103]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6434, 0.7060, 0.6700]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7170, 0.7149, 0.7197]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7153, 0.7073, 0.6231]],\n",
      "\n",
      "        [[1.0000, 0.5002, 0.5004,  ..., 0.6784, 0.7075, 0.7131]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5195, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9901,  1.1407, -0.8672], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5019, 0.5027,  ..., 0.7194, 0.7202, 0.7165]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6873, 0.6839, 0.6931]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6256, 0.6531, 0.6503]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5046,  ..., 0.7123, 0.7214, 0.6849]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5383, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9898,  1.1410, -0.8672], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5001, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5005, 0.5047,  ..., 0.7168, 0.7175, 0.7180]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[1.0000, 0.5020, 0.5005,  ..., 0.7207, 0.7195, 0.7200]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5680, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9895,  1.1413, -0.8672], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[0.0000, 0.5000, 0.5000,  ..., 0.7164, 0.7172, 0.7130]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.6447, 0.7097, 0.6943]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7177, 0.6533, 0.6725]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5001,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.6819, 0.7237, 0.7253]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.7161, 0.7118, 0.6913]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5182, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9885,  1.1422, -0.8672], device='cuda:0', grad_fn=<CloneBackward0>)\n",
      "x_pred:  tensor([[[1.0000, 0.5000, 0.5000,  ..., 0.7082, 0.6821, 0.6927]],\n",
      "\n",
      "        [[1.0000, 0.5001, 0.5000,  ..., 0.7171, 0.7157, 0.7161]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.7160, 0.7138, 0.7182]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.6775, 0.6867, 0.7127]],\n",
      "\n",
      "        [[1.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "        [[0.0000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "loss:  tensor(0.5216, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "previous theta:  tensor([-0.9881,  1.1426, -0.8672], device='cuda:0', grad_fn=<CloneBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [160], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m x0 \u001b[38;5;241m=\u001b[39m correct_seq[:, :\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m x_gt \u001b[38;5;241m=\u001b[39m correct_seq[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 16\u001b[0m x_pred, params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msimulate_path(x0\u001b[38;5;241m=\u001b[39mx0, t\u001b[38;5;241m=\u001b[39mtime_seq, stats\u001b[38;5;241m=\u001b[39mstats)\n\u001b[1;32m     17\u001b[0m p \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_item_pred\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m h \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhalf_life\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn [159], line 101\u001b[0m, in \u001b[0;36mHLR.simulate_path\u001b[0;34m(self, x0, t, items, stats_cal_on_fly, stats)\u001b[0m\n\u001b[1;32m     98\u001b[0m cur_feat \u001b[38;5;241m=\u001b[39m all_feature[:,:,i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# [bs, num_node, 3]\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# half_life = self.base ** (cur_feat @ self.theta)\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m half_life \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhclip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_feat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m p_all \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39mcur_dt\u001b[38;5;241m/\u001b[39mhalf_life)) \u001b[38;5;66;03m# [bs, num_node]\u001b[39;00m\n\u001b[1;32m    103\u001b[0m p_item \u001b[38;5;241m=\u001b[39m p_all[torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,num_seq), cur_item] \u001b[38;5;66;03m# [bs, ]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [159], line 48\u001b[0m, in \u001b[0;36mHLR.hclip\u001b[0;34m(h)\u001b[0m\n\u001b[1;32m     46\u001b[0m MIN_HALF_LIFE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m15.0\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m24\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m), device\u001b[38;5;241m=\u001b[39mh\u001b[38;5;241m.\u001b[39mdevice)    \u001b[38;5;66;03m# 15 minutes\u001b[39;00m\n\u001b[1;32m     47\u001b[0m MAX_HALF_LIFE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m274.\u001b[39m, device\u001b[38;5;241m=\u001b[39mh\u001b[38;5;241m.\u001b[39mdevice)                \u001b[38;5;66;03m# 9 months\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMIN_HALF_LIFE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_HALF_LIFE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_list(\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 211\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/traceback.py:362\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    359\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    360\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m--> 362\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/site-packages/IPython/core/compilerop.py:193\u001b[0m, in \u001b[0;36mcheck_linecache_ipython\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"Call linecache.checkcache() safely protecting our cached values.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# First call the original checkcache as intended\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkcache_ori\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Then, update back the cache with our data, so that tracebacks related\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# to our compiled codes can be produced.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m linecache\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mupdate(linecache\u001b[38;5;241m.\u001b[39m_ipython_cache)\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = HLR(mode='train', device=device)\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3 \n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train:   \n",
    "    for _, (user_id, time_seq, correct_seq, stats) in enumerate(train_loader):\n",
    "        # user_id [bs]\n",
    "        # time_seq [bs, max_time]\n",
    "        # correct_seq [bs, max_time]\n",
    "        # stats [bs, 1, 1, max_time, 3]\n",
    "        x0 = correct_seq[:, :1]\n",
    "        x_gt = correct_seq[:, 1:]\n",
    "        x_pred, params = model.simulate_path(x0=x0, t=time_seq, stats=stats)\n",
    "        p = params['x_item_pred']\n",
    "        h = params['half_life']\n",
    "        bceloss = loss_fn(p, x_gt.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        bceloss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        print('x_pred: ', x_pred)\n",
    "        print('loss: ', bceloss)\n",
    "        print('previous theta: ', model.theta.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab863dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0b96af68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fb61a374",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.6385, 0.5974,  ..., 0.4350, 0.6950, 0.5391]],\n",
      "\n",
      "        [[0.7311, 0.7935, 0.7151,  ..., 0.4595, 0.9449, 0.6396]],\n",
      "\n",
      "        [[0.7311, 0.8946, 0.6721,  ..., 0.5538, 0.9074, 0.6608]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7103, 0.5756,  ..., 0.3547, 0.4922, 0.5517]],\n",
      "\n",
      "        [[0.5000, 0.7668, 0.8117,  ..., 0.4915, 0.6373, 0.8568]],\n",
      "\n",
      "        [[0.7311, 0.9461, 0.7216,  ..., 0.7096, 0.2301, 0.7017]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5445, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.7508, 0.8143,  ..., 0.5385, 0.9110, 0.9036]],\n",
      "\n",
      "        [[0.5000, 0.3746, 0.7781,  ..., 0.6130, 0.7569, 0.4594]],\n",
      "\n",
      "        [[0.7311, 0.6003, 0.6425,  ..., 0.5447, 0.8033, 0.8700]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6687, 0.8518,  ..., 0.8261, 0.3956, 0.3042]],\n",
      "\n",
      "        [[0.7311, 0.7080, 0.5237,  ..., 0.7981, 0.9350, 0.6160]],\n",
      "\n",
      "        [[0.7311, 0.7191, 0.6858,  ..., 0.7200, 0.7605, 0.8926]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.7209, 0.8362,  ..., 0.4330, 0.8709, 0.5369]],\n",
      "\n",
      "        [[0.7311, 0.4145, 0.6846,  ..., 0.6235, 0.9417, 0.8070]],\n",
      "\n",
      "        [[0.7311, 0.3036, 0.6694,  ..., 0.7348, 0.7604, 0.7398]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.8333, 0.7363,  ..., 0.8112, 0.5922, 0.7586]],\n",
      "\n",
      "        [[0.7311, 0.7122, 0.6605,  ..., 0.4505, 0.6435, 0.6892]],\n",
      "\n",
      "        [[0.7311, 0.6770, 0.4310,  ..., 0.2798, 0.9001, 0.6957]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5116, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8227, 0.7294,  ..., 0.8157, 0.8986, 0.9120]],\n",
      "\n",
      "        [[0.7311, 0.4893, 0.7120,  ..., 0.8063, 0.5326, 0.4725]],\n",
      "\n",
      "        [[0.7311, 0.6356, 0.6686,  ..., 0.6999, 0.7383, 0.7298]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.5970, 0.7703,  ..., 0.5062, 0.7393, 0.7760]],\n",
      "\n",
      "        [[0.5000, 0.8748, 0.6717,  ..., 0.8354, 0.8717, 0.8050]],\n",
      "\n",
      "        [[0.7311, 0.9347, 0.7927,  ..., 0.8209, 0.3469, 0.6559]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.4943, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.7214, 0.7372,  ..., 0.5407, 0.7193, 0.7887]],\n",
      "\n",
      "        [[0.7311, 0.6935, 0.7400,  ..., 0.6369, 0.7529, 0.8386]],\n",
      "\n",
      "        [[0.7311, 0.5462, 0.9035,  ..., 0.4530, 0.6427, 0.8716]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.4740, 0.9028,  ..., 0.4078, 0.4722, 0.4452]],\n",
      "\n",
      "        [[0.5000, 0.7015, 0.5199,  ..., 0.7331, 0.7595, 0.8125]],\n",
      "\n",
      "        [[0.5000, 0.8038, 0.7656,  ..., 0.7470, 0.9073, 0.6536]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5524, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8495, 0.7933,  ..., 0.7777, 0.6069, 0.3598]],\n",
      "\n",
      "        [[0.7311, 0.7757, 0.7143,  ..., 0.8381, 0.8251, 0.5815]],\n",
      "\n",
      "        [[0.7311, 0.5956, 0.8013,  ..., 0.7153, 0.8233, 0.8855]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7186, 0.5530,  ..., 0.7748, 0.7391, 0.6314]],\n",
      "\n",
      "        [[0.7311, 0.6997, 0.8739,  ..., 0.7403, 0.9630, 0.7199]],\n",
      "\n",
      "        [[0.7311, 0.7240, 0.6865,  ..., 0.8133, 0.5117, 0.6381]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5607, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8975, 0.6108,  ..., 0.4935, 0.8855, 0.5429]],\n",
      "\n",
      "        [[0.7311, 0.8359, 0.5551,  ..., 0.6383, 0.8566, 0.8231]],\n",
      "\n",
      "        [[0.7311, 0.6937, 0.6569,  ..., 0.9100, 0.9114, 0.8316]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.4568, 0.4603,  ..., 0.5149, 0.8426, 0.4710]],\n",
      "\n",
      "        [[0.5000, 0.3742, 0.7569,  ..., 0.9102, 0.5835, 0.4406]],\n",
      "\n",
      "        [[0.7311, 0.3650, 0.7708,  ..., 0.5948, 0.5278, 0.4701]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5731, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.9212, 0.8440,  ..., 0.8911, 0.4991, 0.9261]],\n",
      "\n",
      "        [[0.5000, 0.5024, 0.7129,  ..., 0.7955, 0.8976, 0.8432]],\n",
      "\n",
      "        [[0.5000, 0.4420, 0.4028,  ..., 0.6078, 0.6619, 0.7626]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.5932, 0.7402,  ..., 0.6084, 0.7319, 0.6117]],\n",
      "\n",
      "        [[0.5000, 0.7837, 0.8889,  ..., 0.8252, 0.7946, 0.3689]],\n",
      "\n",
      "        [[0.7311, 0.9564, 0.7451,  ..., 0.5159, 0.5523, 0.4312]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5057, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.5000, 0.6036, 0.7794,  ..., 0.8926, 0.7723, 0.5901]],\n",
      "\n",
      "        [[0.5000, 0.6583, 0.6695,  ..., 0.7995, 0.7839, 0.5808]],\n",
      "\n",
      "        [[0.7311, 0.2946, 0.3845,  ..., 0.8222, 0.4968, 0.3220]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.8722, 0.8099,  ..., 0.6234, 0.8612, 0.6693]],\n",
      "\n",
      "        [[0.5000, 0.9456, 0.5368,  ..., 0.5497, 0.8804, 0.7229]],\n",
      "\n",
      "        [[0.7311, 0.7909, 0.8144,  ..., 0.8812, 0.4166, 0.6926]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.6223, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.7286, 0.7983,  ..., 0.7254, 0.6225, 0.6856]],\n",
      "\n",
      "        [[0.7311, 0.6117, 0.3208,  ..., 0.6850, 0.6341, 0.5424]],\n",
      "\n",
      "        [[0.7311, 0.6720, 0.3946,  ..., 0.6597, 0.8082, 0.8550]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.8014, 0.9050,  ..., 0.2292, 0.5494, 0.5653]],\n",
      "\n",
      "        [[0.7311, 0.9153, 0.9298,  ..., 0.7661, 0.8882, 0.9042]],\n",
      "\n",
      "        [[0.7311, 0.7808, 0.5520,  ..., 0.9558, 0.5919, 0.6333]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.6217, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8202, 0.6627,  ..., 0.6461, 0.9026, 0.7334]],\n",
      "\n",
      "        [[0.7311, 0.4789, 0.3567,  ..., 0.5478, 0.8472, 0.8657]],\n",
      "\n",
      "        [[0.7311, 0.9127, 0.6291,  ..., 0.6942, 0.5335, 0.9490]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.9557, 0.4374,  ..., 0.6582, 0.4463, 0.6439]],\n",
      "\n",
      "        [[0.7311, 0.6491, 0.6097,  ..., 0.7454, 0.5646, 0.4951]],\n",
      "\n",
      "        [[0.7311, 0.8565, 0.3868,  ..., 0.5410, 0.8507, 0.8654]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5667, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.4763, 0.8887,  ..., 0.5591, 0.5790, 0.9151]],\n",
      "\n",
      "        [[0.5000, 0.4379, 0.6447,  ..., 0.6392, 0.5468, 0.5747]],\n",
      "\n",
      "        [[0.7311, 0.9164, 0.5988,  ..., 0.6868, 0.3658, 0.7281]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7599, 0.2838,  ..., 0.6607, 0.7756, 0.5845]],\n",
      "\n",
      "        [[0.5000, 0.9056, 0.8401,  ..., 0.6744, 0.9393, 0.7124]],\n",
      "\n",
      "        [[0.7311, 0.6068, 0.6460,  ..., 0.6775, 0.6896, 0.7347]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.6665, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.2906, 0.6597,  ..., 0.7204, 0.6005, 0.9285]],\n",
      "\n",
      "        [[0.5000, 0.8964, 0.7112,  ..., 0.9410, 0.7853, 0.5605]],\n",
      "\n",
      "        [[0.7311, 0.8047, 0.7865,  ..., 0.8743, 0.5983, 0.8356]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.8887, 0.8225,  ..., 0.8582, 0.7634, 0.6320]],\n",
      "\n",
      "        [[0.7311, 0.8935, 0.7687,  ..., 0.5932, 0.8149, 0.9366]],\n",
      "\n",
      "        [[0.7311, 0.7996, 0.8542,  ..., 0.8557, 0.7268, 0.8151]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5723, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.5000, 0.7340, 0.6295,  ..., 0.7774, 0.5420, 0.6375]],\n",
      "\n",
      "        [[0.7311, 0.5343, 0.7992,  ..., 0.6717, 0.7810, 0.2307]],\n",
      "\n",
      "        [[0.7311, 0.7972, 0.4596,  ..., 0.6794, 0.6056, 0.6938]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.5676, 0.9160,  ..., 0.7491, 0.5367, 0.5158]],\n",
      "\n",
      "        [[0.7311, 0.6248, 0.9067,  ..., 0.6228, 0.5867, 0.3422]],\n",
      "\n",
      "        [[0.7311, 0.7254, 0.7177,  ..., 0.4189, 0.3344, 0.3952]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5749, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.9156, 0.9368,  ..., 0.9392, 0.8399, 0.3765]],\n",
      "\n",
      "        [[0.5000, 0.7306, 0.7044,  ..., 0.4884, 0.5423, 0.8856]],\n",
      "\n",
      "        [[0.7311, 0.8487, 0.5601,  ..., 0.8036, 0.8618, 0.5726]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.3171, 0.8798,  ..., 0.6093, 0.7789, 0.7544]],\n",
      "\n",
      "        [[0.7311, 0.6413, 0.8108,  ..., 0.4608, 0.6485, 0.6400]],\n",
      "\n",
      "        [[0.7311, 0.8964, 0.8707,  ..., 0.9237, 0.5394, 0.7719]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5744, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.5578, 0.7435,  ..., 0.6463, 0.8666, 0.5800]],\n",
      "\n",
      "        [[0.7311, 0.8379, 0.5343,  ..., 0.3867, 0.7476, 0.7107]],\n",
      "\n",
      "        [[0.5000, 0.4837, 0.8352,  ..., 0.8449, 0.5854, 0.7562]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.5599, 0.5414,  ..., 0.6441, 0.8012, 0.6646]],\n",
      "\n",
      "        [[0.5000, 0.6195, 0.8446,  ..., 0.8213, 0.9170, 0.5227]],\n",
      "\n",
      "        [[0.5000, 0.8768, 0.5241,  ..., 0.5845, 0.8765, 0.9053]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8082, 0.6741,  ..., 0.7748, 0.3898, 0.7288]],\n",
      "\n",
      "        [[0.7311, 0.4541, 0.3733,  ..., 0.6465, 0.6685, 0.4876]],\n",
      "\n",
      "        [[0.7311, 0.8498, 0.7147,  ..., 0.5673, 0.5590, 0.6753]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7527, 0.8672,  ..., 0.9037, 0.7834, 0.5733]],\n",
      "\n",
      "        [[0.5000, 0.3583, 0.3236,  ..., 0.6546, 0.8231, 0.7193]],\n",
      "\n",
      "        [[0.5000, 0.8122, 0.5673,  ..., 0.7122, 0.9330, 0.6054]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5006, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.5303, 0.8634,  ..., 0.4197, 0.4174, 0.5908]],\n",
      "\n",
      "        [[0.5000, 0.6479, 0.8632,  ..., 0.4047, 0.7740, 0.8731]],\n",
      "\n",
      "        [[0.7311, 0.7123, 0.8223,  ..., 0.6311, 0.4012, 0.8900]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6030, 0.7077,  ..., 0.6332, 0.8470, 0.6943]],\n",
      "\n",
      "        [[0.5000, 0.2772, 0.7247,  ..., 0.6510, 0.9761, 0.7563]],\n",
      "\n",
      "        [[0.5000, 0.4757, 0.6376,  ..., 0.5628, 0.3939, 0.7715]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5438, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8458, 0.6611,  ..., 0.7761, 0.6512, 0.7344]],\n",
      "\n",
      "        [[0.7311, 0.7646, 0.5786,  ..., 0.3642, 0.7130, 0.8464]],\n",
      "\n",
      "        [[0.5000, 0.5336, 0.8117,  ..., 0.7124, 0.7812, 0.8447]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6541, 0.6994,  ..., 0.8485, 0.6908, 0.8112]],\n",
      "\n",
      "        [[0.7311, 0.9326, 0.6934,  ..., 0.6108, 0.7430, 0.5896]],\n",
      "\n",
      "        [[0.7311, 0.7780, 0.2840,  ..., 0.7772, 0.6996, 0.7709]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5926, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8858, 0.8532,  ..., 0.6000, 0.8698, 0.7560]],\n",
      "\n",
      "        [[0.7311, 0.5807, 0.3063,  ..., 0.8153, 0.6833, 0.6631]],\n",
      "\n",
      "        [[0.7311, 0.6288, 0.7339,  ..., 0.5058, 0.6508, 0.3520]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.4398, 0.8690,  ..., 0.6677, 0.5298, 0.5145]],\n",
      "\n",
      "        [[0.7311, 0.6090, 0.7373,  ..., 0.7301, 0.7141, 0.4756]],\n",
      "\n",
      "        [[0.7311, 0.7942, 0.6980,  ..., 0.8538, 0.8312, 0.5468]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5807, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.5715, 0.8726,  ..., 0.6783, 0.6248, 0.8771]],\n",
      "\n",
      "        [[0.7311, 0.5051, 0.8681,  ..., 0.6405, 0.3444, 0.8750]],\n",
      "\n",
      "        [[0.7311, 0.9095, 0.7945,  ..., 0.8947, 0.3779, 0.7434]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.5617, 0.8599,  ..., 0.4405, 0.6307, 0.4790]],\n",
      "\n",
      "        [[0.7311, 0.9661, 0.5196,  ..., 0.5965, 0.8192, 0.6607]],\n",
      "\n",
      "        [[0.7311, 0.5522, 0.4534,  ..., 0.6967, 0.7578, 0.3625]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5192, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.5398, 0.6731,  ..., 0.9737, 0.8795, 0.6125]],\n",
      "\n",
      "        [[0.7311, 0.7371, 0.9297,  ..., 0.8332, 0.8364, 0.6946]],\n",
      "\n",
      "        [[0.5000, 0.6644, 0.7971,  ..., 0.7447, 0.8021, 0.7668]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.8286, 0.5179,  ..., 0.4320, 0.7140, 0.8057]],\n",
      "\n",
      "        [[0.7311, 0.9273, 0.6811,  ..., 0.4818, 0.7261, 0.8781]],\n",
      "\n",
      "        [[0.5000, 0.7729, 0.6266,  ..., 0.4829, 0.7263, 0.5800]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5044, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.3936, 0.8922,  ..., 0.7823, 0.7438, 0.8198]],\n",
      "\n",
      "        [[0.7311, 0.6978, 0.5150,  ..., 0.8260, 0.6987, 0.5417]],\n",
      "\n",
      "        [[0.7311, 0.9441, 0.6241,  ..., 0.7152, 0.5482, 0.7144]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.4048, 0.4133,  ..., 0.7185, 0.6589, 0.6492]],\n",
      "\n",
      "        [[0.7311, 0.4510, 0.4271,  ..., 0.6552, 0.8791, 0.8585]],\n",
      "\n",
      "        [[0.5000, 0.6438, 0.6586,  ..., 0.7804, 0.6225, 0.6484]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5326, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8936, 0.6891,  ..., 0.8299, 0.8624, 0.9044]],\n",
      "\n",
      "        [[0.5000, 0.3299, 0.5921,  ..., 0.7641, 0.8206, 0.7990]],\n",
      "\n",
      "        [[0.5000, 0.9093, 0.6118,  ..., 0.6839, 0.5671, 0.7376]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.5876, 0.5663,  ..., 0.8513, 0.2598, 0.4589]],\n",
      "\n",
      "        [[0.7311, 0.7223, 0.9049,  ..., 0.7422, 0.8490, 0.6782]],\n",
      "\n",
      "        [[0.7311, 0.7300, 0.8640,  ..., 0.4522, 0.8472, 0.7259]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5303, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.4976, 0.9062,  ..., 0.5533, 0.7154, 0.7273]],\n",
      "\n",
      "        [[0.7311, 0.8131, 0.6330,  ..., 0.8494, 0.5478, 0.8198]],\n",
      "\n",
      "        [[0.7311, 0.5078, 0.4940,  ..., 0.6864, 0.3024, 0.5932]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.5837, 0.5906,  ..., 0.8837, 0.7151, 0.4080]],\n",
      "\n",
      "        [[0.7311, 0.6594, 0.7039,  ..., 0.4927, 0.5763, 0.6537]],\n",
      "\n",
      "        [[0.7311, 0.5475, 0.8969,  ..., 0.5955, 0.5631, 0.7674]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5423, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8172, 0.8524,  ..., 0.5400, 0.5414, 0.4187]],\n",
      "\n",
      "        [[0.5000, 0.8496, 0.8540,  ..., 0.4045, 0.5395, 0.9028]],\n",
      "\n",
      "        [[0.5000, 0.8364, 0.7956,  ..., 0.5770, 0.4489, 0.7162]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.8350, 0.7215,  ..., 0.5577, 0.5860, 0.7010]],\n",
      "\n",
      "        [[0.7311, 0.7847, 0.8361,  ..., 0.4794, 0.8804, 0.6300]],\n",
      "\n",
      "        [[0.5000, 0.5537, 0.6565,  ..., 0.2782, 0.6709, 0.4328]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5587, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.6355, 0.6947,  ..., 0.6621, 0.5418, 0.7513]],\n",
      "\n",
      "        [[0.5000, 0.4342, 0.6764,  ..., 0.4986, 0.6138, 0.8155]],\n",
      "\n",
      "        [[0.5000, 0.8349, 0.6847,  ..., 0.6306, 0.8033, 0.4780]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7899, 0.5658,  ..., 0.6818, 0.3928, 0.6418]],\n",
      "\n",
      "        [[0.7311, 0.7382, 0.8600,  ..., 0.5649, 0.7421, 0.7302]],\n",
      "\n",
      "        [[0.5000, 0.9429, 0.6775,  ..., 0.6925, 0.6730, 0.7873]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5327, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.7253, 0.7727,  ..., 0.8882, 0.7826, 0.7099]],\n",
      "\n",
      "        [[0.7311, 0.7976, 0.5717,  ..., 0.7199, 0.4161, 0.6997]],\n",
      "\n",
      "        [[0.5000, 0.8635, 0.5137,  ..., 0.7712, 0.7449, 0.8523]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6509, 0.8745,  ..., 0.4043, 0.8197, 0.8274]],\n",
      "\n",
      "        [[0.7311, 0.8932, 0.6570,  ..., 0.4692, 0.7303, 0.7953]],\n",
      "\n",
      "        [[0.7311, 0.8297, 0.6672,  ..., 0.8073, 0.9018, 0.4940]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5649, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8454, 0.7424,  ..., 0.7474, 0.5037, 0.5482]],\n",
      "\n",
      "        [[0.5000, 0.7088, 0.6576,  ..., 0.3573, 0.7947, 0.7086]],\n",
      "\n",
      "        [[0.5000, 0.6112, 0.6292,  ..., 0.7034, 0.7496, 0.8072]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.4733, 0.5911,  ..., 0.8299, 0.2728, 0.6878]],\n",
      "\n",
      "        [[0.7311, 0.9350, 0.7955,  ..., 0.9457, 0.7947, 0.9465]],\n",
      "\n",
      "        [[0.7311, 0.6022, 0.6172,  ..., 0.7204, 0.6041, 0.5742]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5997, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.9589, 0.4749,  ..., 0.8377, 0.9640, 0.4486]],\n",
      "\n",
      "        [[0.7311, 0.5379, 0.8646,  ..., 0.1757, 0.7476, 0.8139]],\n",
      "\n",
      "        [[0.5000, 0.8934, 0.8029,  ..., 0.8999, 0.5621, 0.4076]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6612, 0.8051,  ..., 0.8478, 0.6214, 0.5060]],\n",
      "\n",
      "        [[0.5000, 0.6537, 0.7536,  ..., 0.6867, 0.9283, 0.5254]],\n",
      "\n",
      "        [[0.5000, 0.8021, 0.7506,  ..., 0.5656, 0.6319, 0.5437]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5143, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.9338, 0.3848,  ..., 0.8423, 0.8388, 0.9267]],\n",
      "\n",
      "        [[0.5000, 0.7367, 0.7772,  ..., 0.5574, 0.4793, 0.5348]],\n",
      "\n",
      "        [[0.5000, 0.5316, 0.8446,  ..., 0.8520, 0.6895, 0.8422]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7670, 0.8158,  ..., 0.7194, 0.6773, 0.7437]],\n",
      "\n",
      "        [[0.7311, 0.8140, 0.8824,  ..., 0.7539, 0.4787, 0.5499]],\n",
      "\n",
      "        [[0.5000, 0.5655, 0.7885,  ..., 0.4423, 0.2434, 0.5031]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5566, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.5000, 0.7794, 0.8576,  ..., 0.5640, 0.6832, 0.6452]],\n",
      "\n",
      "        [[0.7311, 0.4990, 0.7840,  ..., 0.8362, 0.7291, 0.6564]],\n",
      "\n",
      "        [[0.7311, 0.5473, 0.6190,  ..., 0.6507, 0.8157, 0.7351]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7383, 0.9093,  ..., 0.6093, 0.8905, 0.8915]],\n",
      "\n",
      "        [[0.7311, 0.4496, 0.8370,  ..., 0.8159, 0.7906, 0.9133]],\n",
      "\n",
      "        [[0.7311, 0.7658, 0.7829,  ..., 0.6986, 0.8517, 0.8246]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5234, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.7660, 0.9119,  ..., 0.6131, 0.5765, 0.5485]],\n",
      "\n",
      "        [[0.7311, 0.7379, 0.6738,  ..., 0.8505, 0.3914, 0.7906]],\n",
      "\n",
      "        [[0.7311, 0.6458, 0.6990,  ..., 0.6374, 0.7320, 0.7958]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.2819, 0.5629,  ..., 0.7448, 0.4341, 0.7364]],\n",
      "\n",
      "        [[0.7311, 0.7965, 0.7762,  ..., 0.6363, 0.6238, 0.7094]],\n",
      "\n",
      "        [[0.7311, 0.6865, 0.8370,  ..., 0.9288, 0.7389, 0.4384]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.4977, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.5633, 0.7197,  ..., 0.5225, 0.8390, 0.8143]],\n",
      "\n",
      "        [[0.7311, 0.9213, 0.7390,  ..., 0.6260, 0.8587, 0.8568]],\n",
      "\n",
      "        [[0.7311, 0.7941, 0.6555,  ..., 0.5798, 0.8052, 0.7296]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.5450, 0.4930,  ..., 0.7646, 0.3484, 0.7002]],\n",
      "\n",
      "        [[0.7311, 0.8863, 0.8323,  ..., 0.7603, 0.3810, 0.8660]],\n",
      "\n",
      "        [[0.7311, 0.8898, 0.5410,  ..., 0.9077, 0.7150, 0.5155]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.6039, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8514, 0.5963,  ..., 0.4854, 0.1665, 0.7193]],\n",
      "\n",
      "        [[0.7311, 0.4293, 0.4495,  ..., 0.5877, 0.7071, 0.2541]],\n",
      "\n",
      "        [[0.7311, 0.8726, 0.4183,  ..., 0.8394, 0.8383, 0.6658]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.8673, 0.4819,  ..., 0.8157, 0.6527, 0.8680]],\n",
      "\n",
      "        [[0.7311, 0.7209, 0.8698,  ..., 0.4761, 0.6374, 0.6115]],\n",
      "\n",
      "        [[0.5000, 0.7892, 0.3027,  ..., 0.6855, 0.8372, 0.8328]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5360, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.5847, 0.6320,  ..., 0.3852, 0.7427, 0.8594]],\n",
      "\n",
      "        [[0.5000, 0.6681, 0.6624,  ..., 0.8161, 0.9087, 0.7320]],\n",
      "\n",
      "        [[0.7311, 0.7112, 0.6474,  ..., 0.7989, 0.7815, 0.6571]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.5890, 0.6882,  ..., 0.9092, 0.7597, 0.6183]],\n",
      "\n",
      "        [[0.7311, 0.8370, 0.7918,  ..., 0.7557, 0.6683, 0.6599]],\n",
      "\n",
      "        [[0.5000, 0.5385, 0.8114,  ..., 0.7864, 0.7566, 0.8890]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.6116, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.5490, 0.6302,  ..., 0.8504, 0.4454, 0.5513]],\n",
      "\n",
      "        [[0.7311, 0.7663, 0.8597,  ..., 0.5307, 0.6831, 0.7613]],\n",
      "\n",
      "        [[0.5000, 0.8519, 0.8406,  ..., 0.4058, 0.7192, 0.9233]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.4648, 0.8445,  ..., 0.5303, 0.5688, 0.5834]],\n",
      "\n",
      "        [[0.7311, 0.7086, 0.5613,  ..., 0.6600, 0.5058, 0.8391]],\n",
      "\n",
      "        [[0.5000, 0.7192, 0.7509,  ..., 0.6687, 0.5116, 0.7934]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5129, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.5000, 0.4833, 0.6545,  ..., 0.7252, 0.6936, 0.4598]],\n",
      "\n",
      "        [[0.7311, 0.7192, 0.5936,  ..., 0.7088, 0.8403, 0.7464]],\n",
      "\n",
      "        [[0.7311, 0.8238, 0.2877,  ..., 0.8638, 0.8538, 0.6500]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.9465, 0.6628,  ..., 0.7853, 0.5443, 0.7177]],\n",
      "\n",
      "        [[0.7311, 0.5044, 0.7530,  ..., 0.6598, 0.8431, 0.6356]],\n",
      "\n",
      "        [[0.7311, 0.8306, 0.6555,  ..., 0.7641, 0.5120, 0.7565]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.6217, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.5000, 0.6292, 0.7023,  ..., 0.7337, 0.1887, 0.7300]],\n",
      "\n",
      "        [[0.7311, 0.7425, 0.5336,  ..., 0.6262, 0.5058, 0.4995]],\n",
      "\n",
      "        [[0.7311, 0.7930, 0.7996,  ..., 0.8527, 0.7967, 0.5819]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.4983, 0.6854,  ..., 0.5812, 0.5872, 0.6663]],\n",
      "\n",
      "        [[0.5000, 0.6400, 0.7308,  ..., 0.7072, 0.7810, 0.8070]],\n",
      "\n",
      "        [[0.7311, 0.5684, 0.8822,  ..., 0.3529, 0.7776, 0.8752]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.4912, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.8587, 0.9466,  ..., 0.6231, 0.6519, 0.9052]],\n",
      "\n",
      "        [[0.7311, 0.7633, 0.6134,  ..., 0.4062, 0.9456, 0.4666]],\n",
      "\n",
      "        [[0.5000, 0.6805, 0.6271,  ..., 0.7580, 0.7812, 0.6128]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.4937, 0.5148,  ..., 0.7517, 0.8754, 0.6130]],\n",
      "\n",
      "        [[0.7311, 0.6080, 0.7122,  ..., 0.8753, 0.6358, 0.6833]],\n",
      "\n",
      "        [[0.7311, 0.6094, 0.9276,  ..., 0.3913, 0.5815, 0.8235]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5687, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.6331, 0.4220,  ..., 0.9266, 0.7356, 0.4249]],\n",
      "\n",
      "        [[0.7311, 0.7822, 0.8023,  ..., 0.5172, 0.8949, 0.9447]],\n",
      "\n",
      "        [[0.7311, 0.5640, 0.2288,  ..., 0.8094, 0.5794, 0.8000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6541, 0.7541,  ..., 0.8963, 0.9661, 0.9288]],\n",
      "\n",
      "        [[0.7311, 0.4215, 0.7824,  ..., 0.7541, 0.5473, 0.8283]],\n",
      "\n",
      "        [[0.5000, 0.8141, 0.6676,  ..., 0.5165, 0.7134, 0.7465]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5502, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.6896, 0.8787,  ..., 0.7867, 0.7165, 0.4742]],\n",
      "\n",
      "        [[0.7311, 0.5755, 0.7704,  ..., 0.7623, 0.7538, 0.6440]],\n",
      "\n",
      "        [[0.5000, 0.6743, 0.7568,  ..., 0.7243, 0.6415, 0.5729]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.5572, 0.7326,  ..., 0.7882, 0.6522, 0.8650]],\n",
      "\n",
      "        [[0.5000, 0.8451, 0.4732,  ..., 0.5516, 0.3683, 0.6517]],\n",
      "\n",
      "        [[0.5000, 0.8241, 0.5400,  ..., 0.6251, 0.7783, 0.9262]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.5477, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "x_pred:  tensor([[[0.7311, 0.3881, 0.8470,  ..., 0.7801, 0.9259, 0.7082]],\n",
      "\n",
      "        [[0.7311, 0.6621, 0.6696,  ..., 0.6005, 0.8709, 0.8842]],\n",
      "\n",
      "        [[0.7311, 0.7526, 0.7198,  ..., 0.6310, 0.6559, 0.4783]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.8296, 0.8575,  ..., 0.8226, 0.8267, 0.6776]],\n",
      "\n",
      "        [[0.5000, 0.7686, 0.4209,  ..., 0.6255, 0.6346, 0.8385]],\n",
      "\n",
      "        [[0.7311, 0.6791, 0.7962,  ..., 0.6109, 0.6548, 0.6668]]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "loss:  tensor(0.6109, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [166], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m x0 \u001b[38;5;241m=\u001b[39m correct_seq[:, :\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m x_gt \u001b[38;5;241m=\u001b[39m correct_seq[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 17\u001b[0m x_pred, params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msimulate_path(x0\u001b[38;5;241m=\u001b[39mx0, t\u001b[38;5;241m=\u001b[39mtime_seq)\n\u001b[1;32m     18\u001b[0m x_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(x_pred)\n\u001b[1;32m     20\u001b[0m bceloss \u001b[38;5;241m=\u001b[39m loss_fn(x_pred[:,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mfloat(), x_gt\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m/mnt/qb/home/mlcolab/hzhou52/knowledge_tracing/exp/../models/parametric_models.py:166\u001b[0m, in \u001b[0;36mVanillaOU.simulate_path\u001b[0;34m(self, x0, t, items)\u001b[0m\n\u001b[1;32m    164\u001b[0m x_pred\u001b[38;5;241m.\u001b[39mappend(x_last)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, time_step):\n\u001b[0;32m--> 166\u001b[0m     x_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_last\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [bs, num_node]\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     x_next \u001b[38;5;241m=\u001b[39m x_next \u001b[38;5;241m+\u001b[39m noise[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m scale[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    168\u001b[0m     x_pred\u001b[38;5;241m.\u001b[39mappend(x_next)\n",
      "File \u001b[0;32m/mnt/qb/home/mlcolab/hzhou52/knowledge_tracing/exp/../models/parametric_models.py:109\u001b[0m, in \u001b[0;36mVanillaOU.mean\u001b[0;34m(self, x0, t, speed, level)\u001b[0m\n\u001b[1;32m    107\u001b[0m speed \u001b[38;5;241m=\u001b[39m speed \u001b[38;5;28;01mif\u001b[39;00m speed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_rev_speed\n\u001b[1;32m    108\u001b[0m level \u001b[38;5;241m=\u001b[39m level \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_rev_level\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x0 \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mspeed \u001b[38;5;241m*\u001b[39m t) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m)) \u001b[38;5;241m*\u001b[39m level\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_list(\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 211\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/traceback.py:362\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    359\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[1;32m    360\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[0;32m--> 362\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/site-packages/IPython/core/compilerop.py:193\u001b[0m, in \u001b[0;36mcheck_linecache_ipython\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"Call linecache.checkcache() safely protecting our cached values.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# First call the original checkcache as intended\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkcache_ori\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Then, update back the cache with our data, so that tracebacks related\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# to our compiled codes can be produced.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m linecache\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mupdate(linecache\u001b[38;5;241m.\u001b[39m_ipython_cache)\n",
      "File \u001b[0;32m/mnt/qb/work/mlcolab/hzhou52/anaconda3/envs/mykt/lib/python3.9/linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.parametric_models import VanillaOU\n",
    "model = VanillaOU(mode='train',device=device)\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3 \n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train:   \n",
    "    for _, (user_id, time_seq, correct_seq, stats) in enumerate(train_loader):\n",
    "        # user_id [bs]\n",
    "        # time_seq [bs, max_time]\n",
    "        # correct_seq [bs, max_time]\n",
    "        # stats [bs, 1, 1, max_time, 3]\n",
    "        x0 = correct_seq[:, :1]\n",
    "        x_gt = correct_seq[:, 1:]\n",
    "        x_pred, params = model.simulate_path(x0=x0, t=time_seq)\n",
    "        x_pred = torch.sigmoid(x_pred)\n",
    "        \n",
    "        bceloss = loss_fn(x_pred[:,0,1:].float(), x_gt.float())\n",
    "        optimizer.zero_grad()\n",
    "        bceloss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        for p in model.parameters():\n",
    "            p.data.clamp_(0)\n",
    "            \n",
    "        print('x_pred: ', x_pred)\n",
    "        print('loss: ', bceloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b886a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4dd9aacd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[1396074712950590, 1396074731829670, 1396074773575750, ...,\n",
       "          1398852710575690, 1398852992033000, 1398852994450900],\n",
       "         [1415262416498920, 1415262419445660, 1415262422195060, ...,\n",
       "          1415263057357550, 1415263059526660, 1415263061520220],\n",
       "         [1387787774940730, 1387787781184910, 1387787799123690, ...,\n",
       "          1388048675490840, 1388048679178310, 1388048680993940],\n",
       "         ...,\n",
       "         [1415795063793670, 1415795070589590, 1415795076839730, ...,\n",
       "          1419502373008050, 1419502377533750, 1419502384260280],\n",
       "         [1413724796537240, 1413724806822940, 1413724814720990, ...,\n",
       "          1415013021904710, 1415013029341670, 1415013036723360],\n",
       "         [1392187490662380, 1392187502786280, 1392187529079100, ...,\n",
       "          1398341836997900, 1398341839500620, 1398341841491520]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1419409365829920, 1419409369231440, 1419409372278230, ...,\n",
       "          1420531824845200, 1420531825918530, 1420531828653220],\n",
       "         [1403351115659730, 1403351140396670, 1403351145345240, ...,\n",
       "          1403414284958540, 1403414288947060, 1403414292990980],\n",
       "         [1355728731028100, 1355728740830570, 1355728744101200, ...,\n",
       "          1419220726582170, 1419220729015480, 1419220731748830],\n",
       "         ...,\n",
       "         [1414632059171840, 1414632067656960, 1414632088018320, ...,\n",
       "          1416057057606340, 1416057062073680, 1416057066146120],\n",
       "         [1420758145395200, 1420758173543130, 1420758180447620, ...,\n",
       "          1420763537090420, 1420763539465310, 1420763541352210],\n",
       "         [1414041163846410, 1414644761305850, 1414644764125970, ...,\n",
       "          1417670246088830, 1417670249042800, 1417670253931920]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1416905390041770, 1416905402404250, 1416905412604970, ...,\n",
       "          1419294084095810, 1419294091032130, 1419294097851840],\n",
       "         [1394526105530770, 1394526138045310, 1394526149192330, ...,\n",
       "          1396319552221850, 1396319554877530, 1396319559750240],\n",
       "         [1415254051208550, 1415254067241400, 1415254076973010, ...,\n",
       "          1415339466187080, 1415339475419590, 1415339488391100],\n",
       "         ...,\n",
       "         [1384231669925100, 1384231676711740, 1384231679458810, ...,\n",
       "          1384434761766050, 1384434764966490, 1384434765657510],\n",
       "         [1402671144033840, 1402671154708500, 1402671166347790, ...,\n",
       "          1403880886340040, 1403880898364020, 1403880900291530],\n",
       "         [1413625338501710, 1413625515059250, 1413625666085990, ...,\n",
       "          1416725892832950, 1416725904339290, 1416725917977750]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 0],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 0, 0, 0]])),\n",
       " (array([[1404116820123360, 1404116882152570, 1404117006578900, ...,\n",
       "          1404282292680800, 1404282348555890, 1404282360552350],\n",
       "         [1352790640328650, 1352790650238450, 1352790663365030, ...,\n",
       "          1365332182850210, 1365332192914110, 1365332200215080],\n",
       "         [1380027875625110, 1380027881908580, 1380027887955650, ...,\n",
       "          1380267977763320, 1380267981149280, 1380267984365850],\n",
       "         ...,\n",
       "         [1416301399512640, 1416301402391760, 1416301405352730, ...,\n",
       "          1416303806495490, 1416303807483850, 1416303808430820],\n",
       "         [1418045850511780, 1418045862533170, 1418045870931730, ...,\n",
       "          1418132034253100, 1418132039673240, 1418132043616010],\n",
       "         [1400117178968170, 1401929869425670, 1401929896165850, ...,\n",
       "          1402534354861000, 1402534362160940, 1402534373479710]]),\n",
       "  array([[0, 0, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 0]])),\n",
       " (array([[1401705741718220, 1401705752451830, 1401705848873710, ...,\n",
       "          1411383437287650, 1411383443024170, 1411471448517620],\n",
       "         [1417154585833690, 1417154595519970, 1417154604324250, ...,\n",
       "          1419421647924940, 1419421651529050, 1419421653446490],\n",
       "         [1397724093052370, 1397724099076530, 1397724104033950, ...,\n",
       "          1418899208946850, 1418899211181860, 1418899213361120],\n",
       "         ...,\n",
       "         [1384419298264930, 1384419302436290, 1384419313725430, ...,\n",
       "          1385628835015790, 1385628843664860, 1385628855862280],\n",
       "         [1396341934913670, 1396341948496630, 1396341954919660, ...,\n",
       "          1402030113973110, 1402030126455970, 1402030130620560],\n",
       "         [1397731988765770, 1397732021796980, 1397732037048380, ...,\n",
       "          1398417496128170, 1398417499716650, 1398417503508030]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 0, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1]])),\n",
       " (array([[1415102647789270, 1415102649988390, 1415102658784700, ...,\n",
       "          1420962980447790, 1420962982401180, 1420962984110660],\n",
       "         [1384319125650220, 1384319136877260, 1384319141201580, ...,\n",
       "          1385112916201840, 1385112922466730, 1385112927006610],\n",
       "         [1396861140028810, 1396861160943970, 1396861167076530, ...,\n",
       "          1398071842590890, 1398071846182070, 1398071852730720],\n",
       "         ...,\n",
       "         [1389769348489340, 1389769356688170, 1389769365262780, ...,\n",
       "          1398835102968980, 1398835105547680, 1398835108233310],\n",
       "         [1397201430560050, 1397201434450130, 1397201442993060, ...,\n",
       "          1397550075064820, 1397550078034970, 1397550108428930],\n",
       "         [1414127354452090, 1414127362397600, 1414127369404400, ...,\n",
       "          1418620297761480, 1418620301782000, 1418620304214160]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1415093667018130, 1415093680304760, 1415093694804890, ...,\n",
       "          1420708930752940, 1420708936556050, 1420708939260000],\n",
       "         [1394543957356270, 1394543982521890, 1394543985361260, ...,\n",
       "          1401973690780890, 1401973692374250, 1401973742877200],\n",
       "         [1415950795862570, 1415950799263130, 1415950802083140, ...,\n",
       "          1416554947117940, 1416554948480030, 1416554951437990],\n",
       "         ...,\n",
       "         [1397786437366360, 1397786439219620, 1397786452093440, ...,\n",
       "          1399601761681540, 1399601764167900, 1399601767638110],\n",
       "         [1400567272923000, 1400567285151870, 1400567301989160, ...,\n",
       "          1400596749101080, 1400596751566360, 1400596753981530],\n",
       "         [1381067606529840, 1381067619195120, 1381067626951390, ...,\n",
       "          1398001978816300, 1398001982393070, 1398002156853760]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1390379309501350, 1390379339045140, 1390379357598740, ...,\n",
       "          1390535770846940, 1390535777074030, 1390535789346820],\n",
       "         [1407371667798360, 1407372398517650, 1407372706485320, ...,\n",
       "          1408065161004060, 1408065220126440, 1408065238969520],\n",
       "         [1396499676723910, 1396499697830640, 1396499709236090, ...,\n",
       "          1396658619835060, 1396658624286170, 1396658628049490],\n",
       "         ...,\n",
       "         [1420015131093580, 1420015215682820, 1420015243550600, ...,\n",
       "          1420619608431660, 1420619617135860, 1420619639479410],\n",
       "         [1394673053125740, 1394673058903760, 1394673062892100, ...,\n",
       "          1395279452270880, 1395279458772910, 1395279460858020],\n",
       "         [1383284739426460, 1383284744189630, 1383284748271020, ...,\n",
       "          1383433319643590, 1383433327032620, 1383433329670630]]),\n",
       "  array([[0, 0, 0, ..., 1, 0, 0],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1377835001504370, 1377835004499850, 1377835006827150, ...,\n",
       "          1382361597676770, 1382361599629900, 1382361601241570],\n",
       "         [1419224220038280, 1419224233089800, 1419224280676390, ...,\n",
       "          1419311198709080, 1419311201777870, 1419311205290440],\n",
       "         [1396839861170830, 1396839864034090, 1396839866189230, ...,\n",
       "          1397445127429820, 1397445134623100, 1397445136564250],\n",
       "         ...,\n",
       "         [1396255858291500, 1396256065426460, 1396256170917890, ...,\n",
       "          1402359708833020, 1402359728257970, 1402359736268050],\n",
       "         [1412861053877700, 1412861072464730, 1412861094889710, ...,\n",
       "          1420004154915820, 1420004160781990, 1420004176147410],\n",
       "         [1390705711824930, 1390705714885360, 1390705718699050, ...,\n",
       "          1390985077751850, 1390985080407800, 1390985083478300]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 1, ..., 1, 1, 0],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1367498844022870, 1367498906060690, 1367500801081300, ...,\n",
       "          1368877802336500, 1368877804701330, 1368877806642470],\n",
       "         [1398163796604330, 1398163825666240, 1398234758260760, ...,\n",
       "          1398761292824600, 1398761307847110, 1398761320074300],\n",
       "         [1383112909006380, 1383112924813900, 1383112938825610, ...,\n",
       "          1393135643744920, 1393136796901790, 1393416130013650],\n",
       "         ...,\n",
       "         [1411989487554440, 1411989552365660, 1411989572129130, ...,\n",
       "          1413804856017830, 1413804944001180, 1414412635851490],\n",
       "         [1416885515711290, 1416885545288400, 1416885798682460, ...,\n",
       "          1417099279278400, 1417099288975540, 1417099301464940],\n",
       "         [1416360643684760, 1416360647074590, 1416360649915060, ...,\n",
       "          1417400905787440, 1417400908385530, 1417400910540990]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 0],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1394704236368670, 1394704309307230, 1394704333524540, ...,\n",
       "          1396518015071770, 1396518146987520, 1396518181257810],\n",
       "         [1382676446622760, 1384145429594630, 1384145451730580, ...,\n",
       "          1397445115251210, 1397445126515230, 1397445135207600],\n",
       "         [1416380736848880, 1416380740255200, 1416380744993890, ...,\n",
       "          1418796284159990, 1418796292754750, 1418796297357220],\n",
       "         ...,\n",
       "         [1420520173712670, 1420520187815290, 1420520196983690, ...,\n",
       "          1420602847774540, 1420602850262340, 1420602853100520],\n",
       "         [1397639659285340, 1397639952389250, 1397639984084700, ...,\n",
       "          1413365165889890, 1413365173166810, 1413365524880070],\n",
       "         [1380779707302900, 1380779715070530, 1380779727586180, ...,\n",
       "          1401344180289950, 1401344194723310, 1401344198862680]]),\n",
       "  array([[1, 0, 0, ..., 0, 1, 0],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1418032309823590, 1418083851933730, 1418083920825880, ...,\n",
       "          1418212059661670, 1418212072562450, 1418212076730220],\n",
       "         [1399278724692460, 1399278831249860, 1399278876582920, ...,\n",
       "          1418097188325390, 1418097198260810, 1418097217855530],\n",
       "         [1390212566752660, 1390212569533350, 1390212573249610, ...,\n",
       "          1404204298480760, 1404204301118790, 1404204304299070],\n",
       "         ...,\n",
       "         [1407293028379050, 1407293040585110, 1407293046380200, ...,\n",
       "          1407467164550220, 1407467170709190, 1407467187522780],\n",
       "         [1407287757289780, 1407288511706050, 1407288539569460, ...,\n",
       "          1407290626726370, 1407290639831100, 1407290645624020],\n",
       "         [1416820845655170, 1416820848555300, 1416820849756850, ...,\n",
       "          1417076838492530, 1417076839771900, 1417076841689670]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 1, 0, 1],\n",
       "         [0, 0, 1, ..., 0, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1]])),\n",
       " (array([[1419233408097570, 1419233418904430, 1419233422228600, ...,\n",
       "          1419838791733360, 1419838793765750, 1419838797113280],\n",
       "         [1380693358080450, 1380693376857230, 1380693409302560, ...,\n",
       "          1395839648183360, 1395839658135980, 1396775462332830],\n",
       "         [1395125610608730, 1395125628672840, 1395125634379350, ...,\n",
       "          1415346219109280, 1415346221426100, 1415346226776580],\n",
       "         ...,\n",
       "         [1402896119830620, 1402896132821530, 1402896135478150, ...,\n",
       "          1402915172205470, 1402915178579150, 1402915181634720],\n",
       "         [1396873396391550, 1396873411915870, 1396873417522460, ...,\n",
       "          1397373371898120, 1397373374362070, 1397373376929030],\n",
       "         [1403700516012760, 1403700526359700, 1403700549909640, ...,\n",
       "          1411278580941300, 1411278584129300, 1411278589012290]]),\n",
       "  array([[1, 1, 1, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 0, 1, 0],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1398070600655990, 1398070604621660, 1398070626119870, ...,\n",
       "          1408062433479170, 1408062435821480, 1408062438477100],\n",
       "         [1395723670817050, 1395723678878780, 1395723681555210, ...,\n",
       "          1396933631841280, 1396933635450810, 1396933637524610],\n",
       "         [1401271336036160, 1401271373288320, 1401271390542100, ...,\n",
       "          1401358699534100, 1401358702274360, 1401358708909500],\n",
       "         ...,\n",
       "         [1397883661739060, 1397883665339300, 1397883670824890, ...,\n",
       "          1397884594058570, 1397884597502550, 1397884600904500],\n",
       "         [1417181390812080, 1417181397832810, 1417242943656930, ...,\n",
       "          1419683966217330, 1419683968802830, 1419683972735450],\n",
       "         [1394849722605370, 1394849727645580, 1394849734771000, ...,\n",
       "          1398949741076430, 1398949748646750, 1398949760799470]]),\n",
       "  array([[1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 0, 1, 1]])),\n",
       " (array([[1412757194514870, 1412757197330730, 1412757201392250, ...,\n",
       "          1412758862735030, 1412758865711600, 1412758868032550],\n",
       "         [1418109838002340, 1418109850875070, 1418109858360260, ...,\n",
       "          1420545999879420, 1420546003430280, 1420546010615390],\n",
       "         [1384576519464580, 1384576530592770, 1384576535827710, ...,\n",
       "          1384734453285130, 1384734458839320, 1384734466077400],\n",
       "         ...,\n",
       "         [1412931281659380, 1412931288544010, 1412931295679380, ...,\n",
       "          1413010817002470, 1413010820792730, 1413010825046120],\n",
       "         [1415082518773400, 1415082521604260, 1415082523874060, ...,\n",
       "          1415928809608870, 1415928813914640, 1415928815266870],\n",
       "         [1392105221892620, 1392105249267680, 1392105272077950, ...,\n",
       "          1401797921575710, 1401797923897290, 1401797926246910]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1395279836735840, 1395279938302690, 1395279989217190, ...,\n",
       "          1416891670762410, 1416891679996430, 1416891682820100],\n",
       "         [1420779334643850, 1420779338252520, 1420779346573680, ...,\n",
       "          1420794087789620, 1420794099362680, 1420794103430410],\n",
       "         [1397625953318350, 1397625986998610, 1397626001309300, ...,\n",
       "          1400649818648350, 1400649830376100, 1400649845383240],\n",
       "         ...,\n",
       "         [1378178883626700, 1378178901458850, 1378178935120350, ...,\n",
       "          1380251063773040, 1380251065915710, 1380251069820030],\n",
       "         [1395360416243740, 1395360426544490, 1395360441124790, ...,\n",
       "          1401703870067440, 1401703871780830, 1401703875098100],\n",
       "         [1396012130402450, 1396012195117670, 1396012202502870, ...,\n",
       "          1397568136315720, 1397568142616090, 1397568146575490]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 0, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1393892169779940, 1393906164532450, 1393906167923220, ...,\n",
       "          1394115503031800, 1394115507187010, 1394115508821170],\n",
       "         [1397445987428780, 1397445990734650, 1397445994292290, ...,\n",
       "          1401854117513720, 1401854120707000, 1401854123731020],\n",
       "         [1411039241727310, 1411039247458590, 1411039252903560, ...,\n",
       "          1412821508643530, 1412821513027940, 1412821517179400],\n",
       "         ...,\n",
       "         [1381475368902590, 1381475394173270, 1381475531638350, ...,\n",
       "          1404396811410880, 1404396820737220, 1404396827528130],\n",
       "         [1400565452163370, 1400565460704980, 1400565467571980, ...,\n",
       "          1402987647979860, 1402987653626580, 1402987657392830],\n",
       "         [1404182805987400, 1404182825487880, 1404182843491960, ...,\n",
       "          1404273318525100, 1404362439210810, 1404362447632610]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 1]])),\n",
       " (array([[1419575598941260, 1419575614209930, 1419575636498640, ...,\n",
       "          1419660934210530, 1419660944753270, 1419660958215490],\n",
       "         [1399442736686960, 1399442805226190, 1399442807022400, ...,\n",
       "          1401860221094980, 1401860223481900, 1401860227384180],\n",
       "         [1397015762724010, 1397015766399590, 1397015770234740, ...,\n",
       "          1398224848512060, 1398224851195540, 1398224859979870],\n",
       "         ...,\n",
       "         [1414590760580620, 1414590763867390, 1414590767065840, ...,\n",
       "          1416452412883090, 1416452415104660, 1416452417170200],\n",
       "         [1401265191350120, 1401265197438160, 1401265204615560, ...,\n",
       "          1401271524064990, 1401271536642070, 1401271540890100],\n",
       "         [1410933866475890, 1410933876174080, 1410933877144530, ...,\n",
       "          1412158100168280, 1412158104725870, 1412158343222760]]),\n",
       "  array([[1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1]])),\n",
       " (array([[1398926541151950, 1398926547639540, 1401950753094480, ...,\n",
       "          1402555420298960, 1402555424554720, 1402555428006510],\n",
       "         [1420700445566640, 1420700468301130, 1420700481983910, ...,\n",
       "          1420702305304250, 1420702308808080, 1420702319308200],\n",
       "         [1395629215195210, 1395629324555670, 1395629438165510, ...,\n",
       "          1400202497076580, 1400202499519180, 1400202501688890],\n",
       "         ...,\n",
       "         [1415693457406940, 1415693459007110, 1415693461629820, ...,\n",
       "          1416472286493880, 1416472288526110, 1416472290482580],\n",
       "         [1412957780106150, 1412957834165230, 1413041423501510, ...,\n",
       "          1414251518888640, 1414251532058770, 1414251561932490],\n",
       "         [1373590568408720, 1373590588639830, 1373590596837940, ...,\n",
       "          1385082083484290, 1385082100997300, 1385082120741840]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 0],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 0, ..., 1, 1, 0]])),\n",
       " (array([[1410076194954250, 1410076197842020, 1410076201333860, ...,\n",
       "          1410090705588870, 1410090717561540, 1410090724595260],\n",
       "         [1403099774002750, 1403099781822670, 1403099800276140, ...,\n",
       "          1407321665877730, 1407321676111940, 1407321679214580],\n",
       "         [1418298992217390, 1418299044987900, 1418299113894780, ...,\n",
       "          1418386480703140, 1418386485584080, 1418386493659260],\n",
       "         ...,\n",
       "         [1410437550143980, 1410437553413310, 1410437556473220, ...,\n",
       "          1415608011737510, 1415608015337250, 1415608018360660],\n",
       "         [1410758226321550, 1410758231450920, 1410758241463610, ...,\n",
       "          1413781170195580, 1413781174578850, 1413781179175540],\n",
       "         [1415712769480180, 1415712787453630, 1415712792523400, ...,\n",
       "          1416035318958930, 1416035321273670, 1416035323564360]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 0, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1415854038526810, 1415854048783340, 1415854061367820, ...,\n",
       "          1416459610100230, 1416459613766870, 1416459616570570],\n",
       "         [1416973371035310, 1416973423920190, 1416973624617000, ...,\n",
       "          1418893930013400, 1418893990804370, 1418894035880550],\n",
       "         [1399623574291910, 1399623577045050, 1399623579712220, ...,\n",
       "          1403254715503720, 1403254718796140, 1403254722806050],\n",
       "         ...,\n",
       "         [1411957652388270, 1411957656937880, 1411957660639530, ...,\n",
       "          1417064498802370, 1417064499987130, 1417064502551290],\n",
       "         [1398932795383100, 1398933015407810, 1398933080768320, ...,\n",
       "          1399356184955420, 1399356210244430, 1399356232886510],\n",
       "         [1389594870533960, 1389594875587310, 1389594878571810, ...,\n",
       "          1401083382988520, 1401083384718740, 1401083386839240]]),\n",
       "  array([[0, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0]])),\n",
       " (array([[1394085039731560, 1394085044883300, 1394085053403180, ...,\n",
       "          1418776656057090, 1418776673539590, 1418776871753020],\n",
       "         [1376313439467640, 1376313529657670, 1376313538785580, ...,\n",
       "          1376395457863880, 1376395467528610, 1376395475814340],\n",
       "         [1404446451988800, 1404446657501780, 1404446745541110, ...,\n",
       "          1405314928852940, 1405314936605700, 1405314943848070],\n",
       "         ...,\n",
       "         [1393228210333920, 1393228235253510, 1393228273249370, ...,\n",
       "          1396424550828820, 1396424556452930, 1396424978684630],\n",
       "         [1396407328444770, 1396407342810930, 1396407353903740, ...,\n",
       "          1398241893636430, 1398241901329970, 1398241914948860],\n",
       "         [1403175763021540, 1403175789691970, 1418200205423260, ...,\n",
       "          1418896996359660, 1418896998248220, 1418897000539720]]),\n",
       "  array([[1, 1, 1, ..., 1, 0, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1]])),\n",
       " (array([[1387260158707640, 1387260178732660, 1389185986265160, ...,\n",
       "          1389274313668910, 1389274317157990, 1389274320965010],\n",
       "         [1413260778605620, 1413284804064440, 1413284807461590, ...,\n",
       "          1413381236874090, 1413381241219820, 1413381246406160],\n",
       "         [1409884635821090, 1409884638306830, 1409884643041430, ...,\n",
       "          1412307591175530, 1412307594633010, 1412307598731120],\n",
       "         ...,\n",
       "         [1386720595472900, 1386720653772820, 1386720724422740, ...,\n",
       "          1395755143572300, 1395755166111080, 1395755172803650],\n",
       "         [1414399365023850, 1414399387964150, 1414399415926820, ...,\n",
       "          1416903665161320, 1416903680748950, 1416903691984640],\n",
       "         [1394616452139160, 1394616459107820, 1394616468996150, ...,\n",
       "          1414066881819000, 1414066884034610, 1414066892155190]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1417157038922090, 1417157047216190, 1417157059187760, ...,\n",
       "          1417785620553130, 1417785631191050, 1417785635488720],\n",
       "         [1392867598001270, 1392867602361000, 1392867606351860, ...,\n",
       "          1397198523443720, 1397198525688680, 1397198528526890],\n",
       "         [1414932015441350, 1414932019752390, 1414932023005840, ...,\n",
       "          1417266869821980, 1417266872522790, 1417266874776610],\n",
       "         ...,\n",
       "         [1385617545001660, 1385617568230560, 1385617589635080, ...,\n",
       "          1398922884695930, 1398922888068600, 1398922891007890],\n",
       "         [1380524520933050, 1380524544871960, 1380524554889070, ...,\n",
       "          1380531774251760, 1380531781805100, 1380531789655400],\n",
       "         [1389678648451710, 1389678664971160, 1389678670567300, ...,\n",
       "          1390270500844090, 1390270503388290, 1390270505316590]]),\n",
       "  array([[1, 0, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1386340328972140, 1386340406703060, 1386340614372700, ...,\n",
       "          1396277607374000, 1396277633421720, 1396277655347350],\n",
       "         [1395056468930260, 1395056492024220, 1395056510047890, ...,\n",
       "          1405935215556970, 1405935302731610, 1406968291501250],\n",
       "         [1400500116664400, 1400500138232140, 1400500226883460, ...,\n",
       "          1401193121622720, 1401193134358520, 1401193138269530],\n",
       "         ...,\n",
       "         [1380848550118610, 1380848582234920, 1380848597432280, ...,\n",
       "          1410445763340160, 1410445776145090, 1410445779403520],\n",
       "         [1396501207402770, 1405561427447220, 1405561433355410, ...,\n",
       "          1415671324283560, 1415671329591200, 1415671334068540],\n",
       "         [1411101694930720, 1411101702886450, 1411101705401240, ...,\n",
       "          1413263604622150, 1413263607155810, 1413263610807940]]),\n",
       "  array([[1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1392601353748650, 1392601556441560, 1392601891836800, ...,\n",
       "          1397117808056090, 1397117861636820, 1397117880859320],\n",
       "         [1392372820354660, 1392372911727470, 1392630497580260, ...,\n",
       "          1395723610415220, 1398042456931240, 1398042526892750],\n",
       "         [1396424679080750, 1396424683402640, 1396424685284740, ...,\n",
       "          1400053394056210, 1400053399144230, 1400053402272490],\n",
       "         ...,\n",
       "         [1410250517355250, 1412065565030750, 1412065588754800, ...,\n",
       "          1414485519977710, 1414485522196280, 1414485525177580],\n",
       "         [1374661840083390, 1374661847530280, 1374661860535160, ...,\n",
       "          1387889861392610, 1387889878186210, 1387889897810340],\n",
       "         [1413955985397310, 1413956002710110, 1413956012888630, ...,\n",
       "          1416532393568600, 1416532396397460, 1416532400088190]]),\n",
       "  array([[0, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1414804844190430, 1414804846862110, 1414804850219500, ...,\n",
       "          1415085601508200, 1415085603135480, 1415085605388980],\n",
       "         [1396237113063920, 1396237125224220, 1396237132835500, ...,\n",
       "          1410772577925640, 1410772582132590, 1410772586342600],\n",
       "         [1409729247785260, 1409729265100440, 1409729275072700, ...,\n",
       "          1412144175966460, 1412144178251030, 1412144183133470],\n",
       "         ...,\n",
       "         [1418973378214660, 1418973401236930, 1418973410481480, ...,\n",
       "          1420689378415560, 1420689383085580, 1420689391977480],\n",
       "         [1402907440240330, 1402907459410760, 1402907812490960, ...,\n",
       "          1402912339453740, 1402912344401660, 1402912354919070],\n",
       "         [1398039998024970, 1398040002542390, 1398040005366850, ...,\n",
       "          1400113926717480, 1400113928687800, 1400113930801100]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0]])),\n",
       " (array([[1400221967991130, 1400222236389960, 1400222514758920, ...,\n",
       "          1400245658688280, 1400245682352460, 1400245687716630],\n",
       "         [1395457470344480, 1395457473729250, 1395457482847310, ...,\n",
       "          1401335574504100, 1401335577503710, 1401335582011750],\n",
       "         [1400123849908840, 1400123851599350, 1400123855286400, ...,\n",
       "          1412642396417410, 1412642400229310, 1412642403593280],\n",
       "         ...,\n",
       "         [1403574917916930, 1403574921261320, 1403574925613270, ...,\n",
       "          1404788420105220, 1404788422611260, 1404788433429700],\n",
       "         [1379939525052790, 1379939544019500, 1379939550176080, ...,\n",
       "          1415621148152050, 1415621151216430, 1415621153365740],\n",
       "         [1396531790435370, 1396531800030500, 1396531807220720, ...,\n",
       "          1399428913483390, 1399428924350510, 1399428929632740]]),\n",
       "  array([[1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 0],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1]])),\n",
       " (array([[1378704410329840, 1378705023779240, 1378705036374700, ...,\n",
       "          1379991282569230, 1379991286657430, 1379991294647620],\n",
       "         [1414938098773290, 1414938109549820, 1414938124983020, ...,\n",
       "          1414939969852820, 1414939982188010, 1414939996957420],\n",
       "         [1415796300200920, 1415796307136650, 1415796311964920, ...,\n",
       "          1415968652358840, 1415968653847990, 1415968656183560],\n",
       "         ...,\n",
       "         [1394349431795930, 1394349443480460, 1394349448613820, ...,\n",
       "          1394442997854500, 1394443003956430, 1394443009659160],\n",
       "         [1418289935410590, 1418289938469720, 1418289945423870, ...,\n",
       "          1418805458155900, 1418805460501030, 1418805462315030],\n",
       "         [1416963016997450, 1416963026803630, 1416963098999830, ...,\n",
       "          1419906344862420, 1419906365285520, 1419906368859290]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1]])),\n",
       " (array([[1417150638811870, 1417150658338720, 1417151249237650, ...,\n",
       "          1417669081612280, 1417669086584070, 1417669088992010],\n",
       "         [1420109092267190, 1420109097784680, 1420109102280100, ...,\n",
       "          1420609755639970, 1420801315420390, 1420801320014430],\n",
       "         [1399454768837710, 1399454774263360, 1399454779045780, ...,\n",
       "          1417772003033140, 1417772007077660, 1417772213313540],\n",
       "         ...,\n",
       "         [1415339141473840, 1415339292022590, 1415339296360940, ...,\n",
       "          1418363425320610, 1418363427648960, 1418363429739570],\n",
       "         [1401615887933130, 1401615898506300, 1401615901776140, ...,\n",
       "          1401618225179720, 1401618229699150, 1401618234491540],\n",
       "         [1411540147190000, 1411540150189980, 1411540153533220, ...,\n",
       "          1415768277244390, 1415768278231060, 1415768279337960]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 0]])),\n",
       " (array([[1405558135482570, 1405558160498320, 1405558168107840, ...,\n",
       "          1406337345338030, 1406337359841660, 1406337367143290],\n",
       "         [1377673644244360, 1377673726587860, 1378123610354290, ...,\n",
       "          1390489233067120, 1390489309827310, 1390489334490930],\n",
       "         [1398771665121260, 1398771675071600, 1398771693903160, ...,\n",
       "          1415017437786980, 1415017442832300, 1415017447447860],\n",
       "         ...,\n",
       "         [1396357351400440, 1396357355829940, 1396357358891810, ...,\n",
       "          1398684546555080, 1398684549961860, 1398684551202310],\n",
       "         [1393892017034770, 1393892031193740, 1393892080329370, ...,\n",
       "          1394116691083740, 1394116692807120, 1394116695084760],\n",
       "         [1404263501633090, 1404263507908610, 1404263514420500, ...,\n",
       "          1404437191390050, 1404437213442420, 1404437233177020]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 0, 1, 1]])),\n",
       " (array([[1413175883243740, 1413175894349110, 1413175942965400, ...,\n",
       "          1415596303044550, 1415596310802500, 1416287327349910],\n",
       "         [1391513743710270, 1391513749024230, 1391513753832910, ...,\n",
       "          1391517786988520, 1391517788661990, 1391560952959710],\n",
       "         [1395034708592030, 1397047040749660, 1397047246240240, ...,\n",
       "          1397292693535580, 1397292700992460, 1397292719618480],\n",
       "         ...,\n",
       "         [1394077085467270, 1394077090352990, 1394077097789090, ...,\n",
       "          1394506760503820, 1394794838555120, 1394794840057370],\n",
       "         [1415973446077240, 1415973452326590, 1415973522340140, ...,\n",
       "          1416062601099540, 1416062606141540, 1416062609532110],\n",
       "         [1412513069523430, 1412513075022160, 1412513077694230, ...,\n",
       "          1412687383599530, 1412687386478330, 1412687391366810]]),\n",
       "  array([[1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1376315891986060, 1376399357027330, 1376401368200600, ...,\n",
       "          1378990746182310, 1378990749364310, 1378990753956800],\n",
       "         [1398156591165390, 1398156637655680, 1398156682829690, ...,\n",
       "          1398860814978110, 1398860831737010, 1398860849083520],\n",
       "         [1405651548210670, 1405651963382060, 1405651979733350, ...,\n",
       "          1406257054756780, 1406257058704960, 1406257066975090],\n",
       "         ...,\n",
       "         [1384399766027600, 1384399800393420, 1384399865115180, ...,\n",
       "          1389787519509840, 1389787524673050, 1389787530417030],\n",
       "         [1384776743396870, 1384776749624180, 1384776763985430, ...,\n",
       "          1386476896027430, 1386476903952430, 1386476908554890],\n",
       "         [1417392762341020, 1417392784966320, 1417392799924730, ...,\n",
       "          1418299386191330, 1418299394614750, 1418299404144770]]),\n",
       "  array([[1, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1382519573841500, 1382519606027070, 1395498488672220, ...,\n",
       "          1395925954079410, 1395925958121530, 1395925960847190],\n",
       "         [1416472591572160, 1416472598235860, 1416472605201950, ...,\n",
       "          1416473952994180, 1416473957192220, 1416473961839520],\n",
       "         [1417073525250460, 1417073528861590, 1417073532132070, ...,\n",
       "          1419483581825940, 1419483585826750, 1419483588891690],\n",
       "         ...,\n",
       "         [1405492681188680, 1405492685089170, 1405492689996050, ...,\n",
       "          1405669959511890, 1405669963108100, 1405669964798590],\n",
       "         [1406718344773810, 1406718368883150, 1406718387503870, ...,\n",
       "          1406721581257120, 1406721599105940, 1406721610782220],\n",
       "         [1399621199772840, 1399621201511020, 1399621204655800, ...,\n",
       "          1403857016379440, 1403857019538740, 1403857022931290]]),\n",
       "  array([[1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 0]])),\n",
       " (array([[1387249106503340, 1387249109762450, 1387249113613630, ...,\n",
       "          1387455158387970, 1387455165295620, 1387455170486680],\n",
       "         [1391571185114900, 1391571263836850, 1391571295563040, ...,\n",
       "          1403429980081920, 1403429985847800, 1403441602081050],\n",
       "         [1413851508584070, 1413851528474140, 1413851793998870, ...,\n",
       "          1413945065197110, 1413945067860640, 1413945070498320],\n",
       "         ...,\n",
       "         [1417698810775490, 1417699016551310, 1417699038938750, ...,\n",
       "          1418187918637530, 1418187922431460, 1418187928924870],\n",
       "         [1394592133090770, 1394592150593350, 1394673426295490, ...,\n",
       "          1398302846601700, 1398302852038420, 1398302858332430],\n",
       "         [1417059578351440, 1417059586524360, 1418301795988620, ...,\n",
       "          1418972458236790, 1418972461350510, 1418972464912360]]),\n",
       "  array([[1, 1, 1, ..., 0, 0, 1],\n",
       "         [0, 0, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         [0, 0, 0, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1382430006270030, 1382430028162210, 1382430038979810, ...,\n",
       "          1400230388720780, 1400230392616360, 1400230395552170],\n",
       "         [1419557900264300, 1419557906014640, 1419557909747270, ...,\n",
       "          1420099127621590, 1420099131087610, 1420099136866290],\n",
       "         [1380114744614750, 1380114759700920, 1380114775111660, ...,\n",
       "          1383649884498820, 1383649889662190, 1383649891818350],\n",
       "         ...,\n",
       "         [1398922420202110, 1398922422286000, 1398922424601100, ...,\n",
       "          1400131886022490, 1400131888049750, 1400131890481220],\n",
       "         [1415590153083430, 1415590168981990, 1415590346948630, ...,\n",
       "          1418009263394410, 1418009266070120, 1418009269427230],\n",
       "         [1395718741906190, 1395718747228090, 1395718759159510, ...,\n",
       "          1411287512860990, 1411287515169940, 1411287517124780]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1396423905755620, 1396423920294730, 1396423928512730, ...,\n",
       "          1401867163156010, 1401867165235220, 1401867167337090],\n",
       "         [1412344535550680, 1412602504575630, 1412602519362060, ...,\n",
       "          1419515561498680, 1419515571169950, 1419515577292670],\n",
       "         [1386810417960020, 1386810420577120, 1386810423597100, ...,\n",
       "          1390278643888640, 1390278645741970, 1390278649996450],\n",
       "         ...,\n",
       "         [1401930016676960, 1401930038084740, 1401930044012800, ...,\n",
       "          1402322037588810, 1402322052575270, 1402322083755750],\n",
       "         [1411967014019550, 1411967024182590, 1411967031933110, ...,\n",
       "          1420693133433810, 1420693139412660, 1420693143100940],\n",
       "         [1419236456034940, 1419236460797600, 1419236467845870, ...,\n",
       "          1419237609402750, 1419237613133990, 1419237618832960]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 0],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 0, 0]])),\n",
       " (array([[1416214233539200, 1416214252248840, 1416299178194940, ...,\n",
       "          1416818665028310, 1416818673196210, 1416818677081650],\n",
       "         [1419337570833810, 1419337575936810, 1419337580472730, ...,\n",
       "          1419685664711040, 1419685667380780, 1419685676968860],\n",
       "         [1414721297777260, 1414721302339080, 1414721306873830, ...,\n",
       "          1417139226581520, 1417139228820320, 1417139231854200],\n",
       "         ...,\n",
       "         [1395738680836070, 1395738712557220, 1395738719483080, ...,\n",
       "          1396414421489070, 1396414431200560, 1396414442989430],\n",
       "         [1400950534330110, 1400950544958080, 1400950557486890, ...,\n",
       "          1401461540085990, 1401461542822670, 1401461548267220],\n",
       "         [1412749393538420, 1412749395767770, 1412749398667080, ...,\n",
       "          1416994424959960, 1416994426999260, 1416994429118080]]),\n",
       "  array([[1, 0, 0, ..., 0, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1407741436553450, 1407741640400610, 1407741736940950, ...,\n",
       "          1417937443187060, 1417937455375210, 1417937462062010],\n",
       "         [1389663523881430, 1389663530400640, 1389663545541900, ...,\n",
       "          1416191706061230, 1416191711428870, 1416191717406340],\n",
       "         [1381286733755650, 1381286739967510, 1381286757511580, ...,\n",
       "          1382334482591390, 1382334496357320, 1382334529755200],\n",
       "         ...,\n",
       "         [1392176259078280, 1392176267410160, 1392176299475480, ...,\n",
       "          1398225117402660, 1398225118146060, 1398225125314190],\n",
       "         [1407287740608040, 1407287822390040, 1407287860145900, ...,\n",
       "          1407290683715550, 1407290686051170, 1407290688587580],\n",
       "         [1391839874407230, 1391839879829770, 1391840221482890, ...,\n",
       "          1405408066181920, 1405408090533060, 1405408093092720]]),\n",
       "  array([[0, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 0, 0, ..., 0, 0, 1],\n",
       "         [1, 0, 0, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1362714176564460, 1362714186515740, 1363315930265540, ...,\n",
       "          1368427074483540, 1368427076532120, 1368427081259700],\n",
       "         [1390357834195000, 1390357839670560, 1390357846720750, ...,\n",
       "          1390478021846540, 1390478261631320, 1390478263425360],\n",
       "         [1400712594739490, 1400712672820920, 1402382038017960, ...,\n",
       "          1403750720081840, 1403750725308540, 1403750738450960],\n",
       "         ...,\n",
       "         [1414677921424010, 1414677931586250, 1414677940423800, ...,\n",
       "          1419777109447660, 1419777125078870, 1419777141382750],\n",
       "         [1403573978654850, 1403573986704260, 1403573992820800, ...,\n",
       "          1405057417953890, 1405057420214300, 1405057422579650],\n",
       "         [1411472768891810, 1411472773257480, 1411472779431430, ...,\n",
       "          1411565757581300, 1411565761215870, 1411565764186820]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1]])),\n",
       " (array([[1417154372248810, 1417154381660940, 1417154387515240, ...,\n",
       "          1420635417833540, 1420635422736060, 1420635428909380],\n",
       "         [1415248095735550, 1415248104432780, 1415248123257240, ...,\n",
       "          1416458714372150, 1416458717683700, 1416458724707860],\n",
       "         [1389843819092480, 1389843821766620, 1389843824102720, ...,\n",
       "          1393378065380300, 1393378067797350, 1393378076826730],\n",
       "         ...,\n",
       "         [1410616266136920, 1410616285235420, 1410616314602260, ...,\n",
       "          1410935657973820, 1410935660280190, 1410935666294550],\n",
       "         [1394622288196470, 1394622302943830, 1394622306064470, ...,\n",
       "          1395396776985450, 1395396781572970, 1395396784446310],\n",
       "         [1414201918524750, 1414202012535970, 1418118309641410, ...,\n",
       "          1418119256359220, 1418119259140080, 1418119263037530]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1393479495913980, 1393479523408090, 1393479533917200, ...,\n",
       "          1400629932303260, 1400629935846620, 1400629938800050],\n",
       "         [1418100122060790, 1418100198170810, 1418100201989360, ...,\n",
       "          1418618878464230, 1418618884561430, 1418618888852090],\n",
       "         [1414657171658090, 1414657177072240, 1414657183229310, ...,\n",
       "          1414730125768750, 1414730128290960, 1414730130067940],\n",
       "         ...,\n",
       "         [1401427149118590, 1401427153198970, 1401427158448380, ...,\n",
       "          1402032056874760, 1402032066574590, 1402032069387240],\n",
       "         [1413552930369710, 1413552951780890, 1413552963579580, ...,\n",
       "          1417139195888520, 1417139200334840, 1417139204382460],\n",
       "         [1404171939429830, 1404171953891740, 1404171968234830, ...,\n",
       "          1404432441777340, 1404432447593960, 1404432465267430]]),\n",
       "  array([[1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1393915408060270, 1393915416284060, 1393915420971320, ...,\n",
       "          1416375186652740, 1416375190270320, 1416375194230190],\n",
       "         [1418642255818620, 1418642291901170, 1418642328542160, ...,\n",
       "          1420457946693040, 1420457956749420, 1420457967315930],\n",
       "         [1400649141662390, 1400649292837090, 1400649572591160, ...,\n",
       "          1403157855152600, 1403157861482080, 1403157906106870],\n",
       "         ...,\n",
       "         [1412833963970020, 1412833969218100, 1412833977100760, ...,\n",
       "          1416100792267700, 1416100796301980, 1416100800591730],\n",
       "         [1392692388815390, 1392692394712680, 1392867019042860, ...,\n",
       "          1402305115659870, 1402305126740230, 1402305133782360],\n",
       "         [1409795992739540, 1409795997447030, 1409796003181750, ...,\n",
       "          1418880088392070, 1418880092046180, 1418880094995240]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1403840205345000, 1403840229387360, 1403840257497940, ...,\n",
       "          1404788448959190, 1404886811077660, 1404886814379740],\n",
       "         [1382425100939450, 1382425121022790, 1384418169086660, ...,\n",
       "          1399963628047360, 1399963639411790, 1399963653728090],\n",
       "         [1417789044252180, 1417789049348210, 1417789053890800, ...,\n",
       "          1419250336086420, 1419250338153880, 1419250340784750],\n",
       "         ...,\n",
       "         [1385535596087280, 1385535615936470, 1385535631169970, ...,\n",
       "          1385537352679640, 1385537361176220, 1385537364182740],\n",
       "         [1395982424798850, 1395982461569170, 1395982485635790, ...,\n",
       "          1395983907832710, 1395983912611660, 1395983919935680],\n",
       "         [1382533306189310, 1382533309535330, 1382533311541560, ...,\n",
       "          1389102082924460, 1389102090837580, 1389102094874040]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 0, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1384688444385280, 1384688464841840, 1384688471020360, ...,\n",
       "          1384690311369780, 1384690318514320, 1384690324828050],\n",
       "         [1409818578585570, 1409818582868500, 1409818589527830, ...,\n",
       "          1410423843531130, 1410423845992310, 1410423848320350],\n",
       "         [1420799159471740, 1420799162554140, 1420799166150600, ...,\n",
       "          1420800017864830, 1420800019757330, 1420800023109870],\n",
       "         ...,\n",
       "         [1416279611526180, 1416279617772180, 1416279622671930, ...,\n",
       "          1416537794236270, 1416537797730290, 1416537802669950],\n",
       "         [1400032917817390, 1400032945248840, 1400032949669360, ...,\n",
       "          1401155312993230, 1401155316068240, 1401155318428980],\n",
       "         [1397439460155820, 1397439482060530, 1397439494933540, ...,\n",
       "          1397545226942660, 1397545229402480, 1397545238078200]]),\n",
       "  array([[1, 1, 1, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 0, 0, 0],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1395382472231310, 1395382476465430, 1395382480287370, ...,\n",
       "          1401281710088620, 1401281730624230, 1401281733724440],\n",
       "         [1402555381295210, 1402555388420170, 1402555403354360, ...,\n",
       "          1412239248051740, 1412239253174090, 1412239256711000],\n",
       "         [1417678118865280, 1417678166786290, 1417678188470980, ...,\n",
       "          1417767130121060, 1417767137829850, 1417767147968280],\n",
       "         ...,\n",
       "         [1420197084539370, 1420197105729650, 1420197838620950, ...,\n",
       "          1420959540523900, 1420959543763690, 1420959548100200],\n",
       "         [1387961034103340, 1387961037420220, 1387961049714380, ...,\n",
       "          1389773857713470, 1389773860811870, 1389773865489490],\n",
       "         [1393480399568980, 1393480417451110, 1393480486154610, ...,\n",
       "          1397789116858920, 1397789119540130, 1397789121849490]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1389435931966140, 1389435938610450, 1389435941670200, ...,\n",
       "          1389532439684450, 1389532441937300, 1389532444301420],\n",
       "         [1399872067886380, 1400477133163540, 1400477148425160, ...,\n",
       "          1401081984885990, 1401081993564300, 1401081997730120],\n",
       "         [1382533125927800, 1382533129301190, 1382533132838130, ...,\n",
       "          1389102653671150, 1389102655496980, 1389102658260710],\n",
       "         ...,\n",
       "         [1411029928531120, 1411029940212140, 1411029952406180, ...,\n",
       "          1414053421946690, 1414053433670740, 1414053439541540],\n",
       "         [1414041396843060, 1414041405992320, 1414041410690200, ...,\n",
       "          1414990292961380, 1414990304871960, 1414990307517220],\n",
       "         [1420586999980760, 1420587025045770, 1420587038829620, ...,\n",
       "          1420763891932870, 1420763895292570, 1420763906468020]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1]])),\n",
       " (array([[1394104903613990, 1394104930726620, 1394104935289500, ...,\n",
       "          1395794114773610, 1395794120215570, 1395794125973300],\n",
       "         [1402013646489810, 1402013695248160, 1402013698983190, ...,\n",
       "          1403659840286080, 1403659843068130, 1403659845469700],\n",
       "         [1407593590793560, 1407593605475190, 1407593619107600, ...,\n",
       "          1407737606021340, 1407737621194210, 1407737629042840],\n",
       "         ...,\n",
       "         [1409729218769140, 1409729226908070, 1409729236875870, ...,\n",
       "          1412145723803390, 1412145731988760, 1412145739259590],\n",
       "         [1400826650871900, 1400826654728890, 1400826658677390, ...,\n",
       "          1401432572460270, 1401432577910250, 1401432581094410],\n",
       "         [1413521975602120, 1413521976603390, 1413521980640860, ...,\n",
       "          1414369801202280, 1414369806499320, 1414369814870730]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 0, ..., 0, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1]])),\n",
       " (array([[1417072727181950, 1417072740035980, 1417072752449030, ...,\n",
       "          1420696170024120, 1420696179001990, 1420696182721440],\n",
       "         [1415858517462430, 1415858518691940, 1415858520226140, ...,\n",
       "          1419320952525260, 1419320955134820, 1419320956709920],\n",
       "         [1415608863598820, 1415608916599440, 1415609018091970, ...,\n",
       "          1418273789775420, 1418273791877490, 1418273794774970],\n",
       "         ...,\n",
       "         [1384158067667420, 1384158104928720, 1384417626486770, ...,\n",
       "          1388477528489700, 1388477536550250, 1388477565568990],\n",
       "         [1416302109383240, 1416302115169570, 1416302120840100, ...,\n",
       "          1417158203746290, 1417158205814620, 1417158207688490],\n",
       "         [1394603230173280, 1394603452346160, 1394603560814160, ...,\n",
       "          1397627394159340, 1397627406100460, 1397627409335980]]),\n",
       "  array([[0, 0, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 1, 1]])),\n",
       " (array([[1391685385669260, 1391685524291580, 1391685637426970, ...,\n",
       "          1411556028774730, 1411556063204260, 1411556099977000],\n",
       "         [1400748318795890, 1400748322682080, 1400748325000470, ...,\n",
       "          1402023266028140, 1402023267868010, 1402023271539610],\n",
       "         [1415328265746150, 1415328272356660, 1415328280200310, ...,\n",
       "          1415933976495890, 1415933979549880, 1415933983740680],\n",
       "         ...,\n",
       "         [1390353494053740, 1390353612370020, 1390353635197890, ...,\n",
       "          1412845484376760, 1412845489708940, 1412845493709560],\n",
       "         [1395889996432550, 1395890006006800, 1395890014651640, ...,\n",
       "          1401264855657020, 1401264859347920, 1401264905551530],\n",
       "         [1417440858152320, 1417440934939340, 1417444320672300, ...,\n",
       "          1418041798279450, 1418041813974050, 1418041832967920]]),\n",
       "  array([[0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 0],\n",
       "         [0, 0, 0, ..., 1, 0, 1]])),\n",
       " (array([[1384231786614500, 1384231796644290, 1384231804938390, ...,\n",
       "          1386039093541290, 1386039100405630, 1386039106776110],\n",
       "         [1414397923675980, 1414397927871540, 1414397930376190, ...,\n",
       "          1415865308494420, 1415865320364840, 1415865333935540],\n",
       "         [1400221219789700, 1400221247564510, 1400221543051830, ...,\n",
       "          1400222963718750, 1400222965712870, 1400222968341550],\n",
       "         ...,\n",
       "         [1393418359043360, 1393418367946090, 1393418376161150, ...,\n",
       "          1393422123040490, 1393422152511670, 1393422157901830],\n",
       "         [1394087701753780, 1394087715977850, 1394087729307810, ...,\n",
       "          1394793767066550, 1394793770271990, 1394793775952260],\n",
       "         [1413196891559060, 1413196894662330, 1413196897184450, ...,\n",
       "          1419222983799340, 1419222985747990, 1419222987915800]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1389938409039810, 1389938424277160, 1389938486902410, ...,\n",
       "          1405521703091000, 1405521712379590, 1405521714932370],\n",
       "         [1412842850271400, 1412842869300900, 1412842888136690, ...,\n",
       "          1413024542836020, 1413024551712920, 1413024566611690],\n",
       "         [1409743740138880, 1409743756024200, 1410260401988290, ...,\n",
       "          1411687986299050, 1411687990639420, 1411687994295370],\n",
       "         ...,\n",
       "         [1418874161750680, 1418874166880950, 1418874170804100, ...,\n",
       "          1419905501325360, 1419905504081570, 1419905506944240],\n",
       "         [1410874443534960, 1410874447447370, 1410874454819520, ...,\n",
       "          1419415512745520, 1419415514585950, 1419415516320150],\n",
       "         [1418101794318080, 1418101826855130, 1418101877692910, ...,\n",
       "          1418706935863220, 1418706947721180, 1418706965453200]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 0]])),\n",
       " (array([[1398069051947970, 1398069138568720, 1398069174225600, ...,\n",
       "          1398761475234040, 1398761499115890, 1398761533438230],\n",
       "         [1411536950968230, 1411536968282170, 1411536977870670, ...,\n",
       "          1411540128052890, 1411540132173880, 1411540135584430],\n",
       "         [1386663658365850, 1386663668595630, 1386663706083350, ...,\n",
       "          1387441496905420, 1387441512038610, 1387441518482540],\n",
       "         ...,\n",
       "         [1414380946991040, 1414380950234480, 1414380955407160, ...,\n",
       "          1417403917450260, 1417403920659700, 1417403922839520],\n",
       "         [1395995237965550, 1395995248217550, 1395995287039440, ...,\n",
       "          1398390468283150, 1398390475310400, 1398390477831060],\n",
       "         [1389448194354200, 1389448227356510, 1389448255111780, ...,\n",
       "          1389923596463990, 1389923604987290, 1389923610299990]]),\n",
       "  array([[0, 0, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 1]])),\n",
       " (array([[1368061491382370, 1368061496385790, 1368061565157480, ...,\n",
       "          1368239307651300, 1368239322628470, 1368239325819710],\n",
       "         [1400830850830680, 1400830856378760, 1400830862285710, ...,\n",
       "          1415580063561620, 1415580066838580, 1415607072759970],\n",
       "         [1414486208055660, 1414734811185550, 1414734814568490, ...,\n",
       "          1414993470390810, 1414993472651560, 1414993475773640],\n",
       "         ...,\n",
       "         [1384336499591230, 1384336520911480, 1384336534147830, ...,\n",
       "          1384424507859760, 1384424510686030, 1384424513876650],\n",
       "         [1378868517151820, 1378868520055950, 1378868524088610, ...,\n",
       "          1393031956390520, 1393031958697450, 1393031961258270],\n",
       "         [1376708377831020, 1376708387148870, 1376708394365040, ...,\n",
       "          1405314776438080, 1405314781127730, 1405314787033970]]),\n",
       "  array([[1, 0, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1]])),\n",
       " (array([[1400134560339600, 1400134574852120, 1400134621168730, ...,\n",
       "          1402384129307490, 1402384133331540, 1402384137770290],\n",
       "         [1413455627114340, 1413455649123850, 1413455693895200, ...,\n",
       "          1414840299682420, 1414840309645110, 1414904122605030],\n",
       "         [1395302754945560, 1395302779364280, 1395302795783000, ...,\n",
       "          1403163028754710, 1403163030955890, 1403163033301090],\n",
       "         ...,\n",
       "         [1407115894224590, 1407115917038040, 1407116037413870, ...,\n",
       "          1411640474737890, 1411640484132160, 1411640493294290],\n",
       "         [1395054684022450, 1395054711429200, 1395054716225420, ...,\n",
       "          1400502819616220, 1400502825605330, 1400502831209190],\n",
       "         [1406700934197910, 1406700943128250, 1406700954397030, ...,\n",
       "          1407976178900910, 1407976182448970, 1407976195689280]]),\n",
       "  array([[1, 1, 0, ..., 1, 0, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1]])),\n",
       " (array([[1401421379391640, 1401421383908980, 1401421395074480, ...,\n",
       "          1403252171957670, 1403252173898970, 1403252193784190],\n",
       "         [1378342007515300, 1378947446475660, 1384829127741290, ...,\n",
       "          1395639553805400, 1395639581802670, 1395639591610960],\n",
       "         [1416472167658930, 1416472197956130, 1416472219409580, ...,\n",
       "          1417077601785040, 1417077621382530, 1417077658899970],\n",
       "         ...,\n",
       "         [1377435143082920, 1377435147984220, 1377435148854460, ...,\n",
       "          1377499385967060, 1377499387997890, 1377499389935890],\n",
       "         [1395624029398840, 1395624039628130, 1395624045555270, ...,\n",
       "          1400053166868640, 1400053182352560, 1400053192423130],\n",
       "         [1416287855913220, 1416287858663570, 1416287860711870, ...,\n",
       "          1417669174805580, 1417669176991120, 1417669178979350]]),\n",
       "  array([[1, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0]])),\n",
       " (array([[1400492217826530, 1400492354831060, 1400492407181180, ...,\n",
       "          1418894216002760, 1418894422459310, 1418894492628520],\n",
       "         [1393915271367650, 1393915273988880, 1393915274841230, ...,\n",
       "          1393935989601920, 1393935997823900, 1393936006621620],\n",
       "         [1412321704460680, 1412321708926900, 1412321712212920, ...,\n",
       "          1415345619557780, 1415345621968780, 1415345625532740],\n",
       "         ...,\n",
       "         [1407287680714900, 1407287704005490, 1407288481447340, ...,\n",
       "          1407462309163860, 1407462314782070, 1407462319749900],\n",
       "         [1400132789514320, 1400132805627340, 1400132821525350, ...,\n",
       "          1404185597824680, 1404185670085500, 1404185674927730],\n",
       "         [1408332008812730, 1408332061090400, 1408332073545290, ...,\n",
       "          1408585594225200, 1408585610237500, 1408585627205670]]),\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 0, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 1]])),\n",
       " (array([[1400573031194310, 1400573041728600, 1400573049978140, ...,\n",
       "          1400574426155840, 1400574429889970, 1400574434476980],\n",
       "         [1414761978691530, 1414761983625820, 1414761988822170, ...,\n",
       "          1414847753909150, 1414847757094200, 1414847760767940],\n",
       "         [1393302667036450, 1394155496820190, 1394504600550890, ...,\n",
       "          1402974997416690, 1402974999886090, 1402975004017500],\n",
       "         ...,\n",
       "         [1389851270423440, 1389851316398770, 1389851321271120, ...,\n",
       "          1392782246050000, 1392782248769450, 1392782257367940],\n",
       "         [1393032796036740, 1393033041914450, 1393033128612090, ...,\n",
       "          1393331712534700, 1393331714688590, 1393331716658520],\n",
       "         [1412317925227240, 1412317937322310, 1412317965079180, ...,\n",
       "          1415678138610690, 1415678144210270, 1415678149724330]]),\n",
       "  array([[0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1415261473029200, 1415261535576760, 1415261541188640, ...,\n",
       "          1416557867930260, 1416557871650050, 1416557876413670],\n",
       "         [1378865495360080, 1378865500077070, 1378865505537650, ...,\n",
       "          1379990013620890, 1379990020306650, 1379990023566540],\n",
       "         [1412430555818230, 1412430565069390, 1412430575881380, ...,\n",
       "          1416750212555150, 1416750227660350, 1416750234324810],\n",
       "         ...,\n",
       "         [1414925726809190, 1414930480923300, 1414930519571320, ...,\n",
       "          1414940429039230, 1414940433191390, 1414940440607680],\n",
       "         [1420031840664360, 1420031860088740, 1420031884998430, ...,\n",
       "          1420359632618100, 1420359639673280, 1420359647772370],\n",
       "         [1389837895484590, 1389837908506320, 1389838017661690, ...,\n",
       "          1406884064718910, 1413422100011170, 1413422126547420]]),\n",
       "  array([[0, 1, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1396503720579450, 1396503728284920, 1396503730940700, ...,\n",
       "          1401774478549650, 1401774479228920, 1401946740661930],\n",
       "         [1389787712190830, 1389787715741550, 1389787719140900, ...,\n",
       "          1394513553058880, 1394513556115160, 1394513559663490],\n",
       "         [1400228597578820, 1400228620772020, 1400229727757630, ...,\n",
       "          1401439195083700, 1401439203284350, 1401439206990890],\n",
       "         ...,\n",
       "         [1419497146197410, 1419497153100880, 1419497159477250, ...,\n",
       "          1420534022586660, 1420534032355010, 1420534041694420],\n",
       "         [1400852838700990, 1400852955786310, 1400853003617340, ...,\n",
       "          1401093084227320, 1401093090357810, 1401093106552690],\n",
       "         [1388725010450670, 1388725031914280, 1388725037021100, ...,\n",
       "          1388726403853880, 1388726409908810, 1388726412204000]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1414580864493500, 1414580869077240, 1414580872202450, ...,\n",
       "          1415844530556840, 1415844538461830, 1415844540534430],\n",
       "         [1418563942090670, 1418563951107290, 1418563968472540, ...,\n",
       "          1420465396105470, 1420465411258510, 1420465421142010],\n",
       "         [1380875612663240, 1380875866170090, 1380875889930100, ...,\n",
       "          1386230992369320, 1386231002981420, 1388131961925530],\n",
       "         ...,\n",
       "         [1417754469790660, 1417754494016460, 1417755729457590, ...,\n",
       "          1418015072983780, 1418015077459380, 1418015079943870],\n",
       "         [1399992461889870, 1399992464931040, 1399992468029840, ...,\n",
       "          1400247430393260, 1400247433960360, 1400247435269250],\n",
       "         [1380072738652680, 1380072760372820, 1380072788884560, ...,\n",
       "          1381462996795820, 1381462999916300, 1381463003488460]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 0]])),\n",
       " (array([[1389775278576030, 1389775285866380, 1389775290268750, ...,\n",
       "          1392972533708160, 1392972538049950, 1392972547754150],\n",
       "         [1415356515487220, 1415356653134560, 1415356726639270, ...,\n",
       "          1416140802247510, 1416140812271150, 1416140826767470],\n",
       "         [1376880696920540, 1376881056347790, 1376881184502760, ...,\n",
       "          1398143604407180, 1398143653485960, 1398143725281230],\n",
       "         ...,\n",
       "         [1399625614142430, 1399625626701030, 1399625642227440, ...,\n",
       "          1399692952416700, 1399692954888680, 1399692957414810],\n",
       "         [1368261547303220, 1368261566354870, 1368261570544120, ...,\n",
       "          1371012982797630, 1371012985659530, 1371012989037360],\n",
       "         [1395367034805670, 1395367051853280, 1395367054185950, ...,\n",
       "          1400641279214430, 1400641282010990, 1400641290441310]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 0],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1415601640322120, 1415601654282870, 1415601660054780, ...,\n",
       "          1416811920107650, 1416811924974740, 1416811929340450],\n",
       "         [1411989475480700, 1411990148358140, 1411990173991350, ...,\n",
       "          1414409727672410, 1414409734622170, 1414409737257000],\n",
       "         [1412147361293770, 1412147368078190, 1412147375996630, ...,\n",
       "          1412149397682070, 1412149401703740, 1412149407396140],\n",
       "         ...,\n",
       "         [1412421791052600, 1412421877056590, 1412421881857400, ...,\n",
       "          1412424092369300, 1412424095332910, 1412424103328400],\n",
       "         [1411959916051520, 1411959931979700, 1412073841761180, ...,\n",
       "          1414138559672580, 1414138565080590, 1414138567655530],\n",
       "         [1411462691965760, 1411979527964800, 1411979558643170, ...,\n",
       "          1416817714070140, 1416817719184030, 1416817723408920]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 1]])),\n",
       " (array([[1419391633205080, 1419391639342000, 1419391642163800, ...,\n",
       "          1419502438432440, 1419502441041460, 1419502443475940],\n",
       "         [1413988723058750, 1413988727220300, 1413988731439350, ...,\n",
       "          1415183611458970, 1415183614486140, 1415183617791330],\n",
       "         [1406173067963350, 1406173081999980, 1406173135891000, ...,\n",
       "          1408070981046680, 1408070985503290, 1408070993708830],\n",
       "         ...,\n",
       "         [1362291663532750, 1362291671011330, 1362291678276780, ...,\n",
       "          1397111394500440, 1397111418772710, 1397111426415820],\n",
       "         [1401363415253180, 1401363423216150, 1401363431335360, ...,\n",
       "          1401463640203260, 1401463662279470, 1401463668218020],\n",
       "         [1398991521775330, 1398991536663460, 1398991552689170, ...,\n",
       "          1399626656193900, 1399626659219710, 1399626664009270]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1389769728217790, 1389769731019210, 1389769733601950, ...,\n",
       "          1394167059444400, 1394167066605470, 1394167070152420],\n",
       "         [1402391725590780, 1402391738993990, 1402391749729880, ...,\n",
       "          1402647603344900, 1402647606298760, 1402647608747110],\n",
       "         [1420002055082960, 1420002061204740, 1420002106005030, ...,\n",
       "          1420003759219830, 1420003780144070, 1420003781927850],\n",
       "         ...,\n",
       "         [1409971462840300, 1409971548547450, 1409971587982130, ...,\n",
       "          1409975982166330, 1409975990219650, 1409976004035620],\n",
       "         [1412831122279210, 1412831130175680, 1412831135224000, ...,\n",
       "          1413435726858870, 1413435731938150, 1413435738167470],\n",
       "         [1387633339277220, 1387633346434800, 1387633369754830, ...,\n",
       "          1388833558977370, 1388833562387140, 1388833566427610]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1415604016090430, 1415604020741180, 1415604026307860, ...,\n",
       "          1415605406822740, 1415605413896190, 1415605420081360],\n",
       "         [1403421767472660, 1403421770099270, 1403421775537420, ...,\n",
       "          1407075352380000, 1407075355153610, 1407075357170800],\n",
       "         [1412230377316610, 1414069688150040, 1414069744871460, ...,\n",
       "          1415869729091840, 1415873975540130, 1415873980316380],\n",
       "         ...,\n",
       "         [1406859941526520, 1406859989874460, 1406860014785490, ...,\n",
       "          1415425667426210, 1415425711025740, 1415425765464050],\n",
       "         [1418274761034950, 1418706301461950, 1418706315479090, ...,\n",
       "          1420775435975160, 1420775438295530, 1420775440924570],\n",
       "         [1382329006177260, 1382329027041240, 1382329074509370, ...,\n",
       "          1384230060434370, 1384230066477600, 1384230069655470]]),\n",
       "  array([[1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1373887869641360, 1373887874267380, 1373887942000400, ...,\n",
       "          1373891105516800, 1373891115481960, 1373891124102880],\n",
       "         [1398222046733510, 1398222052088150, 1398222055045640, ...,\n",
       "          1399432493476040, 1399432998495300, 1399433002177840],\n",
       "         [1410664970024650, 1410671188499750, 1410671193273410, ...,\n",
       "          1410872002074490, 1410872200830720, 1410872205264730],\n",
       "         ...,\n",
       "         [1403571885828320, 1403572499347650, 1403572508091780, ...,\n",
       "          1404715405573910, 1404715417006110, 1404715419930660],\n",
       "         [1400755586389390, 1400755590343090, 1400755597833870, ...,\n",
       "          1401790536574610, 1401790539289270, 1401790542752370],\n",
       "         [1398238930172310, 1398238935997650, 1398238940196480, ...,\n",
       "          1401259869463030, 1401259874197000, 1401259878496810]]),\n",
       "  array([[1, 0, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1395399367362850, 1395399372137140, 1395399375352030, ...,\n",
       "          1420601928567800, 1420601931244040, 1420601933858850],\n",
       "         [1411027096573380, 1411027104633830, 1411027119425920, ...,\n",
       "          1415259434225350, 1415259438664760, 1415259445614460],\n",
       "         [1396252834036210, 1396252860620950, 1396252890003220, ...,\n",
       "          1396341288883640, 1396341293695270, 1396341307166620],\n",
       "         ...,\n",
       "         [1398167079851010, 1398167083345720, 1398167086057510, ...,\n",
       "          1407466968449920, 1407466971629510, 1407466974160230],\n",
       "         [1398134009805950, 1398134035088320, 1398134082136320, ...,\n",
       "          1398244958616940, 1398245004324470, 1398245057314500],\n",
       "         [1404444396744280, 1404444415287540, 1404444431163230, ...,\n",
       "          1405047321939790, 1405047324349150, 1405047326759020]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1382139662778120, 1382139680253780, 1382139687783600, ...,\n",
       "          1382704929929320, 1382704939146950, 1382704957256810],\n",
       "         [1411990403507960, 1412594944519520, 1413200929964440, ...,\n",
       "          1419851259636780, 1419851261252130, 1419851262277640],\n",
       "         [1400832719492360, 1400832730004520, 1400832734633830, ...,\n",
       "          1401440491877710, 1402042293308390, 1402042297005760],\n",
       "         ...,\n",
       "         [1412147045138050, 1412147091401480, 1412147117443060, ...,\n",
       "          1420612690532570, 1420612694235250, 1420612698306250],\n",
       "         [1394177628128150, 1394177643134080, 1394177658819090, ...,\n",
       "          1394803476822380, 1394803482095380, 1394803515352150],\n",
       "         [1409140091817260, 1409140098391350, 1409140103662240, ...,\n",
       "          1409186865620870, 1409186870238110, 1409186873006790]]),\n",
       "  array([[1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1355140320837140, 1355140335382550, 1355140491424470, ...,\n",
       "          1363924471443730, 1363924474050120, 1363924483802880],\n",
       "         [1417755663624450, 1417755682527190, 1417755698204810, ...,\n",
       "          1418620191705940, 1418620194978940, 1418620200459480],\n",
       "         [1413348400136500, 1413348426831670, 1413349356272200, ...,\n",
       "          1417584539645750, 1417584542385840, 1417584545034390],\n",
       "         ...,\n",
       "         [1389850289730540, 1389850366402040, 1389850383691560, ...,\n",
       "          1390823006599990, 1390823015559340, 1390823026156470],\n",
       "         [1419247647994350, 1419247668944890, 1419247748617440, ...,\n",
       "          1419249885048370, 1419249887668090, 1419249890437330],\n",
       "         [1391837340146390, 1391837361903890, 1391837406456910, ...,\n",
       "          1403675195556160, 1403675198763680, 1403675202810960]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1393228283345920, 1393228312201770, 1393831769339650, ...,\n",
       "          1399276038384530, 1399276062558390, 1399276093439420],\n",
       "         [1418395609241130, 1418395627412340, 1418395646364020, ...,\n",
       "          1419649700358260, 1419649705254600, 1419649709179500],\n",
       "         [1397537841873290, 1397537846040470, 1397537847999910, ...,\n",
       "          1402893927995310, 1402893930155860, 1402893932182650],\n",
       "         ...,\n",
       "         [1410934979471630, 1410934982089770, 1410934985336920, ...,\n",
       "          1416983739283320, 1416983740520500, 1416983744422500],\n",
       "         [1395034846438210, 1395119961851090, 1395120012110400, ...,\n",
       "          1397797021807940, 1397797391689020, 1397797412901660],\n",
       "         [1399104248329240, 1399104318973990, 1399104364140220, ...,\n",
       "          1399533519861030, 1399533522656390, 1399533526134160]]),\n",
       "  array([[1, 0, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1397650988290800, 1397651038345220, 1397651255393050, ...,\n",
       "          1408024223473190, 1408024303154170, 1408024404634710],\n",
       "         [1390631988098290, 1390632069219310, 1390632256089750, ...,\n",
       "          1391837046801350, 1391837061619840, 1391837065134720],\n",
       "         [1379141402472900, 1379141413146060, 1379141438562850, ...,\n",
       "          1379673637468630, 1379673639590690, 1379673642561140],\n",
       "         ...,\n",
       "         [1368589064814990, 1368589080888580, 1368589224777190, ...,\n",
       "          1369897950708840, 1369897961216330, 1369897976421850],\n",
       "         [1412560501228810, 1412560504351620, 1412560507651140, ...,\n",
       "          1414979064011730, 1414979066103410, 1414979067848830],\n",
       "         [1389678779118870, 1389678797641750, 1389679263902920, ...,\n",
       "          1395032501765620, 1395032507988930, 1395032511519530]]),\n",
       "  array([[1, 0, 1, ..., 0, 1, 1],\n",
       "         [1, 0, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1413710414729620, 1413710480115680, 1413710534415710, ...,\n",
       "          1415354463535290, 1415354475341420, 1415354486050030],\n",
       "         [1400138389328970, 1400138398651880, 1400138407429780, ...,\n",
       "          1400742738740080, 1400742741084830, 1400742745530860],\n",
       "         [1404131313039490, 1404131323345790, 1404131329352180, ...,\n",
       "          1407131770007130, 1407131774312880, 1407131913278530],\n",
       "         ...,\n",
       "         [1396425048965070, 1396425062434880, 1396425078337900, ...,\n",
       "          1397627286134810, 1397627290906010, 1397627293332770],\n",
       "         [1411215966725460, 1411215969087110, 1411215971219540, ...,\n",
       "          1411394202364610, 1411394204601560, 1411394206672380],\n",
       "         [1410586986666550, 1410587006020600, 1410587024921990, ...,\n",
       "          1410700678998140, 1410700687615320, 1410700695586580]]),\n",
       "  array([[0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1]])),\n",
       " (array([[1413377579942490, 1413377589362090, 1413377595371950, ...,\n",
       "          1419236174976380, 1419236182518750, 1419236189448410],\n",
       "         [1419929802644330, 1419929809235300, 1419929812062710, ...,\n",
       "          1420704324875320, 1420704326490570, 1420704329471730],\n",
       "         [1417409081233210, 1417409084411730, 1417409086979550, ...,\n",
       "          1417668043426570, 1417668050663890, 1417668052572330],\n",
       "         ...,\n",
       "         [1419557514282250, 1419557523177960, 1419557528580920, ...,\n",
       "          1419914081752760, 1419914085122230, 1419914091131390],\n",
       "         [1394071169235380, 1394071173232430, 1394071176593200, ...,\n",
       "          1398932279012830, 1398932281067940, 1398932283131800],\n",
       "         [1377428875521490, 1377428881195990, 1377428882003640, ...,\n",
       "          1377491921179460, 1377491923296100, 1377491925098480]]),\n",
       "  array([[0, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1402491044967420, 1402491108875780, 1402491132630160, ...,\n",
       "          1403102053158570, 1403102077186400, 1403102095965770],\n",
       "         [1395999418276890, 1395999431759150, 1395999456868880, ...,\n",
       "          1401182377880760, 1401182382735480, 1401182384571150],\n",
       "         [1418632587461300, 1418632603053240, 1418632677184340, ...,\n",
       "          1419237690108390, 1419237693578070, 1419237696547700],\n",
       "         ...,\n",
       "         [1380788510412500, 1380788551550610, 1380788713239290, ...,\n",
       "          1382604200692510, 1382604210844590, 1382604213123290],\n",
       "         [1394344076189770, 1394344094270110, 1394344097480870, ...,\n",
       "          1409125750159410, 1409125753981580, 1409125756181420],\n",
       "         [1400730212251290, 1400730274034050, 1400730276730540, ...,\n",
       "          1401334493482820, 1401334500100420, 1401334518554580]]),\n",
       "  array([[0, 1, 1, ..., 0, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 0]])),\n",
       " (array([[1416212816291050, 1416212821020000, 1416212827732510, ...,\n",
       "          1416540899741970, 1416540900744420, 1416540901571930],\n",
       "         [1378890996468910, 1378891030938410, 1378891103603570, ...,\n",
       "          1379492124752890, 1379492133785760, 1379492148691570],\n",
       "         [1394416196277460, 1394416358008740, 1394416406803710, ...,\n",
       "          1397463357469090, 1397463370528310, 1397463380503180],\n",
       "         ...,\n",
       "         [1415595242154980, 1415595273044090, 1415595288316260, ...,\n",
       "          1416805524612680, 1416805528508590, 1416805532091490],\n",
       "         [1384417719972170, 1384762780496830, 1384762786615380, ...,\n",
       "          1385626459977640, 1385626466424540, 1385626472563720],\n",
       "         [1393980239198210, 1393980244177880, 1393980249992080, ...,\n",
       "          1394585622547820, 1394585624676270, 1394585631382710]]),\n",
       "  array([[1, 1, 1, ..., 0, 0, 0],\n",
       "         [0, 0, 1, ..., 1, 1, 0],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1419250881464320, 1419250895913360, 1419250910837110, ...,\n",
       "          1419331219307880, 1419331225861470, 1419331234538820],\n",
       "         [1382097723958110, 1382097747515080, 1382097757587970, ...,\n",
       "          1382761670593140, 1382761672603520, 1382761674259030],\n",
       "         [1415014195274730, 1415014199201130, 1415014204259040, ...,\n",
       "          1417263173338190, 1417263176074980, 1417263178736330],\n",
       "         ...,\n",
       "         [1399603272790120, 1399603285195480, 1399603301690070, ...,\n",
       "          1400643357620380, 1400643361271020, 1400643364569460],\n",
       "         [1387289675336800, 1387444635358300, 1387444764925250, ...,\n",
       "          1387454351939880, 1387454359098910, 1387454364150760],\n",
       "         [1414157616127220, 1414157626500430, 1414157637451120, ...,\n",
       "          1414305731086200, 1414305733014660, 1414305734684470]]),\n",
       "  array([[1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 0],\n",
       "         [0, 0, 1, ..., 1, 1, 1]])),\n",
       " (array([[1419384212383060, 1419384252895400, 1419384268395890, ...,\n",
       "          1420001617990330, 1420001621040480, 1420001667468800],\n",
       "         [1416465535309180, 1416465546504570, 1416465625099070, ...,\n",
       "          1416874719146880, 1416874726423010, 1416874787989820],\n",
       "         [1387527187986620, 1387527211489690, 1387527214128170, ...,\n",
       "          1388132278758550, 1388132281143760, 1388132285160380],\n",
       "         ...,\n",
       "         [1400826945851440, 1400826960780920, 1400826972138820, ...,\n",
       "          1401431414956780, 1401431416822550, 1401431449148490],\n",
       "         [1398402063309810, 1398660620951570, 1398660638393990, ...,\n",
       "          1398748752669910, 1398748756928560, 1398748761113050],\n",
       "         [1416886635768160, 1416886644728050, 1416886654737880, ...,\n",
       "          1417231297881880, 1417231299960380, 1417231304294980]]),\n",
       "  array([[0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1416811099676450, 1416811134784780, 1416811149723570, ...,\n",
       "          1417092177842270, 1417092180678020, 1417092202808120],\n",
       "         [1415604702347390, 1415604716769820, 1415604853675110, ...,\n",
       "          1419214230704450, 1419214232867730, 1419214235139990],\n",
       "         [1397436974254250, 1397436992335200, 1397437011083910, ...,\n",
       "          1397724120508200, 1397724129156100, 1397724136720760],\n",
       "         ...,\n",
       "         [1414841126703410, 1414841131376380, 1414841134861430, ...,\n",
       "          1415784141670540, 1415784144912840, 1415784152648460],\n",
       "         [1413886530168110, 1413886603863490, 1413886751735200, ...,\n",
       "          1414413911849430, 1414414048626240, 1414414060485080],\n",
       "         [1414071753944220, 1414071758687620, 1414071766718990, ...,\n",
       "          1415108271473810, 1415108274041570, 1415108275894580]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1418024376096700, 1418024381011410, 1418024383204580, ...,\n",
       "          1418211391300720, 1418211393344630, 1418211395240770],\n",
       "         [1413527645760240, 1413527661944120, 1413527670208490, ...,\n",
       "          1419665970997760, 1419665973109920, 1419665974830790],\n",
       "         [1384338568116090, 1384338582356450, 1384338597074370, ...,\n",
       "          1385291714696710, 1385291719222150, 1385291724462750],\n",
       "         ...,\n",
       "         [1415590909175320, 1415590913949630, 1415590920797830, ...,\n",
       "          1415669506816400, 1415669513140220, 1415669516948500],\n",
       "         [1392267395467030, 1392267700721510, 1392267911184110, ...,\n",
       "          1392612952587880, 1392612966092810, 1392612972342300],\n",
       "         [1388035681685770, 1388035684741200, 1388035687489080, ...,\n",
       "          1394687642760760, 1394687645196780, 1394687647265700]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 0, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1416214023153060, 1416214367439440, 1416214383312600, ...,\n",
       "          1418620004594780, 1418620050513030, 1418620065422750],\n",
       "         [1398152885867030, 1398152890285790, 1398152894640460, ...,\n",
       "          1415273483149460, 1415273485918230, 1415273488394370],\n",
       "         [1419499414474000, 1419499417193690, 1419499419355360, ...,\n",
       "          1419679817796020, 1419679821645970, 1419679830980160],\n",
       "         ...,\n",
       "         [1403189304633830, 1403189326653590, 1403189336955960, ...,\n",
       "          1403425940329850, 1403425950432100, 1403425961865510],\n",
       "         [1382330998083130, 1382331001163620, 1382331004816130, ...,\n",
       "          1383028417557900, 1383028424300600, 1383028435072180],\n",
       "         [1406948613419790, 1406948618983310, 1406948710116450, ...,\n",
       "          1416832792468540, 1416832898533610, 1416832912034600]]),\n",
       "  array([[0, 0, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1410921075064350, 1410923170620190, 1410923176388390, ...,\n",
       "          1417145546268670, 1417145551886030, 1417145556037690],\n",
       "         [1414156336109550, 1414156340012340, 1414156345377690, ...,\n",
       "          1414159561647230, 1414159565457880, 1414159566661050],\n",
       "         [1417599945964930, 1417599949207860, 1417599953234240, ...,\n",
       "          1418977696265690, 1418977697605910, 1418977703869440],\n",
       "         ...,\n",
       "         [1392363862832740, 1392364117328670, 1392364145792730, ...,\n",
       "          1394276584963490, 1394276602880190, 1394276635767880],\n",
       "         [1417013929508400, 1417013940627750, 1417013950290610, ...,\n",
       "          1417078168032680, 1417078169964220, 1417078171886740],\n",
       "         [1414127730879260, 1414127732841930, 1414127747395190, ...,\n",
       "          1414131274679080, 1414131280588210, 1414131284124560]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1416298876169340, 1416298879177550, 1416298881866050, ...,\n",
       "          1416903316673160, 1416903318598940, 1416903320694880],\n",
       "         [1410836758407290, 1410836763279290, 1410836771142500, ...,\n",
       "          1413554386830010, 1413554388872060, 1413554390915520],\n",
       "         [1415603181036820, 1415603193407870, 1415603201427920, ...,\n",
       "          1417418366442370, 1417418368279520, 1417418370708490],\n",
       "         ...,\n",
       "         [1410331610514710, 1410331617463190, 1410331632161120, ...,\n",
       "          1411537456441580, 1411537465311920, 1411537469985320],\n",
       "         [1384317002792980, 1384317013418900, 1384317022487240, ...,\n",
       "          1385129106357080, 1385129114961090, 1385129126567370],\n",
       "         [1418100594375630, 1418100602531340, 1418100610594840, ...,\n",
       "          1418101466278930, 1418101468563030, 1418101470616870]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 1, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1356438036525960, 1404270191475670, 1404436703611670, ...,\n",
       "          1405225341319760, 1405225344444800, 1405225347438980],\n",
       "         [1416547596844120, 1416547601545460, 1416547605103170, ...,\n",
       "          1418175469008660, 1418175492041920, 1418175952714220],\n",
       "         [1413521114345500, 1413521162466080, 1413522992661850, ...,\n",
       "          1416898243108720, 1416898248175650, 1416898250728910],\n",
       "         ...,\n",
       "         [1395982831565080, 1395982869993190, 1395982882873870, ...,\n",
       "          1396502286399600, 1396502291451780, 1396502296948340],\n",
       "         [1392267549224400, 1392267908052430, 1392267955310920, ...,\n",
       "          1392355111148530, 1392355114493510, 1392355119836400],\n",
       "         [1400551653839800, 1400551656699720, 1400551658909200, ...,\n",
       "          1400918493351510, 1400918501978580, 1400918505073320]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 0, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1393324018704560, 1393324030899450, 1393324039728800, ...,\n",
       "          1393328390946220, 1393328399057380, 1393328405921700],\n",
       "         [1389664560307480, 1389664567848440, 1389664574700810, ...,\n",
       "          1392251323636380, 1392251326529330, 1392251334950830],\n",
       "         [1382360698427870, 1382360739161870, 1382360816831570, ...,\n",
       "          1384171386092760, 1384171396181700, 1384171415976650],\n",
       "         ...,\n",
       "         [1394587981623920, 1394587988983210, 1394588005181850, ...,\n",
       "          1395111817613620, 1395111824085300, 1395111868027960],\n",
       "         [1401687887822240, 1401687903421740, 1401687906397550, ...,\n",
       "          1401706408348840, 1401706411414510, 1401706416312130],\n",
       "         [1395900102214850, 1395900108703200, 1395900112812320, ...,\n",
       "          1396876877372960, 1396876879830970, 1396876883047460]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1407396145599410, 1407396151066960, 1407396180043950, ...,\n",
       "          1409121995263730, 1409122002504760, 1409122006448990],\n",
       "         [1384419120360010, 1384419136640550, 1384419150012900, ...,\n",
       "          1389256716727010, 1389256723733600, 1389256733472430],\n",
       "         [1377877236848220, 1377877259387430, 1377877282025420, ...,\n",
       "          1416228180020540, 1416228189566840, 1416228197636140],\n",
       "         ...,\n",
       "         [1383030560553820, 1383030592524750, 1383030607728900, ...,\n",
       "          1385794610931590, 1385794619504080, 1385794629465110],\n",
       "         [1394169457296110, 1394169475104410, 1394169477629610, ...,\n",
       "          1394279535817480, 1394279538957470, 1394279542089390],\n",
       "         [1398070601123050, 1398070694672500, 1398071081177800, ...,\n",
       "          1398675667402520, 1398675672903480, 1398675677186560]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0]])),\n",
       " (array([[1393491964235750, 1393491975598750, 1393491984304690, ...,\n",
       "          1394895211244080, 1394895216043470, 1394895222249400],\n",
       "         [1411449578998030, 1411449594464880, 1411449607462690, ...,\n",
       "          1417497487678810, 1417497493453030, 1417497502473650],\n",
       "         [1382073044981260, 1382073061848470, 1382073081923200, ...,\n",
       "          1382937629135710, 1382937631285650, 1382937635605620],\n",
       "         ...,\n",
       "         [1405513559472400, 1405513565257200, 1405513573488540, ...,\n",
       "          1408860732371130, 1408860734303810, 1408860736629690],\n",
       "         [1407672385018030, 1407672460340700, 1407672469077760, ...,\n",
       "          1418905874199400, 1418905878970840, 1418905882340080],\n",
       "         [1383725604322890, 1383725633762410, 1383826287459000, ...,\n",
       "          1384224682897160, 1384224685500680, 1384224688932790]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1385626641622780, 1385626660442170, 1387937014888530, ...,\n",
       "          1400721692244160, 1400721697202610, 1400721719168610],\n",
       "         [1417495555374450, 1417495626962720, 1417495643780230, ...,\n",
       "          1419927261207550, 1419927265476690, 1419927274285660],\n",
       "         [1392942622929190, 1394690500913510, 1394754570823690, ...,\n",
       "          1418170644130720, 1418170658701200, 1418170685187550],\n",
       "         ...,\n",
       "         [1415192109507880, 1415192112219490, 1415192114731440, ...,\n",
       "          1415662958014160, 1415662960883740, 1415662963391270],\n",
       "         [1381327000307510, 1381327053333730, 1381327100623750, ...,\n",
       "          1389704215802780, 1389704268859670, 1394356762852770],\n",
       "         [1406029996956620, 1406030031212050, 1406030172735370, ...,\n",
       "          1407722195123440, 1407722200711450, 1407722239325400]]),\n",
       "  array([[0, 0, 1, ..., 1, 0, 0],\n",
       "         [0, 0, 0, ..., 1, 0, 1],\n",
       "         [0, 0, 1, ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 0]])),\n",
       " (array([[1417762263422110, 1417762277391550, 1417763316584660, ...,\n",
       "          1418040625517150, 1418040627109260, 1418040628911690],\n",
       "         [1412853199439100, 1412853213066930, 1412854711848820, ...,\n",
       "          1413032158755290, 1413032161280530, 1413032163475640],\n",
       "         [1416149090841390, 1416149094438630, 1416149097492790, ...,\n",
       "          1416231479074780, 1416231482558210, 1416231484976440],\n",
       "         ...,\n",
       "         [1405917204622540, 1405917213240830, 1405917221730750, ...,\n",
       "          1406175457229690, 1406175460925350, 1406175480978120],\n",
       "         [1378260327437600, 1378341003273530, 1378341062284300, ...,\n",
       "          1378722708587140, 1378722718997340, 1378722726849030],\n",
       "         [1415927411177910, 1415927423262810, 1415927595652400, ...,\n",
       "          1415930128456960, 1415930130484810, 1415930132884690]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1410439213571710, 1410439220076360, 1410439235975340, ...,\n",
       "          1412256193802960, 1412256198843330, 1412256202391900],\n",
       "         [1419302637406030, 1419302647450710, 1419302652705840, ...,\n",
       "          1420768045665950, 1420768050206560, 1420768054209470],\n",
       "         [1393838341208800, 1393838344106990, 1393838347689600, ...,\n",
       "          1394443444592090, 1394443448834650, 1394443465580910],\n",
       "         ...,\n",
       "         [1410939579730480, 1410939586291260, 1410939592623930, ...,\n",
       "          1411538149444410, 1411538153185200, 1411538162386260],\n",
       "         [1384837859134440, 1384837910906610, 1384838019548380, ...,\n",
       "          1395461709242020, 1395461728501780, 1395461741268060],\n",
       "         [1399531711139890, 1399531788189890, 1399531830983510, ...,\n",
       "          1400135538016850, 1400135542956270, 1400135547803670]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 0, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1387171303404980, 1387246841278140, 1387246885466930, ...,\n",
       "          1387286623566950, 1387286650362740, 1387286673385010],\n",
       "         [1401070723948090, 1401070729267820, 1401070735753110, ...,\n",
       "          1401943741198230, 1401943754945940, 1401943769651340],\n",
       "         [1395296008544370, 1395296062989520, 1395296100566700, ...,\n",
       "          1396859709144150, 1396859717994590, 1396859723505930],\n",
       "         ...,\n",
       "         [1394623525047890, 1394623614875290, 1394623979308610, ...,\n",
       "          1395741869971910, 1395741896028400, 1395741917188000],\n",
       "         [1416278604473970, 1416278644630870, 1416278647797960, ...,\n",
       "          1418696994754280, 1418696998382150, 1418697002048080],\n",
       "         [1418996366625880, 1418996369407660, 1418996375376410, ...,\n",
       "          1420433506976120, 1420433508187420, 1420433509391820]]),\n",
       "  array([[0, 0, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1411028637187390, 1411028682294720, 1411028703548000, ...,\n",
       "          1411978992295900, 1411978995335290, 1411979003830200],\n",
       "         [1395911624147160, 1395911633444750, 1395911637977970, ...,\n",
       "          1399970972598970, 1399970976254610, 1399970979912290],\n",
       "         [1416211554538010, 1416211586244740, 1416211596171800, ...,\n",
       "          1417076375434590, 1417076390474560, 1417076422035260],\n",
       "         ...,\n",
       "         [1378782081500530, 1378782102866190, 1378782110172590, ...,\n",
       "          1391953524265350, 1391953534532570, 1391953547084180],\n",
       "         [1415371738047580, 1415371751910250, 1415371760253180, ...,\n",
       "          1420092584936280, 1420092591502990, 1420092595555890],\n",
       "         [1413203531733060, 1413204156622870, 1413204222150840, ...,\n",
       "          1414206348769610, 1414206386356200, 1414206402319970]]),\n",
       "  array([[0, 1, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1396514029343810, 1396514038037610, 1396514045305560, ...,\n",
       "          1419322684317370, 1419322686363750, 1419322689411540],\n",
       "         [1416815062053490, 1416815065501950, 1416815072548400, ...,\n",
       "          1418024068475650, 1418024070506700, 1418024072372860],\n",
       "         [1401334691427960, 1401334729035700, 1401334792277140, ...,\n",
       "          1419209161427020, 1419209163744890, 1419209168298850],\n",
       "         ...,\n",
       "         [1394622595119370, 1394622683908520, 1394622691568880, ...,\n",
       "          1394860407626610, 1394860414737180, 1394860420486270],\n",
       "         [1416539274940160, 1416539277494300, 1416539280991070, ...,\n",
       "          1418951816678370, 1418951819263960, 1418951853276680],\n",
       "         [1394433885930640, 1394433913270750, 1394433916903840, ...,\n",
       "          1394513805166390, 1394513807704960, 1394513811772260]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1417418879414570, 1417418892525800, 1417418903231580, ...,\n",
       "          1417420244370610, 1417420246106690, 1417420247915260],\n",
       "         [1392967062764940, 1392967102244850, 1392968078334470, ...,\n",
       "          1396755080073240, 1396755184823090, 1396755222544830],\n",
       "         [1396958874945070, 1396958910191100, 1396958943823010, ...,\n",
       "          1399373611678260, 1399373615657200, 1399373635219930],\n",
       "         ...,\n",
       "         [1373615572678000, 1373615586752350, 1373615613382500, ...,\n",
       "          1377680466425650, 1377680469624760, 1377680474626140],\n",
       "         [1419600926838190, 1419600931056230, 1419600958392540, ...,\n",
       "          1420196966896770, 1420196969208730, 1420196976078400],\n",
       "         [1414667074309540, 1414667080557330, 1414667083404060, ...,\n",
       "          1414753584793760, 1414753587636040, 1414753590225470]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1414244711349190, 1414244736722440, 1414244751139770, ...,\n",
       "          1414246966841650, 1414246974442160, 1414246977410360],\n",
       "         [1411989749398490, 1411989760486790, 1411989786187470, ...,\n",
       "          1412596007507140, 1412596011650940, 1412596012648820],\n",
       "         [1396493587204040, 1396500684419430, 1397109477119690, ...,\n",
       "          1415180006737670, 1415180027491980, 1415180034554860],\n",
       "         ...,\n",
       "         [1387508166844490, 1387508239276340, 1387508531526350, ...,\n",
       "          1411139907632740, 1411139910528160, 1411139915175220],\n",
       "         [1394609809286330, 1394609822387640, 1394609843059130, ...,\n",
       "          1397360969312400, 1397466184956570, 1397550438712180],\n",
       "         [1401852984529770, 1401853049238550, 1401853112999660, ...,\n",
       "          1416994533599410, 1416994535591040, 1416994542594960]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1419688907357300, 1419688910218780, 1419688914841960, ...,\n",
       "          1419697584484030, 1419697587672470, 1419697590177210],\n",
       "         [1380874223809040, 1380874228260940, 1380874232167440, ...,\n",
       "          1382689319887590, 1382689322411220, 1382689325286300],\n",
       "         [1386493609278400, 1386493615409060, 1386493698498610, ...,\n",
       "          1386498667778930, 1386498674802040, 1386498679392500],\n",
       "         ...,\n",
       "         [1415865737959660, 1415865744647970, 1415865753947170, ...,\n",
       "          1416214374194140, 1416214376369870, 1416214378551330],\n",
       "         [1397196988613540, 1397196994860850, 1397197001611950, ...,\n",
       "          1397612887094230, 1397612889031060, 1397612891065910],\n",
       "         [1393920733645960, 1393920736566130, 1393920740992300, ...,\n",
       "          1411141352419570, 1411141379071190, 1411141381366560]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1419138467854120, 1419138506650630, 1419156829778430, ...,\n",
       "          1419742195091660, 1419742196910350, 1419742197821920],\n",
       "         [1366947331093100, 1366947360499380, 1412317064122030, ...,\n",
       "          1413343541860430, 1413343588517870, 1413343593084430],\n",
       "         [1374897910483850, 1374897997073640, 1374900982520480, ...,\n",
       "          1398934246695280, 1398934248684050, 1398934251220940],\n",
       "         ...,\n",
       "         [1415061814748590, 1415061821757950, 1415061827245150, ...,\n",
       "          1415363816644030, 1415363821076490, 1415363822386040],\n",
       "         [1395637258026340, 1395637330255660, 1395637380808050, ...,\n",
       "          1396241526952260, 1396241580045460, 1396241603930360],\n",
       "         [1384417113183110, 1384417119275400, 1384417139298730, ...,\n",
       "          1399883039994530, 1399883045967030, 1399883048144700]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1384582554636740, 1384582599897110, 1384583446662650, ...,\n",
       "          1390109425581620, 1390109454798360, 1390109473674590],\n",
       "         [1400724478104170, 1400724494286750, 1400724511323310, ...,\n",
       "          1403747632017920, 1403747634979150, 1403747637453500],\n",
       "         [1415000424707810, 1415000428193660, 1415000431548100, ...,\n",
       "          1415766373507870, 1415766376121480, 1415766378325160],\n",
       "         ...,\n",
       "         [1378260240297450, 1378260243299240, 1378260251347130, ...,\n",
       "          1380159398504930, 1380159399685070, 1380159406791210],\n",
       "         [1414210987316990, 1414211002480520, 1414211010397780, ...,\n",
       "          1414281512110930, 1414281513641420, 1414281515355020],\n",
       "         [1416819316247450, 1416819326394960, 1416819351289940, ...,\n",
       "          1417424832741040, 1417424835348790, 1417424838113610]]),\n",
       "  array([[1, 0, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 0]])),\n",
       " (array([[1414303547297960, 1414303549976130, 1414303553058540, ...,\n",
       "          1416725492980650, 1416725496156950, 1416725499298580],\n",
       "         [1416533758041740, 1416533767982750, 1416533771814710, ...,\n",
       "          1417683976396640, 1417683977968300, 1417683982555770],\n",
       "         [1414650343580760, 1414650348766390, 1414650353011740, ...,\n",
       "          1415254980034410, 1415254983503260, 1415254985530770],\n",
       "         ...,\n",
       "         [1414660900840700, 1414660905779030, 1414660908346940, ...,\n",
       "          1416471204871320, 1416471206155730, 1416471207919440],\n",
       "         [1413292001109880, 1414383141383980, 1414383145353060, ...,\n",
       "          1417529503759090, 1417529507840070, 1417529510174580],\n",
       "         [1418128631313010, 1419249457609050, 1419249461060120, ...,\n",
       "          1419430246811640, 1419430253307830, 1419430257968620]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1400848363855910, 1400848381460300, 1400848397573880, ...,\n",
       "          1400854760908140, 1400854771118860, 1400854776713120],\n",
       "         [1412582993792180, 1412583013172400, 1412583016888420, ...,\n",
       "          1417508521711320, 1417508526200090, 1417508529067260],\n",
       "         [1414553400819740, 1414553404822590, 1414553414432340, ...,\n",
       "          1419998279568920, 1419998281831390, 1419998287697910],\n",
       "         ...,\n",
       "         [1400730561921090, 1400730764728790, 1400730831055820, ...,\n",
       "          1400829649928430, 1400829660694350, 1400829666931410],\n",
       "         [1413177158075060, 1413177192512650, 1413177204350060, ...,\n",
       "          1414990878019490, 1414990881297360, 1414990885527560],\n",
       "         [1403833289137320, 1403833298273280, 1403833314621850, ...,\n",
       "          1410784157892410, 1410784749431040, 1410784892983210]]),\n",
       "  array([[0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 0, 1, 0]])),\n",
       " (array([[1402964043463930, 1402964049569950, 1402964053988650, ...,\n",
       "          1415261283113350, 1415261351146660, 1415261354349530],\n",
       "         [1417406140895740, 1417406145190430, 1417406149166780, ...,\n",
       "          1419638063700290, 1419638067804380, 1419638086607980],\n",
       "         [1393982289381850, 1393982297543580, 1393982309681640, ...,\n",
       "          1405241965399010, 1405242021429220, 1405242045978060],\n",
       "         ...,\n",
       "         [1380178036457300, 1380178043877860, 1380178073110160, ...,\n",
       "          1383803868560780, 1383803873171260, 1383803881291290],\n",
       "         [1416181918445480, 1416181947720530, 1416450183305100, ...,\n",
       "          1417218330791860, 1417218335436280, 1417218339962470],\n",
       "         [1413953002666180, 1413953094928090, 1413953104587660, ...,\n",
       "          1413956108827550, 1413956118323460, 1413956130192040]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 0, 1]])),\n",
       " (array([[1415177366268420, 1415177370462540, 1415177372695920, ...,\n",
       "          1417685252221060, 1417685254803980, 1417685257519260],\n",
       "         [1410163790076090, 1410163874531290, 1410163884329320, ...,\n",
       "          1413722109623430, 1413722133375980, 1413722139575220],\n",
       "         [1413982259192160, 1413982380503200, 1413982452934850, ...,\n",
       "          1415192101853830, 1415192130070190, 1415192235540850],\n",
       "         ...,\n",
       "         [1410741909282250, 1410741917890460, 1410741930393780, ...,\n",
       "          1414907243074670, 1414907248065370, 1414907253220120],\n",
       "         [1417231850374690, 1417231860340490, 1417231866900620, ...,\n",
       "          1417264019972020, 1417264021371390, 1417264025195790],\n",
       "         [1413904091201030, 1413904104956330, 1413904871846090, ...,\n",
       "          1414678537535630, 1414678544521090, 1414678547750410]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 0, 1, 1]])),\n",
       " (array([[1417862768425630, 1417862773974100, 1417862777160730, ...,\n",
       "          1417929256521640, 1417929259372950, 1417929262454580],\n",
       "         [1416558448386680, 1416558452131030, 1416558468715720, ...,\n",
       "          1416817864863890, 1416817870773810, 1416817874053170],\n",
       "         [1382137973699250, 1382137978236190, 1382137984747410, ...,\n",
       "          1382916353902790, 1382916361307600, 1382916364264530],\n",
       "         ...,\n",
       "         [1411028662103880, 1411028694113560, 1411028713182040, ...,\n",
       "          1411979032509620, 1411979035717820, 1411979039520180],\n",
       "         [1399278340204770, 1399278401328860, 1399278408189400, ...,\n",
       "          1416797922488040, 1416797936822650, 1416797950585600],\n",
       "         [1417682293020100, 1417682352358480, 1417682369093570, ...,\n",
       "          1419584342217540, 1419584347305520, 1419584364570680]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 0],\n",
       "         [0, 0, 0, ..., 1, 0, 1]])),\n",
       " (array([[1383111163415110, 1383111185062000, 1383111198869350, ...,\n",
       "          1383299627446730, 1383299640581870, 1383299645783760],\n",
       "         [1396321680600860, 1396322291123060, 1396322319409620, ...,\n",
       "          1396428969190130, 1396428974606320, 1396428979825640],\n",
       "         [1413793522898810, 1413793549524810, 1413793557943790, ...,\n",
       "          1415608320468760, 1415608339519580, 1415608364920330],\n",
       "         ...,\n",
       "         [1415616147094340, 1415616149583080, 1415616154632580, ...,\n",
       "          1415616947513690, 1415616950302090, 1415616955464820],\n",
       "         [1390276141329790, 1390359339564920, 1390359341694660, ...,\n",
       "          1390359947870040, 1390359950050540, 1390359951877650],\n",
       "         [1400825564909260, 1400852612699840, 1400852690016140, ...,\n",
       "          1402010744220150, 1402010747303440, 1402010750529890]]),\n",
       "  array([[0, 1, 1, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1393921979979880, 1394157842314090, 1394157875053560, ...,\n",
       "          1395295963516920, 1395295969097050, 1395295977961660],\n",
       "         [1394182990747010, 1394183045794600, 1394183113887450, ...,\n",
       "          1398412306453880, 1398412311755150, 1398412315422790],\n",
       "         [1394083003381710, 1394083161586140, 1394083226421730, ...,\n",
       "          1396502169096260, 1396502172393060, 1396502175147150],\n",
       "         ...,\n",
       "         [1388820805735640, 1388820820469360, 1388820828799760, ...,\n",
       "          1388825538962410, 1389187787899980, 1389188019784530],\n",
       "         [1417142931722680, 1417142939219710, 1417142949792780, ...,\n",
       "          1418353093760090, 1418353104501410, 1418353107205930],\n",
       "         [1418030904958240, 1418030908755070, 1418030918536960, ...,\n",
       "          1419239944548830, 1419239954094400, 1419239961571140]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1]])),\n",
       " (array([[1355811003435830, 1355811024171050, 1355811061145040, ...,\n",
       "          1357626995867910, 1357627000077800, 1357627015574980],\n",
       "         [1416835759475950, 1416835768541400, 1416835777519530, ...,\n",
       "          1417004525272110, 1417004529983080, 1417004534292130],\n",
       "         [1407205312592290, 1407205321021830, 1407205327568160, ...,\n",
       "          1409035371383670, 1409035375497410, 1409035377772280],\n",
       "         ...,\n",
       "         [1401345300099940, 1401345307712060, 1401345315831250, ...,\n",
       "          1402556090591100, 1402556093259620, 1402556095651100],\n",
       "         [1388742334094660, 1388742347471590, 1388742366275380, ...,\n",
       "          1402731032696160, 1402731034963460, 1402731038345210],\n",
       "         [1416400410799840, 1416400606228240, 1416400651180800, ...,\n",
       "          1418731464941790, 1418731468596210, 1418731471687210]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 0, 1, 1]])),\n",
       " (array([[1413206405649880, 1413206409309050, 1413206411285820, ...,\n",
       "          1413288004046340, 1413288009410510, 1413288010870000],\n",
       "         [1393560792410200, 1393560796335790, 1393560799399130, ...,\n",
       "          1393567974116010, 1393567976259580, 1393567978357850],\n",
       "         [1393379949584940, 1393380066795060, 1393380124389970, ...,\n",
       "          1398514270227240, 1398514286514720, 1398514293408660],\n",
       "         ...,\n",
       "         [1395815301059100, 1395815310832540, 1395815313141260, ...,\n",
       "          1395816053602070, 1395816056599260, 1395816058836950],\n",
       "         [1400566114199170, 1400566141414140, 1400566164017330, ...,\n",
       "          1400844892044210, 1400844895943840, 1400844900858910],\n",
       "         [1393480545226910, 1393480561857680, 1393480588442330, ...,\n",
       "          1411517540410360, 1411517544307930, 1411517547308890]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1380167528554070, 1380167551201240, 1380167565012510, ...,\n",
       "          1380368827130600, 1380368833287170, 1380368837919860],\n",
       "         [1415975480035510, 1415975484792090, 1415975501910230, ...,\n",
       "          1417351766175860, 1417351795642670, 1417351803354130],\n",
       "         [1397723383328490, 1397723429126300, 1397723466256840, ...,\n",
       "          1402388460291060, 1402388476904700, 1402388486085000],\n",
       "         ...,\n",
       "         [1387860756328440, 1387860780374850, 1387860796914920, ...,\n",
       "          1393149360182510, 1393149364601830, 1393149374433020],\n",
       "         [1380980587123580, 1380980596296570, 1380980600199190, ...,\n",
       "          1382180981250480, 1382180982281330, 1382180999750860],\n",
       "         [1412681593421820, 1412681633719400, 1412681742735440, ...,\n",
       "          1412943458391080, 1412943479425170, 1412943483085620]]),\n",
       "  array([[0, 0, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 0],\n",
       "         [0, 0, 1, ..., 0, 1, 0]])),\n",
       " (array([[1409821702945470, 1409821718173040, 1409821900787200, ...,\n",
       "          1409823714207390, 1409823718987790, 1409823728392330],\n",
       "         [1416201037987320, 1416201075249050, 1416201108934650, ...,\n",
       "          1417153844949390, 1417153859561230, 1417153872944860],\n",
       "         [1394440307598010, 1394440313221620, 1394440317523250, ...,\n",
       "          1399365507997660, 1399365511186490, 1399365514836510],\n",
       "         ...,\n",
       "         [1412567385745620, 1412567400440660, 1412567436792390, ...,\n",
       "          1414113820487020, 1414113836746580, 1414113890585250],\n",
       "         [1412578424803530, 1412578435368920, 1412578440971850, ...,\n",
       "          1415680977921940, 1415680986335240, 1415680988362420],\n",
       "         [1412245226094330, 1412245292380960, 1412245299341490, ...,\n",
       "          1413368045593580, 1413368048157560, 1413368103101250]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 1, 0, 0],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1387108886984180, 1387109238206380, 1387109471239630, ...,\n",
       "          1387286799420210, 1387286809254670, 1387286814405730],\n",
       "         [1383802574650060, 1383802580107050, 1383802584355610, ...,\n",
       "          1384407534102240, 1384407668194540, 1384407671591280],\n",
       "         [1416381461805420, 1416381783789280, 1416381822368630, ...,\n",
       "          1420615681639800, 1420615689281630, 1420615700144350],\n",
       "         ...,\n",
       "         [1388026366580370, 1388026394601220, 1388026410092150, ...,\n",
       "          1398672744356510, 1398672748432490, 1398672752087710],\n",
       "         [1418891984832370, 1418891988382140, 1418891991771390, ...,\n",
       "          1419578698623630, 1419578704088320, 1419578706434140],\n",
       "         [1411825214569710, 1411825219275890, 1411825221159790, ...,\n",
       "          1412143190119330, 1412143196068590, 1412143204736150]]),\n",
       "  array([[0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1399861472229540, 1399861476715010, 1399861482698380, ...,\n",
       "          1401862228024350, 1401862230734720, 1401862233434720],\n",
       "         [1398142414474720, 1398142425137170, 1398142438011150, ...,\n",
       "          1398143545085050, 1398143553901040, 1398143556361700],\n",
       "         [1400470347184740, 1400470366904180, 1400470402622600, ...,\n",
       "          1401071031492060, 1401071061157310, 1401071125860760],\n",
       "         ...,\n",
       "         [1419395990135290, 1419395993741440, 1419395997254520, ...,\n",
       "          1419396941504930, 1419396945747340, 1419396948948950],\n",
       "         [1383896345120180, 1383896354386590, 1383896359200510, ...,\n",
       "          1401439705751020, 1401439718900960, 1401439721592640],\n",
       "         [1396514820509370, 1396515116142570, 1396530556449870, ...,\n",
       "          1400203145614100, 1400203153314360, 1400203156258890]]),\n",
       "  array([[1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1385023571388690, 1385023596225740, 1385974911431500, ...,\n",
       "          1386835998088180, 1386836019309960, 1386836047377250],\n",
       "         [1395381742055930, 1395381756432970, 1395381801311690, ...,\n",
       "          1400221486165120, 1400221503747930, 1400221519778960],\n",
       "         [1382683636951230, 1382683670629880, 1382683743512420, ...,\n",
       "          1401439987570690, 1401439996060500, 1401439998433110],\n",
       "         ...,\n",
       "         [1404122187656140, 1404122241339350, 1404266806570390, ...,\n",
       "          1404887392637760, 1404887466572690, 1404887523752970],\n",
       "         [1398661324375520, 1398661337635560, 1398661347938540, ...,\n",
       "          1398920725050860, 1398920729265610, 1398920733780980],\n",
       "         [1395118327104840, 1395118357209790, 1395118386028490, ...,\n",
       "          1413443970999800, 1413443975046050, 1413443982443910]]),\n",
       "  array([[1, 0, 1, ..., 1, 0, 0],\n",
       "         [1, 0, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 0]])),\n",
       " (array([[1402278349969280, 1402278359535650, 1402278363346810, ...,\n",
       "          1411478159885840, 1411478167888840, 1411478178432240],\n",
       "         [1396515805404980, 1396515808756230, 1396515814691350, ...,\n",
       "          1399971278915560, 1399971284045670, 1399971287040390],\n",
       "         [1416805466763260, 1416805479357520, 1416805484206910, ...,\n",
       "          1416806922382360, 1416806927915210, 1416806939164470],\n",
       "         ...,\n",
       "         [1415839239286520, 1415839242384830, 1415839245794720, ...,\n",
       "          1418033499272150, 1418033501349680, 1418033503448860],\n",
       "         [1412583687604240, 1412583694546870, 1412583699444880, ...,\n",
       "          1416538749019380, 1416538755037360, 1416538762569960],\n",
       "         [1381068029948660, 1381068034464780, 1381068038603610, ...,\n",
       "          1412346552281640, 1412346561043540, 1412346567603170]]),\n",
       "  array([[1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1414668685214070, 1414668694752990, 1414668732315800, ...,\n",
       "          1415014053511230, 1415014062373700, 1415014085466320],\n",
       "         [1413187021840270, 1413187122262570, 1413187130438370, ...,\n",
       "          1415001535031400, 1415001537095300, 1415001539759920],\n",
       "         [1413698998957620, 1413699095810200, 1413699212753110, ...,\n",
       "          1413891326926370, 1413891430042850, 1413891460154310],\n",
       "         ...,\n",
       "         [1389582596959020, 1389668811295540, 1389668830847740, ...,\n",
       "          1393822732218850, 1393822741974650, 1393822754246800],\n",
       "         [1402410922149810, 1402410953302430, 1402411142230390, ...,\n",
       "          1411729879472570, 1411729884040900, 1411729891457490],\n",
       "         [1412992937888310, 1412992958234890, 1412992964136110, ...,\n",
       "          1413725612254490, 1413725616707600, 1413725621141560]]),\n",
       "  array([[0, 0, 0, ..., 1, 0, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1]])),\n",
       " (array([[1381218767771060, 1381234871382200, 1381234903088940, ...,\n",
       "          1392800428370320, 1392800433277510, 1392800438197710],\n",
       "         [1410168864958690, 1410168867398130, 1410168869548070, ...,\n",
       "          1410183515556620, 1410183523880300, 1410183530703820],\n",
       "         [1397044368983750, 1397044371402920, 1397044375058010, ...,\n",
       "          1401795832340240, 1401795835387930, 1401795839057580],\n",
       "         ...,\n",
       "         [1413794345452880, 1413794373118750, 1413794388595590, ...,\n",
       "          1419496253706640, 1419496264702880, 1419496274102380],\n",
       "         [1401949162873590, 1401949165331980, 1401949169582960, ...,\n",
       "          1402554536663090, 1402554540015910, 1402554541364110],\n",
       "         [1389927735143750, 1389927737860090, 1389927740201010, ...,\n",
       "          1420873853692530, 1420873858525930, 1420873861864880]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1388718956309160, 1388718971632720, 1388718984616290, ...,\n",
       "          1392952250261420, 1392952257164260, 1392952265158920],\n",
       "         [1418966133427370, 1418966144504800, 1418966153772380, ...,\n",
       "          1419311837172710, 1419311841843840, 1419311849034150],\n",
       "         [1412305419892920, 1412305433266160, 1412305448587770, ...,\n",
       "          1417150532798760, 1417657184346330, 1418863938865000],\n",
       "         ...,\n",
       "         [1369977441909670, 1369977462442250, 1369977474980000, ...,\n",
       "          1381198647245590, 1381198655416600, 1381198663115130],\n",
       "         [1387854061342030, 1387854070087250, 1387854078378330, ...,\n",
       "          1389182962317030, 1389182967995500, 1389182973617950],\n",
       "         [1416539435645720, 1416539437530460, 1416539439413380, ...,\n",
       "          1416831102203930, 1416831105619680, 1416831108713620]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1420020105020240, 1420020119910320, 1420020128340940, ...,\n",
       "          1420454924353610, 1420454927323540, 1420454929458630],\n",
       "         [1417492743513680, 1417492746627170, 1417492748834240, ...,\n",
       "          1419686317410960, 1419686319817400, 1419686322135380],\n",
       "         [1415014099594730, 1415014103480300, 1415014106043120, ...,\n",
       "          1415621329681960, 1415621331378380, 1415621334021180],\n",
       "         ...,\n",
       "         [1416298975241270, 1416298977869710, 1416298980231480, ...,\n",
       "          1416903888279360, 1416903890436370, 1416903892314360],\n",
       "         [1415599335782540, 1415599340734240, 1415599344201020, ...,\n",
       "          1418383738872490, 1418383747347060, 1418383771454400],\n",
       "         [1408530074921870, 1408530084382920, 1408530089699150, ...,\n",
       "          1408539396242490, 1408539405158800, 1408539412840180]]),\n",
       "  array([[0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 0, 0, 0]])),\n",
       " (array([[1419914210398100, 1419914224050360, 1419914231166870, ...,\n",
       "          1420427893957810, 1420427912328090, 1420427913307730],\n",
       "         [1401065578087930, 1401065581168460, 1401065586851040, ...,\n",
       "          1402967566405320, 1402967568879600, 1402967572123530],\n",
       "         [1388823186500520, 1388823198482300, 1388823203560390, ...,\n",
       "          1389175332059780, 1389175334739070, 1389175338154940],\n",
       "         ...,\n",
       "         [1414732187698880, 1414732196565070, 1414732199409190, ...,\n",
       "          1416805118545600, 1416805120683630, 1416805124803060],\n",
       "         [1412079542852300, 1412079563113740, 1412079699943460, ...,\n",
       "          1414134565438880, 1414134573479840, 1414134581279280],\n",
       "         [1400470638279090, 1400555628891650, 1400555808311690, ...,\n",
       "          1402458376495070, 1402458531090590, 1402458564791700]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 0, 1, 0]])),\n",
       " (array([[1411540286459450, 1411540291043590, 1411540304598700, ...,\n",
       "          1411906321246840, 1411906338406930, 1411906342701760],\n",
       "         [1411383366442400, 1411383370214800, 1411383373638760, ...,\n",
       "          1411391067208290, 1411391070121000, 1411391073825410],\n",
       "         [1378344176401460, 1378344215860830, 1378344257042060, ...,\n",
       "          1384394179273580, 1384394198514060, 1384394209893560],\n",
       "         ...,\n",
       "         [1416285813145930, 1416285821369920, 1416285829316740, ...,\n",
       "          1416357953842280, 1416357963661390, 1416357976295290],\n",
       "         [1415866424088750, 1416211767205680, 1416211778846820, ...,\n",
       "          1418026632993200, 1418026638335340, 1418026645452470],\n",
       "         [1384319584728120, 1384319631541670, 1384319654106600, ...,\n",
       "          1386039070566710, 1386039075733790, 1386039078032570]]),\n",
       "  array([[1, 0, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1418646926156270, 1418646928837980, 1418646942376080, ...,\n",
       "          1418823195278690, 1418823197539380, 1418823199498090],\n",
       "         [1394251135823390, 1394251146658430, 1394251152132250, ...,\n",
       "          1397219474704070, 1397219476730470, 1397219482191280],\n",
       "         [1414052044909310, 1414052051131240, 1414052056177890, ...,\n",
       "          1415261549105690, 1415261551938250, 1415261555111680],\n",
       "         ...,\n",
       "         [1416891744235800, 1416891746261310, 1416891749691530, ...,\n",
       "          1417150074078640, 1417150077567310, 1417150080869990],\n",
       "         [1384491891629350, 1388034824139370, 1388034888408080, ...,\n",
       "          1403231150519600, 1403231155876440, 1403231164761390],\n",
       "         [1388715242786110, 1388715285172130, 1388715355155360, ...,\n",
       "          1389589807718980, 1389589816206120, 1389589837334210]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1402877397366350, 1402877467734030, 1402877536027580, ...,\n",
       "          1411634310033660, 1411634321682270, 1411634326030330],\n",
       "         [1418957833872780, 1418957841881080, 1418957850190050, ...,\n",
       "          1420433812331060, 1420433817371600, 1420433819688460],\n",
       "         [1416472577833410, 1416472588271370, 1416472591383870, ...,\n",
       "          1417078772539380, 1417078773422140, 1417078774490290],\n",
       "         ...,\n",
       "         [1397962404718760, 1397962438171540, 1397962483423380, ...,\n",
       "          1398256126460360, 1398256137185760, 1398256145448530],\n",
       "         [1395905603488020, 1395905605654170, 1395905608418510, ...,\n",
       "          1395907021497030, 1395907023051560, 1395907024671590],\n",
       "         [1389769052100920, 1389769067183660, 1389769124419400, ...,\n",
       "          1390129663719370, 1390129666367130, 1390129670142800]]),\n",
       "  array([[1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1401278456782210, 1401278466864460, 1401278481410880, ...,\n",
       "          1402488374172110, 1402488388980690, 1402488399802220],\n",
       "         [1393836913159070, 1393836916418360, 1393836920177330, ...,\n",
       "          1394459759371490, 1394459762585280, 1394459764473340],\n",
       "         [1419743109136460, 1419743117254400, 1419743119714380, ...,\n",
       "          1419760937151870, 1419760951316640, 1419760952622140],\n",
       "         ...,\n",
       "         [1412255662137020, 1412255668233020, 1412255682283500, ...,\n",
       "          1420602070063390, 1420602081312770, 1420602085961690],\n",
       "         [1407724049398190, 1407724100105020, 1407724108411590, ...,\n",
       "          1420704696991680, 1420704699998560, 1420704704019620],\n",
       "         [1412583899723470, 1412583905025400, 1412583909863580, ...,\n",
       "          1413879463599400, 1413879467156650, 1413879469300690]]),\n",
       "  array([[1, 1, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1416200578479760, 1416200645998230, 1416200705755480, ...,\n",
       "          1417669588229310, 1417669597920880, 1417669606895010],\n",
       "         [1402405493695120, 1402405504528160, 1402405519912220, ...,\n",
       "          1404135776678960, 1404135780373580, 1404135784091030],\n",
       "         [1393908429088960, 1393924728631150, 1393924750836800, ...,\n",
       "          1394118183060960, 1394118189517840, 1394118194007520],\n",
       "         ...,\n",
       "         [1411211052174150, 1411211055545790, 1411211058324980, ...,\n",
       "          1418491320055630, 1418491321439960, 1418491322784830],\n",
       "         [1415013316320100, 1415013329771600, 1415013341239270, ...,\n",
       "          1416116158233220, 1416116160638370, 1416116164479730],\n",
       "         [1364709925466940, 1364709935069860, 1364709947210980, ...,\n",
       "          1365924801354610, 1365924812119240, 1365924817230980]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1]])),\n",
       " (array([[1416488032460850, 1416488034253180, 1416488036613780, ...,\n",
       "          1416488829613930, 1416488832864650, 1416488835189300],\n",
       "         [1392364743506030, 1392364889942590, 1392365055857150, ...,\n",
       "          1397552946184440, 1397552974322670, 1397552998939640],\n",
       "         [1406097971980040, 1406097980326000, 1406097987651460, ...,\n",
       "          1406529543541450, 1406529550073640, 1406529557241070],\n",
       "         ...,\n",
       "         [1418966107159510, 1418966134055890, 1418966138300420, ...,\n",
       "          1419225313775940, 1419225317433600, 1419225322439720],\n",
       "         [1387444971821180, 1389325654618410, 1389325665053450, ...,\n",
       "          1396531482477550, 1396531489074020, 1396531538074470],\n",
       "         [1384829903261890, 1384829910089470, 1384829912991960, ...,\n",
       "          1386810585324870, 1386810608079880, 1386810620944120]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 0, ..., 1, 0, 1]])),\n",
       " (array([[1402927992944440, 1402928033098340, 1402959837843090, ...,\n",
       "          1404614624835990, 1404614631107470, 1404614640487640],\n",
       "         [1401072417625750, 1401072426587230, 1401072434659400, ...,\n",
       "          1407467676010150, 1407467682417100, 1407467688597840],\n",
       "         [1404972873624260, 1404972925567860, 1404973199973170, ...,\n",
       "          1413806184714720, 1413806190020070, 1413806203778430],\n",
       "         ...,\n",
       "         [1396876074785910, 1396876085164390, 1396876097636940, ...,\n",
       "          1412494478224410, 1412494479343510, 1412494482327010],\n",
       "         [1387161971701690, 1387161983166140, 1387161996797020, ...,\n",
       "          1398253823064560, 1398253828384760, 1398253832779350],\n",
       "         [1401935169082110, 1401935244733140, 1401935269422630, ...,\n",
       "          1404789968101330, 1404789971264160, 1404789974183610]]),\n",
       "  array([[0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1402544285980250, 1402621365556180, 1402621382158200, ...,\n",
       "          1402984397795430, 1402984401778450, 1402984405360150],\n",
       "         [1416015340044960, 1416015375057920, 1416016241198040, ...,\n",
       "          1416017369710370, 1416017370741900, 1416017373252520],\n",
       "         [1377869298239570, 1377869309496020, 1377869319036700, ...,\n",
       "          1378216898388110, 1378216901644270, 1378280313559320],\n",
       "         ...,\n",
       "         [1413528640606740, 1413528658187020, 1413528666671290, ...,\n",
       "          1419663525510990, 1419663528316030, 1419663530071700],\n",
       "         [1398513151259960, 1410585417930730, 1410699663680370, ...,\n",
       "          1411131386259260, 1411131405978600, 1411131418867810],\n",
       "         [1389768903833210, 1389768954738150, 1389769049116780, ...,\n",
       "          1389949840850290, 1389949843064350, 1389949846553730]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1418526680034530, 1418526727128840, 1419249023480180, ...,\n",
       "          1419251967918890, 1419251970354780, 1419251972640630],\n",
       "         [1416285468914670, 1416285493025600, 1416285501973090, ...,\n",
       "          1416357992068710, 1416357999612210, 1416358005492530],\n",
       "         [1413274361835670, 1413274485350680, 1413274492625420, ...,\n",
       "          1414398200829290, 1414398250380630, 1414398255957300],\n",
       "         ...,\n",
       "         [1412412188872610, 1412412191559370, 1412412194235120, ...,\n",
       "          1415780182691820, 1415780185174900, 1415780187712680],\n",
       "         [1418728378365120, 1418728382763570, 1418728386345550, ...,\n",
       "          1418730137603900, 1418730141886660, 1418730144634930],\n",
       "         [1419655117660920, 1419655120266980, 1419655122899170, ...,\n",
       "          1419825519516000, 1419825520622620, 1419825522965600]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1409882668837510, 1409882685163870, 1409882808512690, ...,\n",
       "          1412514606976100, 1412514622225350, 1412514638593900],\n",
       "         [1400829334847220, 1400829464324740, 1401158624016130, ...,\n",
       "          1416979239191110, 1416979246772090, 1416979255628760],\n",
       "         [1385733817576670, 1385733839078950, 1385733882508460, ...,\n",
       "          1388112095764270, 1388112098572150, 1388112103043460],\n",
       "         ...,\n",
       "         [1392860529239770, 1392860540356020, 1392860550239070, ...,\n",
       "          1392959795270950, 1392959800836890, 1392959808197710],\n",
       "         [1387514939970640, 1387514950061770, 1387514956705220, ...,\n",
       "          1395882100437880, 1395882107106150, 1395882112320280],\n",
       "         [1416395896017280, 1416395933354290, 1416395956685870, ...,\n",
       "          1416486424694600, 1416486428351280, 1416486434722500]]),\n",
       "  array([[1, 0, 1, ..., 1, 1, 0],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 0, 0]])),\n",
       " (array([[1401844647513100, 1402621393761530, 1402621414745520, ...,\n",
       "          1417422467053230, 1417422474361150, 1417422481171420],\n",
       "         [1382513504417240, 1382513507117020, 1382513513273930, ...,\n",
       "          1384691213293070, 1384738916694100, 1384738917865810],\n",
       "         [1413248375547260, 1413248380288880, 1413248384737790, ...,\n",
       "          1419391966735580, 1419391968426180, 1419391969890980],\n",
       "         ...,\n",
       "         [1403575106095780, 1403575110289370, 1403575114821140, ...,\n",
       "          1416896933579840, 1416896935969600, 1416896939094650],\n",
       "         [1419558747198220, 1419558763228570, 1419558768356070, ...,\n",
       "          1419592211248680, 1419592214549860, 1419592218425880],\n",
       "         [1404274727208110, 1404274729759710, 1404274732196950, ...,\n",
       "          1406261100579100, 1406261104489840, 1406261110607230]]),\n",
       "  array([[0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1]])),\n",
       " (array([[1387077590843510, 1387077593047500, 1387077595130300, ...,\n",
       "          1387347800092650, 1387347802858780, 1387347805962030],\n",
       "         [1418179473076690, 1418179604083830, 1418179624668970, ...,\n",
       "          1418259110719920, 1418259120861420, 1418259132864740],\n",
       "         [1416821182318180, 1416821186784640, 1416821190642710, ...,\n",
       "          1417080613303450, 1417080626024030, 1417080660164780],\n",
       "         ...,\n",
       "         [1393925571920330, 1393925692849380, 1393925771899340, ...,\n",
       "          1396945939256080, 1400855294850610, 1401857591053660],\n",
       "         [1413937079027290, 1413937086419290, 1413937095449160, ...,\n",
       "          1418343080105190, 1418343084795590, 1418343098936840],\n",
       "         [1382344795845730, 1382344854492080, 1382344868043480, ...,\n",
       "          1382426223251370, 1382426228147340, 1382426235363430]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 0, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1415345695991180, 1415345698827690, 1415345701258270, ...,\n",
       "          1415852389226670, 1415852391210850, 1415852392937760],\n",
       "         [1400730586736010, 1400730589987210, 1400730594403270, ...,\n",
       "          1417003115003630, 1417003119375840, 1417003123568330],\n",
       "         [1392251573342570, 1392251589781960, 1392251601695800, ...,\n",
       "          1394518817049060, 1394518819168150, 1394518821794800],\n",
       "         ...,\n",
       "         [1414483693068720, 1414483706065950, 1414483711723780, ...,\n",
       "          1419322862386230, 1419322865887120, 1419322869013150],\n",
       "         [1398346381457180, 1398346393033350, 1402491787746310, ...,\n",
       "          1403341220957330, 1403341223797810, 1403341226227250],\n",
       "         [1378342169917680, 1378342185495610, 1378342197775510, ...,\n",
       "          1384223343668760, 1384223354597410, 1384223368498080]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 0, 0, 1]])),\n",
       " (array([[1414993679762390, 1414993699249830, 1415599748610690, ...,\n",
       "          1416808145549630, 1416808148262440, 1416808150886140],\n",
       "         [1399955166321570, 1399955183955860, 1399955218214700, ...,\n",
       "          1400638508511140, 1400638517627840, 1400638522318000],\n",
       "         [1404714843078520, 1404714859788120, 1404714888703600, ...,\n",
       "          1405326869049850, 1405326872227220, 1405326875024330],\n",
       "         ...,\n",
       "         [1407895433389460, 1407895441475180, 1407895459674430, ...,\n",
       "          1411460325696480, 1411460392928860, 1411460407804350],\n",
       "         [1385368868443530, 1385627956453990, 1385628005207970, ...,\n",
       "          1386837787407230, 1386837818042850, 1386837833779730],\n",
       "         [1401443780939600, 1401443816847070, 1401443840648280, ...,\n",
       "          1401535365162770, 1401535389092600, 1401535401544550]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 0, 0, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1393988350393520, 1393988380619170, 1393988389781890, ...,\n",
       "          1410761409416780, 1410761413846020, 1410761418063060],\n",
       "         [1413014824634820, 1413014828895090, 1413014831977380, ...,\n",
       "          1414156302749140, 1414156304233080, 1414156306045880],\n",
       "         [1416539220125880, 1416539221239810, 1416539232844650, ...,\n",
       "          1416903695576030, 1416903697065270, 1416903700940500],\n",
       "         ...,\n",
       "         [1404719597902860, 1404719780331260, 1404719814195350, ...,\n",
       "          1405492552245200, 1405492556709810, 1405492561292530],\n",
       "         [1416962060072240, 1416962065483770, 1416962070712130, ...,\n",
       "          1417519429843970, 1417519432076540, 1417519434326450],\n",
       "         [1417515940366120, 1417515944857200, 1417515948057760, ...,\n",
       "          1417612564101170, 1417612566205050, 1417612568590100]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1415798449945680, 1415798523580180, 1415798570071860, ...,\n",
       "          1418045740133190, 1418045744043330, 1418045748412320],\n",
       "         [1400216665859950, 1400216677381430, 1400216685656080, ...,\n",
       "          1401426959287270, 1401426963118430, 1401426969878110],\n",
       "         [1386661234816370, 1386661248104600, 1386661266396070, ...,\n",
       "          1387966629778860, 1387966633294530, 1387966636826250],\n",
       "         ...,\n",
       "         [1408241309093470, 1408242314683090, 1408242467076380, ...,\n",
       "          1408279839463080, 1408279856323850, 1408279861794880],\n",
       "         [1395125636584490, 1395125640521570, 1395125745341160, ...,\n",
       "          1403252953877040, 1403252964260880, 1403252966248070],\n",
       "         [1396924701939430, 1396924758900770, 1396924823038010, ...,\n",
       "          1397113182558220, 1397113220898170, 1397113265412620]]),\n",
       "  array([[1, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 0]])),\n",
       " (array([[1393915314639270, 1393915324549030, 1393915342397440, ...,\n",
       "          1395121132081620, 1395121140365520, 1395121143639080],\n",
       "         [1382078001066180, 1382078073582380, 1382078184327410, ...,\n",
       "          1397721974128890, 1397721987458770, 1402302373713470],\n",
       "         [1396502602131640, 1396502606556990, 1396502610011170, ...,\n",
       "          1397013449526130, 1397013451505630, 1397013453183690],\n",
       "         ...,\n",
       "         [1417830601730030, 1417830636606110, 1417830670844440, ...,\n",
       "          1417917951632840, 1417917988387200, 1417918007713430],\n",
       "         [1418343537525160, 1418343541419980, 1418343544659060, ...,\n",
       "          1418522047943470, 1418522050147070, 1418522052173730],\n",
       "         [1419486115767010, 1419486123738950, 1419486130681730, ...,\n",
       "          1419487633291830, 1419487637251220, 1419487645055710]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1393914170130290, 1393914201712850, 1393914226422860, ...,\n",
       "          1393915375770020, 1393915378988600, 1393915381103360],\n",
       "         [1412595920579040, 1412595926376890, 1412595934776440, ...,\n",
       "          1415618609076940, 1415618611187390, 1415618613853340],\n",
       "         [1409146328034820, 1409146346374320, 1409146350622730, ...,\n",
       "          1409664466073870, 1409664468340840, 1409664471034480],\n",
       "         ...,\n",
       "         [1404293228254990, 1404293237212120, 1404293242544760, ...,\n",
       "          1419164035972960, 1419164047257880, 1419164053042660],\n",
       "         [1380267870400830, 1380267880022930, 1380267903429550, ...,\n",
       "          1386127077666510, 1386127081576590, 1386127084926390],\n",
       "         [1420595394273060, 1420595407453450, 1420595430386910, ...,\n",
       "          1420703692395070, 1420703696612570, 1420703700852430]]),\n",
       "  array([[0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1415693561936660, 1415693580472830, 1415693582735090, ...,\n",
       "          1415771368087050, 1415771370899410, 1415771380666040],\n",
       "         [1413032611150930, 1413032618435140, 1413032622446430, ...,\n",
       "          1414414003619540, 1414414007297680, 1414414010876090],\n",
       "         [1393892716160010, 1393892723262680, 1393892730158450, ...,\n",
       "          1394064838635600, 1394064848313370, 1394064854247700],\n",
       "         ...,\n",
       "         [1398837994977800, 1398838003078150, 1398838062185400, ...,\n",
       "          1398844471373310, 1398844473263750, 1398844475421080],\n",
       "         [1415590490945660, 1415590493578540, 1415590496317700, ...,\n",
       "          1416800558934940, 1416800561058460, 1416800563995330],\n",
       "         [1413896706342680, 1413896740673370, 1413896748478080, ...,\n",
       "          1414071114353990, 1414071118165410, 1414071132185890]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 0]])),\n",
       " (array([[1394524049776310, 1394524108794700, 1394524147799330, ...,\n",
       "          1403790481005230, 1403790491403360, 1403790493955860],\n",
       "         [1382351913280510, 1382351921070260, 1382351924771630, ...,\n",
       "          1396960951835920, 1396960955222220, 1396960957222290],\n",
       "         [1394365744245680, 1394365747824930, 1394365752157510, ...,\n",
       "          1401084943423850, 1401084948307320, 1401084950743760],\n",
       "         ...,\n",
       "         [1413461510845600, 1413461524206550, 1413461537674100, ...,\n",
       "          1415442539750630, 1415442545275310, 1415442551314060],\n",
       "         [1413251557987130, 1413251601256250, 1413251616537600, ...,\n",
       "          1414116508943320, 1414116521197700, 1414116533843430],\n",
       "         [1383553558528940, 1383553641688940, 1383553816546730, ...,\n",
       "          1401093022891980, 1401093042633360, 1401093046143610]]),\n",
       "  array([[1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 0, 0],\n",
       "         [0, 1, 1, ..., 0, 1, 1]])),\n",
       " (array([[1394460902374830, 1394460921037740, 1394460939952900, ...,\n",
       "          1411651837876460, 1411651841031040, 1411651856359630],\n",
       "         [1417073670471230, 1417073675720290, 1417073684072760, ...,\n",
       "          1417419385217930, 1417419386876490, 1417419388651170],\n",
       "         [1418659116088480, 1418742543024100, 1418743610158200, ...,\n",
       "          1419865209578100, 1419865220581840, 1419865232327160],\n",
       "         ...,\n",
       "         [1420803770152850, 1420803781505530, 1420803790407650, ...,\n",
       "          1420854292874640, 1420854299666310, 1420854302550620],\n",
       "         [1380778363125360, 1380778372102110, 1380778377344310, ...,\n",
       "          1381988351143540, 1381988430373010, 1381988432493070],\n",
       "         [1419915498260920, 1419915519770250, 1419915521081040, ...,\n",
       "          1420433190403290, 1420433195151010, 1420433199534090]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1]])),\n",
       " (array([[1406096330416420, 1406096380946890, 1406096398107790, ...,\n",
       "          1406870564886380, 1406870567302770, 1406870575030400],\n",
       "         [1393476563267540, 1393476568376440, 1393476574503250, ...,\n",
       "          1395119518670700, 1395119521541820, 1395119523545830],\n",
       "         [1386829998867490, 1392626305819830, 1392972417446230, ...,\n",
       "          1397202070099910, 1397202072829380, 1397202077606820],\n",
       "         ...,\n",
       "         [1402445549721060, 1402445586529890, 1402445625366550, ...,\n",
       "          1407292713570970, 1407292718434130, 1407292722760890],\n",
       "         [1413794339871670, 1413794343535970, 1413794349623710, ...,\n",
       "          1413879903709960, 1413879914686670, 1413879925204050],\n",
       "         [1392267786913860, 1392267829110310, 1392267846837760, ...,\n",
       "          1392427703823490, 1392427724153250, 1392427750139050]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 0],\n",
       "         [0, 1, 0, ..., 1, 1, 0]])),\n",
       " (array([[1395281068645450, 1395281076196010, 1395281084978420, ...,\n",
       "          1419311515275270, 1419311517477200, 1419311519695480],\n",
       "         [1373593590531220, 1373593723104860, 1373593797315560, ...,\n",
       "          1399519311472440, 1399519341062390, 1399519384490840],\n",
       "         [1409574592209200, 1409574719292260, 1409574802014830, ...,\n",
       "          1416221812547430, 1416221835886490, 1416308672523900],\n",
       "         ...,\n",
       "         [1415265801487270, 1415699342357520, 1415699351481860, ...,\n",
       "          1415782385149310, 1415782392046560, 1415782396330740],\n",
       "         [1403067839008190, 1403067950393930, 1403067954156240, ...,\n",
       "          1410265636881680, 1410265641721140, 1410265645096570],\n",
       "         [1416302171859880, 1416302175956910, 1416302179469250, ...,\n",
       "          1419647175464780, 1419647177310010, 1419647180232910]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1419176295796670, 1419176299065690, 1419176301686670, ...,\n",
       "          1420733832359920, 1420733848125160, 1420733850704060],\n",
       "         [1415001315138280, 1415001326868890, 1415001333192540, ...,\n",
       "          1415004266084170, 1415004272720400, 1415004280118560],\n",
       "         [1412583666571950, 1412583673444740, 1412583681022540, ...,\n",
       "          1417077423049560, 1417077425309240, 1417077427587180],\n",
       "         ...,\n",
       "         [1400731067874700, 1400731096570510, 1400731124239390, ...,\n",
       "          1417487686819720, 1417487692227290, 1417487714604440],\n",
       "         [1400228666269720, 1400228668877660, 1400228670776200, ...,\n",
       "          1400230048601860, 1400230049401470, 1400230050397230],\n",
       "         [1412082540138230, 1412082576060970, 1412082698646580, ...,\n",
       "          1412250465301290, 1412250500673440, 1412250532930570]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 1, 0]])),\n",
       " (array([[1400826796604440, 1400826798973530, 1400826801122510, ...,\n",
       "          1402036290068460, 1402036291839480, 1402036293643520],\n",
       "         [1416472674941210, 1416472681141460, 1416472685497300, ...,\n",
       "          1417680519432540, 1417680521771280, 1417680524780670],\n",
       "         [1383209290329180, 1383640102122220, 1383640134541630, ...,\n",
       "          1388046388938160, 1388046409717050, 1388046429756510],\n",
       "         ...,\n",
       "         [1398153904864200, 1398153985891810, 1398154007789410, ...,\n",
       "          1400373449502550, 1400373456411290, 1400373467170130],\n",
       "         [1367217206778950, 1367217867122200, 1367217997443370, ...,\n",
       "          1369798535107720, 1369798540818340, 1369798545956110],\n",
       "         [1407377759372000, 1407377906588240, 1407378022539060, ...,\n",
       "          1407725340510370, 1407725355469650, 1407725365103090]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 0, 0, 1]])),\n",
       " (array([[1395797443852300, 1395797457281160, 1395797469398530, ...,\n",
       "          1396442109092580, 1396442120005640, 1396442131787870],\n",
       "         [1414242860450280, 1414242862837690, 1414242865884430, ...,\n",
       "          1416143113284540, 1416143116031440, 1416143118172910],\n",
       "         [1413804899699140, 1413804902117800, 1413804905248800, ...,\n",
       "          1413805550070980, 1413805551598190, 1413805553762970],\n",
       "         ...,\n",
       "         [1417315859244860, 1417315863341740, 1417315866859430, ...,\n",
       "          1419135014090460, 1419135016986100, 1419135019314130],\n",
       "         [1412595240883960, 1412595244991580, 1412595249547660, ...,\n",
       "          1412597460230890, 1412597464478100, 1412597467496170],\n",
       "         [1397462531740380, 1397462538940120, 1397462542308980, ...,\n",
       "          1398397773291270, 1398397776914770, 1398397779173360]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1411260625502940, 1411260662623580, 1411278307003580, ...,\n",
       "          1411824457873700, 1411824527925510, 1411824575669380],\n",
       "         [1418114003424880, 1418114008080050, 1418114012212120, ...,\n",
       "          1419325285091350, 1419325286323810, 1419325291353010],\n",
       "         [1415253720644310, 1415253724165070, 1415253727720910, ...,\n",
       "          1419512860040130, 1419512862028790, 1419512864234460],\n",
       "         ...,\n",
       "         [1413901717504310, 1413901796567590, 1413901800595570, ...,\n",
       "          1414056630132600, 1414056632647580, 1414056637672870],\n",
       "         [1411388688692110, 1411388691552530, 1411388693764590, ...,\n",
       "          1413520973519090, 1413520977494320, 1413520980974710],\n",
       "         [1377327251051400, 1377327256059050, 1377327287770800, ...,\n",
       "          1377444357619810, 1377444362099960, 1377444365455180]]),\n",
       "  array([[0, 0, 1, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1412143972605230, 1412143976746480, 1412143979479620, ...,\n",
       "          1413971874488210, 1413971877546440, 1413971879992530],\n",
       "         [1416203770626430, 1416203774318600, 1416203778763250, ...,\n",
       "          1416317525587990, 1416317532570850, 1416317538134030],\n",
       "         [1388825728093160, 1388825741695760, 1400157316002950, ...,\n",
       "          1420894034228880, 1420894036827750, 1420894040572160],\n",
       "         ...,\n",
       "         [1392868387823490, 1392868393763570, 1392868397622360, ...,\n",
       "          1396496272052900, 1396496275181740, 1396496287357980],\n",
       "         [1405348491096120, 1405348494942560, 1405348498540200, ...,\n",
       "          1407930099484160, 1407939186696450, 1407939194232200],\n",
       "         [1415356725280410, 1415356734706660, 1415356745518420, ...,\n",
       "          1415620113270430, 1415620117054260, 1415620119642340]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1387328887686160, 1387328957863310, 1387620655772090, ...,\n",
       "          1394588097714420, 1394588119698670, 1394588136536910],\n",
       "         [1398166652640030, 1398166655808430, 1398166658521360, ...,\n",
       "          1405561650881590, 1405561688277330, 1405561691105560],\n",
       "         [1409569004164710, 1409569032900070, 1410089244483950, ...,\n",
       "          1411564838134280, 1411564841930280, 1411564849158450],\n",
       "         ...,\n",
       "         [1401181131083480, 1401181142718750, 1401181151911780, ...,\n",
       "          1403252242529690, 1403252249794580, 1403252255694980],\n",
       "         [1368060020648830, 1368060055507930, 1368060087380670, ...,\n",
       "          1368100042543950, 1368100046565100, 1368100052453650],\n",
       "         [1389765546865440, 1389765556830450, 1389765573838310, ...,\n",
       "          1406774386625540, 1406774391101580, 1406774392556620]]),\n",
       "  array([[0, 0, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1404264230209820, 1404264234890790, 1404264238453480, ...,\n",
       "          1412306339482420, 1412306340949640, 1412306345331040],\n",
       "         [1397706464127960, 1397706484424170, 1397706498819920, ...,\n",
       "          1419903458255050, 1419903465461810, 1419903469082780],\n",
       "         [1401343779160910, 1401343863837820, 1401417041441060, ...,\n",
       "          1401948765319960, 1401948793969150, 1401948797744180],\n",
       "         ...,\n",
       "         [1383541907351800, 1383541926587330, 1383541940273790, ...,\n",
       "          1395107437122930, 1395107449313390, 1395107456906420],\n",
       "         [1396944729283490, 1396944762873210, 1396944768767540, ...,\n",
       "          1399342566343240, 1399342589563220, 1399342663557960],\n",
       "         [1378258805637730, 1378258828804030, 1378259912677530, ...,\n",
       "          1378704242534380, 1378704250729220, 1378704259052640]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1414644601599340, 1414644612578280, 1414644918921350, ...,\n",
       "          1416287478276540, 1416287483361230, 1416287490906860],\n",
       "         [1400132105087660, 1400132118198930, 1400132125219330, ...,\n",
       "          1401871090254520, 1401871098591120, 1401871105052210],\n",
       "         [1396002867558680, 1396002908557060, 1396002976714780, ...,\n",
       "          1400596182788520, 1400596184996190, 1400596187072160],\n",
       "         ...,\n",
       "         [1416477399687950, 1416826521964960, 1416826724229310, ...,\n",
       "          1419403866838790, 1419403875652480, 1419403877512400],\n",
       "         [1411380955794880, 1411380966815780, 1411380971060860, ...,\n",
       "          1412597484433740, 1412597493590830, 1412597497607670],\n",
       "         [1409923044733700, 1409923050515920, 1409923056265160, ...,\n",
       "          1417180458098210, 1417180460595100, 1417180463375130]]),\n",
       "  array([[1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1354839657592840, 1354839663767550, 1354839670310120, ...,\n",
       "          1356767347450630, 1356767349423760, 1356767351569590],\n",
       "         [1418103482539160, 1418103498243600, 1418103520115320, ...,\n",
       "          1418187613334310, 1418187629042740, 1418187666716650],\n",
       "         [1412324772078930, 1412324810464030, 1412324821023970, ...,\n",
       "          1412836372101680, 1412836375720950, 1412836378245280],\n",
       "         ...,\n",
       "         [1400138185901600, 1400138198151950, 1400138763205860, ...,\n",
       "          1400744316292640, 1400744319513460, 1400744322535120],\n",
       "         [1382853334794250, 1382853348669100, 1382853360682000, ...,\n",
       "          1385112879618770, 1385112903550730, 1385113259398050],\n",
       "         [1417758121950440, 1417758138961170, 1417758317777660, ...,\n",
       "          1419810725825690, 1419810728384370, 1419810730840210]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 0],\n",
       "         [1, 1, 0, ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1399516522528580, 1399516531214300, 1399516545865350, ...,\n",
       "          1401331267113750, 1401331270033000, 1401331272234380],\n",
       "         [1415713408963560, 1415713412342840, 1415713413908210, ...,\n",
       "          1415793865224370, 1415793878232820, 1415793884413250],\n",
       "         [1415607048337470, 1415607053674330, 1415607061264410, ...,\n",
       "          1415693736582080, 1415693740016370, 1415693741896520],\n",
       "         ...,\n",
       "         [1396490214044060, 1396490217550080, 1396490219747420, ...,\n",
       "          1396499048361910, 1396499052252720, 1396499072836780],\n",
       "         [1417782361268810, 1417782373041990, 1417782379740740, ...,\n",
       "          1418212658805960, 1418212661618160, 1418212664341380],\n",
       "         [1400571965972460, 1400572006938460, 1400572068427060, ...,\n",
       "          1419504885446050, 1419504888102220, 1419504891018080]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1413895349205140, 1413895354008880, 1413895370775710, ...,\n",
       "          1414325160473410, 1414325166372920, 1414325176171420],\n",
       "         [1414676597124270, 1414676612981860, 1414676617915450, ...,\n",
       "          1414759098580300, 1414759122125430, 1414759123508280],\n",
       "         [1398992131876730, 1398992140916470, 1398992149948120, ...,\n",
       "          1399721819539440, 1399721822558540, 1399721841315230],\n",
       "         ...,\n",
       "         [1398309096556530, 1398309099254050, 1398309102757940, ...,\n",
       "          1399259897343720, 1399259903409780, 1399259911724370],\n",
       "         [1395282193622010, 1395282208146840, 1395282216828290, ...,\n",
       "          1397096590717960, 1397096595231020, 1397096599809290],\n",
       "         [1413957466410660, 1413957470389140, 1413957474238220, ...,\n",
       "          1415767577835220, 1415767582414980, 1415767583790770]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1414032833570010, 1414032837870500, 1414032845307530, ...,\n",
       "          1415677819379580, 1415677823868040, 1415677827937780],\n",
       "         [1413381004440710, 1413381098810210, 1413381147090370, ...,\n",
       "          1413543992539830, 1413544003463430, 1413544019411720],\n",
       "         [1363607617074160, 1363607628635690, 1363607634439130, ...,\n",
       "          1400500214158420, 1400500218659440, 1400500222897860],\n",
       "         ...,\n",
       "         [1400228649130380, 1400228822733470, 1400228908877110, ...,\n",
       "          1401439922260970, 1401439926280390, 1401439929333500],\n",
       "         [1393401888354080, 1393401892676040, 1393401898346790, ...,\n",
       "          1394788009712400, 1394788011160430, 1394788013319770],\n",
       "         [1415612855187110, 1415612861442630, 1415612869760930, ...,\n",
       "          1420443712156490, 1420443714608230, 1420443716842210]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 0, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1386338007646090, 1386338017049000, 1386338023542890, ...,\n",
       "          1387708380653660, 1387708404694320, 1387708409529570],\n",
       "         [1415940945612260, 1415940949626600, 1415940954017550, ...,\n",
       "          1417756431273590, 1417756433139810, 1417756435177330],\n",
       "         [1411092889880550, 1411092913395610, 1411092932574680, ...,\n",
       "          1411223798268580, 1411223809172400, 1411223817046110],\n",
       "         ...,\n",
       "         [1413512882244130, 1413512884512790, 1413512886508540, ...,\n",
       "          1413771559551740, 1413771561665190, 1413771563631900],\n",
       "         [1409020778476300, 1409020911703620, 1409020996941090, ...,\n",
       "          1409024744950580, 1409024748569360, 1409024770347630],\n",
       "         [1415780723925680, 1415780794458600, 1415780796366000, ...,\n",
       "          1416300447030520, 1416300466412780, 1416300470351940]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 0],\n",
       "         [0, 1, 1, ..., 1, 1, 0]])),\n",
       " (array([[1402878222387410, 1402878261030760, 1402878285112270, ...,\n",
       "          1407720976444090, 1407720979459800, 1407720983833820],\n",
       "         [1412424392010420, 1412424395168390, 1412424402541500, ...,\n",
       "          1412471168982920, 1412471174165550, 1412471178172690],\n",
       "         [1406200160830610, 1406200163399280, 1406200165730370, ...,\n",
       "          1406890635149500, 1406890642181710, 1406890645413910],\n",
       "         ...,\n",
       "         [1401031066150400, 1401031072121970, 1401031078792640, ...,\n",
       "          1401032046519160, 1401032049129500, 1401032054224800],\n",
       "         [1388738523745330, 1388738529292940, 1388738532927390, ...,\n",
       "          1389773642616730, 1389773648580200, 1389773652284730],\n",
       "         [1385434378805560, 1385434387750830, 1385434393786740, ...,\n",
       "          1386125327224750, 1386125332041070, 1386125344663820]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 0, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 0]])),\n",
       " (array([[1413880986442620, 1413880989122810, 1413880991845210, ...,\n",
       "          1415091002638540, 1415091004857350, 1415091007443040],\n",
       "         [1410318402654700, 1410318412217190, 1410318420681520, ...,\n",
       "          1415976314671670, 1415976318820310, 1415976321225390],\n",
       "         [1395046572729860, 1395046602634560, 1395046630954190, ...,\n",
       "          1396515876466010, 1396516006527880, 1396516130192800],\n",
       "         ...,\n",
       "         [1411551264456730, 1411551315322270, 1411551411210250, ...,\n",
       "          1412479053608780, 1412479061110680, 1412479071521710],\n",
       "         [1416818158278310, 1416818214707710, 1416818443144700, ...,\n",
       "          1418374332621210, 1418374360515590, 1418374432135480],\n",
       "         [1410160863111250, 1410160878368080, 1410160910110770, ...,\n",
       "          1418303079402040, 1418303101029240, 1418303109597010]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 0, ..., 1, 1, 0],\n",
       "         [0, 0, 1, ..., 1, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 1, 1]])),\n",
       " (array([[1392973225864210, 1392973231514390, 1392973260318730, ...,\n",
       "          1402456250120950, 1402456252272750, 1402456255223790],\n",
       "         [1402647482963330, 1402647484717090, 1402647487232190, ...,\n",
       "          1403857123986310, 1403857131369590, 1403857134390230],\n",
       "         [1395722247143330, 1395722252059320, 1395722258594270, ...,\n",
       "          1404381690906560, 1404381692015310, 1404381694758190],\n",
       "         ...,\n",
       "         [1391246824201200, 1391246845355250, 1391246866429960, ...,\n",
       "          1391830245622380, 1391830257472220, 1391830268895500],\n",
       "         [1409925307481460, 1409925311977360, 1409925316701220, ...,\n",
       "          1410320480654270, 1410320482720100, 1410320485070940],\n",
       "         [1415695321386910, 1415695334945980, 1415695353816650, ...,\n",
       "          1417682900600150, 1417682905688700, 1417682910567850]]),\n",
       "  array([[1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1405564482319370, 1405564484438060, 1405564486788620, ...,\n",
       "          1412151716248390, 1412151718017200, 1412151720201450],\n",
       "         [1389768998759890, 1389769000931920, 1389769003088680, ...,\n",
       "          1390032738455750, 1390033152908800, 1390033159632600],\n",
       "         [1356663776238590, 1356663780415000, 1356663784718410, ...,\n",
       "          1368424897029480, 1368424899605590, 1368424906163930],\n",
       "         ...,\n",
       "         [1386038207176910, 1386038234966470, 1386038239706450, ...,\n",
       "          1394675950172900, 1394675952971190, 1394675959178640],\n",
       "         [1415758221976750, 1415758296514210, 1415758435338670, ...,\n",
       "          1419151838623770, 1419151861223540, 1419151887140940],\n",
       "         [1411269147721340, 1411269152317160, 1411269154829740, ...,\n",
       "          1411271062111300, 1411271064703770, 1411271067055540]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1412434475015210, 1412434495249480, 1412434504646370, ...,\n",
       "          1414888389886500, 1414888396774290, 1414888402231550],\n",
       "         [1412144065208800, 1412144076114960, 1412144140817140, ...,\n",
       "          1412146457243990, 1412146463284300, 1412146468139210],\n",
       "         [1382536033149390, 1382536053026250, 1382536062452180, ...,\n",
       "          1401712370536960, 1401886087845690, 1402315307486170],\n",
       "         ...,\n",
       "         [1386489239189400, 1386489244705080, 1386489254741210, ...,\n",
       "          1391048177072390, 1391048179617880, 1391048185436330],\n",
       "         [1390468200595980, 1390468410567890, 1390468541456950, ...,\n",
       "          1391669669216380, 1391669701449550, 1391669743135410],\n",
       "         [1401106060081300, 1401106078479360, 1401106092005130, ...,\n",
       "          1401435240519450, 1401435248296990, 1401435253792410]]),\n",
       "  array([[0, 1, 0, ..., 1, 0, 0],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1415012553405240, 1415012575709300, 1415012596591470, ...,\n",
       "          1415013655295360, 1415013657847630, 1415013661378260],\n",
       "         [1396502974162050, 1396502975883990, 1396502977777330, ...,\n",
       "          1400131933676120, 1400131934280700, 1400131935550810],\n",
       "         [1397638540926340, 1397638629838270, 1398055841776680, ...,\n",
       "          1398748693341200, 1398748711213780, 1398748720785480],\n",
       "         ...,\n",
       "         [1416824556028030, 1416824695210500, 1416824838952130, ...,\n",
       "          1418376443628210, 1418376445541170, 1418376448053700],\n",
       "         [1418620214132870, 1418620224938680, 1418620234655050, ...,\n",
       "          1420008419447210, 1420008433888080, 1420008440520600],\n",
       "         [1419833550423450, 1419833550423450, 1419833557849270, ...,\n",
       "          1419834227800630, 1419834232208920, 1419834232208920]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1410701346438770, 1410701359060180, 1410701364417900, ...,\n",
       "          1418131415708940, 1418131419143490, 1418131426505180],\n",
       "         [1414023076427230, 1414023084473480, 1414023098248480, ...,\n",
       "          1414024350756310, 1414024355181860, 1414024357604450],\n",
       "         [1370847240310510, 1370847251137740, 1370847261962150, ...,\n",
       "          1398260786389620, 1398260788107790, 1398260790088640],\n",
       "         ...,\n",
       "         [1389596094446160, 1389598406877850, 1389598416509930, ...,\n",
       "          1400479900700870, 1400479904477300, 1400479907031980],\n",
       "         [1380615895590930, 1380615900479890, 1380615904663840, ...,\n",
       "          1381462661087770, 1381462676328680, 1381462678944240],\n",
       "         [1410855873787950, 1410855909893720, 1410855947060230, ...,\n",
       "          1411460947885750, 1411460956653550, 1411460999694300]]),\n",
       "  array([[0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 0, ..., 0, 0, 0]])),\n",
       " (array([[1413878802078860, 1413878906963050, 1413878908159090, ...,\n",
       "          1414657640178720, 1414657688469330, 1414657725279150],\n",
       "         [1416981585317020, 1416981595646810, 1416981601795660, ...,\n",
       "          1419236431164930, 1419236433651740, 1419236436544950],\n",
       "         [1419234758964010, 1419234762479040, 1419234765713430, ...,\n",
       "          1420444019327560, 1420444021617840, 1420444025981810],\n",
       "         ...,\n",
       "         [1385025296905330, 1415261106194050, 1415261113156510, ...,\n",
       "          1415868834902730, 1415868839434610, 1415868853247350],\n",
       "         [1393336838283630, 1393336923747380, 1394028425946810, ...,\n",
       "          1409317064878000, 1409317415600670, 1409317448089350],\n",
       "         [1394755099959830, 1394755109601100, 1394755124822890, ...,\n",
       "          1400215069783040, 1400215096881040, 1400215135258350]]),\n",
       "  array([[0, 1, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 0, 1]])),\n",
       " (array([[1414661084042220, 1414661104579250, 1414661116507510, ...,\n",
       "          1417512296672090, 1417512300433290, 1417512308492490],\n",
       "         [1415954060054490, 1415954093632740, 1415954114777070, ...,\n",
       "          1417094575439810, 1417094584682070, 1417094597254120],\n",
       "         [1411785421106660, 1411785434808910, 1411785447147350, ...,\n",
       "          1415881708749980, 1415882173035210, 1415882176229940],\n",
       "         ...,\n",
       "         [1405906756063500, 1405906762742510, 1406791915343830, ...,\n",
       "          1407379143147860, 1407379169126080, 1407379173604990],\n",
       "         [1416535942171830, 1416535945524540, 1416535952114120, ...,\n",
       "          1417252908754790, 1417252926427360, 1417252929544830],\n",
       "         [1416318019027400, 1416318047651750, 1416318054452210, ...,\n",
       "          1417242118153930, 1417242126757790, 1417242132010920]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1415768448611180, 1415768451325240, 1415768453610540, ...,\n",
       "          1418792158596900, 1418792169602420, 1418792172734300],\n",
       "         [1402292636553030, 1402292640727560, 1402292645919420, ...,\n",
       "          1402455948163680, 1402455950839750, 1402455954020410],\n",
       "         [1416301685211150, 1416301687530000, 1416301690239560, ...,\n",
       "          1419326227973450, 1419326230195790, 1419326233086930],\n",
       "         ...,\n",
       "         [1416201310085870, 1416201317990380, 1416201325122100, ...,\n",
       "          1416317575299310, 1416317577863440, 1416317580821620],\n",
       "         [1414397899382920, 1414397903117560, 1414397908725220, ...,\n",
       "          1419840759743400, 1419840951943940, 1419840954777010],\n",
       "         [1417337227627220, 1417337248064000, 1417337251838270, ...,\n",
       "          1417425052432470, 1417437524616160, 1417437533808100]]),\n",
       "  array([[1, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         [0, 1, 0, ..., 0, 1, 0]])),\n",
       " (array([[1387285388501820, 1387285392132750, 1387285398681290, ...,\n",
       "          1396098165279500, 1396098167827140, 1396098170198290],\n",
       "         [1389598314975450, 1389598319477890, 1389598411411940, ...,\n",
       "          1402898924332410, 1402898926821140, 1402898929238560],\n",
       "         [1398500973668660, 1398500984400920, 1398501015683100, ...,\n",
       "          1401452723876600, 1401452727031400, 1401452732488380],\n",
       "         ...,\n",
       "         [1381390414744340, 1381390441558860, 1395836571880970, ...,\n",
       "          1415880899990950, 1415880905160400, 1415880908980380],\n",
       "         [1415077213125750, 1415077226522070, 1415077231487290, ...,\n",
       "          1417755194997470, 1417755204234410, 1417755210491360],\n",
       "         [1414926512319420, 1414926521959810, 1414926527547030, ...,\n",
       "          1417239379697950, 1417239389832100, 1417239397132910]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1413527620329440, 1413527624283210, 1413527630919670, ...,\n",
       "          1414739754559410, 1414739756021370, 1414739757537390],\n",
       "         [1418018714451700, 1418018743896830, 1418018776288970, ...,\n",
       "          1418623900875270, 1418623904393160, 1418623906932870],\n",
       "         [1414022579732620, 1414022618726040, 1414022630779750, ...,\n",
       "          1414665114378710, 1414665117872120, 1414665121340620],\n",
       "         ...,\n",
       "         [1388738760275590, 1388738766806350, 1388738774422920, ...,\n",
       "          1389773876641460, 1389773880916380, 1389774120523550],\n",
       "         [1387854175991110, 1387854185536070, 1387854196415150, ...,\n",
       "          1389527083076360, 1389527088673780, 1389527104051280],\n",
       "         [1415169110581580, 1415169116099880, 1415169127054940, ...,\n",
       "          1419402387199740, 1419402390877730, 1419402394634140]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1389596234466930, 1389596238886390, 1389596241303580, ...,\n",
       "          1399880791890490, 1399880795362280, 1399880798806180],\n",
       "         [1377005016989050, 1377005032015790, 1377005061968060, ...,\n",
       "          1397046580158770, 1397046582525360, 1397046584952480],\n",
       "         [1381827078556260, 1383555322461040, 1383555344008640, ...,\n",
       "          1387183064871330, 1387183101704850, 1387183267115520],\n",
       "         ...,\n",
       "         [1411170389013850, 1411170430203160, 1412422327061550, ...,\n",
       "          1414590258221440, 1414590272794290, 1414590282579430],\n",
       "         [1414484438693540, 1414484446765880, 1414484453328180, ...,\n",
       "          1414657177806490, 1414657191284550, 1414657199431530],\n",
       "         [1393416765608020, 1393416903960370, 1393417169871110, ...,\n",
       "          1398083917936420, 1398083924531580, 1398083932418790]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [0, 1, 0, ..., 1, 0, 1],\n",
       "         [0, 1, 0, ..., 0, 0, 0],\n",
       "         [1, 1, 0, ..., 1, 1, 0]])),\n",
       " (array([[1394033286845700, 1394033313467610, 1394033336378660, ...,\n",
       "          1394106233118730, 1394106238467540, 1394106627702300],\n",
       "         [1395837895218010, 1395837913030030, 1395837956782420, ...,\n",
       "          1399382156692160, 1399382166472280, 1399382177549420],\n",
       "         [1397902699803390, 1397902711074340, 1397902737284590, ...,\n",
       "          1398483073703450, 1398483080870040, 1398483083058680],\n",
       "         ...,\n",
       "         [1405408930829550, 1405408948895350, 1405408959851730, ...,\n",
       "          1418738296661560, 1418738301212850, 1418738305500430],\n",
       "         [1410783208842610, 1410783219608760, 1410783224069150, ...,\n",
       "          1413807918225160, 1413807920531570, 1413807923097850],\n",
       "         [1419248958492580, 1419248960916190, 1419248964463050, ...,\n",
       "          1419418264850620, 1419418267518160, 1419418272475980]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1]])),\n",
       " (array([[1420289153894100, 1420289164940320, 1420289174134260, ...,\n",
       "          1420292957942060, 1420292976495140, 1420292993120860],\n",
       "         [1410935506186630, 1410935509164180, 1410935512181550, ...,\n",
       "          1420005502459760, 1420005504952620, 1420005508139550],\n",
       "         [1400048443021290, 1400048444815120, 1400048447036180, ...,\n",
       "          1400806983922050, 1400806985905260, 1400806988525610],\n",
       "         ...,\n",
       "         [1410428537049620, 1410428640325860, 1410428937556090, ...,\n",
       "          1410775168980090, 1410775171622530, 1410775174124840],\n",
       "         [1410413982929290, 1410503877926760, 1410756045786220, ...,\n",
       "          1414041591395810, 1414041594840390, 1414041604323450],\n",
       "         [1401441071463530, 1401441076373590, 1401441080402850, ...,\n",
       "          1402651562463500, 1402651565441590, 1402651575248080]]),\n",
       "  array([[0, 0, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1]])),\n",
       " (array([[1380719046247200, 1380719069618360, 1380719124023620, ...,\n",
       "          1399128212776040, 1399128446328650, 1399288242789410],\n",
       "         [1392860846471320, 1392860853041200, 1392860876178820, ...,\n",
       "          1394163279982590, 1394163284663160, 1394163288577870],\n",
       "         [1393473152225690, 1393473170483680, 1393473177591000, ...,\n",
       "          1395982395866940, 1395982419052460, 1395982425613690],\n",
       "         ...,\n",
       "         [1408952291830830, 1408952300062700, 1408952308128830, ...,\n",
       "          1409027808024970, 1409027812067160, 1409027816221750],\n",
       "         [1411473919615630, 1411473927952310, 1411473951177120, ...,\n",
       "          1411476003135260, 1411476006771290, 1411476011250530],\n",
       "         [1392259588931140, 1392259605102160, 1392259662371260, ...,\n",
       "          1399961021346860, 1399961022395340, 1399961031967840]]),\n",
       "  array([[0, 0, 1, ..., 0, 1, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1400832594767610, 1400832598517100, 1400832600553330, ...,\n",
       "          1406172521010910, 1406172524327050, 1406172532248460],\n",
       "         [1380176931646320, 1380176943984910, 1380176974082780, ...,\n",
       "          1383267041582760, 1383267067612190, 1383267076809750],\n",
       "         [1355819753969840, 1355819764764770, 1356081453035280, ...,\n",
       "          1374847424272380, 1374847439179260, 1374847456391310],\n",
       "         ...,\n",
       "         [1405242533504010, 1405242702833400, 1405242831710190, ...,\n",
       "          1405473565697010, 1405473572823680, 1405473578999160],\n",
       "         [1389282039011730, 1389282042332250, 1389282130717730, ...,\n",
       "          1400335596920370, 1400335599651610, 1400335602314210],\n",
       "         [1418344888877060, 1418344916403520, 1418344966641650, ...,\n",
       "          1419334989021850, 1419334997133860, 1419335001490000]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 0, 1],\n",
       "         ...,\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1]])),\n",
       " (array([[1412306038205630, 1412306058797800, 1412306092992220, ...,\n",
       "          1414575279366820, 1414575292227560, 1414575303559350],\n",
       "         [1405044988873070, 1405045026797440, 1405045043317230, ...,\n",
       "          1405047764989970, 1405047769133540, 1405047774884560],\n",
       "         [1395235666407650, 1395235678651980, 1395235688407210, ...,\n",
       "          1395238758780370, 1395238761554220, 1395238764146760],\n",
       "         ...,\n",
       "         [1420699896932550, 1420699905631590, 1420699907218160, ...,\n",
       "          1420702197199930, 1420702200589170, 1420702206295350],\n",
       "         [1419384405520290, 1419384410263840, 1419384414661460, ...,\n",
       "          1419396569331810, 1419396573321180, 1419396575778090],\n",
       "         [1414485258353160, 1415088558571130, 1415088566726200, ...,\n",
       "          1415695189694610, 1415695196952080, 1415695205347270]]),\n",
       "  array([[1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1395449074967520, 1395451470127360, 1395451480997690, ...,\n",
       "          1400414690440230, 1400414695872760, 1400415236790900],\n",
       "         [1386731619980430, 1386731633104140, 1386731642067840, ...,\n",
       "          1406289335864500, 1406289343938710, 1406289353359250],\n",
       "         [1395388427932580, 1395388431003150, 1395388433729380, ...,\n",
       "          1398157453311790, 1398157456790930, 1398157460856550],\n",
       "         ...,\n",
       "         [1393756387587920, 1393756396715330, 1393756404457170, ...,\n",
       "          1393763055438560, 1393763058506220, 1393763062370640],\n",
       "         [1395637652402230, 1395637725316890, 1395637764358350, ...,\n",
       "          1395917466791720, 1395917494652990, 1395917584039480],\n",
       "         [1381036706224540, 1381036711985620, 1381036716603320, ...,\n",
       "          1381045519163740, 1381045523678920, 1381045531359620]]),\n",
       "  array([[0, 1, 1, ..., 1, 0, 1],\n",
       "         [0, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 0],\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1407297816727170, 1407297820461430, 1407297823345360, ...,\n",
       "          1408443937725930, 1408443941269750, 1408443944769210],\n",
       "         [1406605392310590, 1406605401319500, 1406605410277040, ...,\n",
       "          1406691502998800, 1406691506514760, 1406691511226080],\n",
       "         [1417059600079200, 1417059614779640, 1417059630587710, ...,\n",
       "          1419479243731340, 1419479255225200, 1419479265582100],\n",
       "         ...,\n",
       "         [1411107241846220, 1411107299380050, 1411107310958180, ...,\n",
       "          1414131346366150, 1414131349414770, 1414131398841300],\n",
       "         [1355812159475690, 1355812165088560, 1355812171849200, ...,\n",
       "          1356049248751470, 1356049254016350, 1356049259255820],\n",
       "         [1411966039354510, 1411966066836810, 1411966093126720, ...,\n",
       "          1413724474356970, 1413724478194700, 1413724488475160]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1394543195990390, 1394543205525340, 1394543211530130, ...,\n",
       "          1394549279140800, 1394549286213770, 1394549293622190],\n",
       "         [1416979637527870, 1416979643307000, 1416979646805090, ...,\n",
       "          1416981386452030, 1416981404305300, 1416981411179150],\n",
       "         [1394025534891430, 1394025541542520, 1394025547215520, ...,\n",
       "          1402020495931790, 1402020501320540, 1402020503723350],\n",
       "         ...,\n",
       "         [1413528514520920, 1413528520235720, 1413528528389370, ...,\n",
       "          1418370111188790, 1418370115735590, 1418370118805780],\n",
       "         [1394774095432490, 1394774129234850, 1394774320516530, ...,\n",
       "          1400331013638070, 1400331022540610, 1400331028151110],\n",
       "         [1402375578367010, 1402376347940150, 1402376354966880, ...,\n",
       "          1402378593867740, 1402378601142500, 1402378608124220]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 0]])),\n",
       " (array([[1380778203397420, 1384482375350160, 1384482440859990, ...,\n",
       "          1397110575244040, 1397110698158190, 1397110708586960],\n",
       "         [1389596352871360, 1389596355508840, 1389596358660590, ...,\n",
       "          1399877621466820, 1399877629199850, 1399877632539470],\n",
       "         [1382847815525570, 1382847833879110, 1382847839106520, ...,\n",
       "          1391482428619310, 1391482439579980, 1391482442304220],\n",
       "         ...,\n",
       "         [1409664368414250, 1409664380460560, 1409664392257030, ...,\n",
       "          1411621087304160, 1411621092280270, 1411621097391100],\n",
       "         [1393920786051160, 1393920819439660, 1393920829339630, ...,\n",
       "          1402388922999680, 1402388930613050, 1402388938231020],\n",
       "         [1404972155872750, 1404972171017340, 1404972196655950, ...,\n",
       "          1405059262067140, 1405059264221000, 1405059266884200]]),\n",
       "  array([[0, 0, 0, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1405726151654610, 1405726332238220, 1405726734049260, ...,\n",
       "          1405742803637810, 1405742813758720, 1405742830601380],\n",
       "         [1413419922989040, 1413419937209570, 1413419943609980, ...,\n",
       "          1414024718859760, 1414024725658940, 1414024728848980],\n",
       "         [1398484030193580, 1398484033315800, 1398484035623870, ...,\n",
       "          1417227748113780, 1417227750552250, 1417227753164280],\n",
       "         ...,\n",
       "         [1411022282368370, 1411022284901030, 1411022289529950, ...,\n",
       "          1412335098591770, 1412335101482280, 1412335102726020],\n",
       "         [1405335701633950, 1405335704734750, 1405335709159400, ...,\n",
       "          1405406572716980, 1405406576040620, 1405406578396080],\n",
       "         [1413978099695190, 1413978261422250, 1413978266752210, ...,\n",
       "          1416381604715070, 1416381609346800, 1416381614979330]]),\n",
       "  array([[1, 1, 1, ..., 1, 0, 1],\n",
       "         [0, 1, 1, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1420003220910180, 1420003222175830, 1420003228204400, ...,\n",
       "          1420606968613110, 1420606970556640, 1420606979442620],\n",
       "         [1382007952928590, 1382007967172650, 1382007982724350, ...,\n",
       "          1403253055069640, 1403253066284080, 1403253068862900],\n",
       "         [1396872443631360, 1396872450960500, 1396872471799380, ...,\n",
       "          1398656675825530, 1398656682564190, 1398656692679990],\n",
       "         ...,\n",
       "         [1371192799251030, 1371192802892660, 1371192805700700, ...,\n",
       "          1372744098577650, 1372744102583650, 1372744105797910],\n",
       "         [1393892633898640, 1393892645129390, 1393941425192320, ...,\n",
       "          1394098205963310, 1394098208021570, 1394098210589270],\n",
       "         [1413793945348030, 1413793977190630, 1413793987467930, ...,\n",
       "          1414483645212040, 1414483658366140, 1414483699604870]]),\n",
       "  array([[0, 0, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 0, 1]])),\n",
       " (array([[1415364849325240, 1415365001938040, 1415365011454320, ...,\n",
       "          1417100452204630, 1417100454197310, 1417100457260800],\n",
       "         [1394676535509690, 1394676547177920, 1394676559798520, ...,\n",
       "          1418880070410180, 1418880072441520, 1418880076665290],\n",
       "         [1419912106143140, 1419912114468470, 1419912125788090, ...,\n",
       "          1420963686162590, 1420963690299110, 1420963694553020],\n",
       "         ...,\n",
       "         [1400851105417010, 1400851111623970, 1400851116095960, ...,\n",
       "          1400886215376410, 1400886217974600, 1400886221253750],\n",
       "         [1382092928111990, 1382092933355810, 1382092937558660, ...,\n",
       "          1383625625290690, 1383625640848930, 1383625642669530],\n",
       "         [1379745450748820, 1380717307577110, 1380717425283340, ...,\n",
       "          1401629667475650, 1401976957007030, 1401977066937820]]),\n",
       "  array([[1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 1, 1, 1]])),\n",
       " (array([[1412320409758560, 1412320421999330, 1412320432554180, ...,\n",
       "          1413524987477090, 1413525654736370, 1413525658561120],\n",
       "         [1413189665456930, 1413189674224990, 1413189683453480, ...,\n",
       "          1413793434964880, 1413793441532750, 1413793451889410],\n",
       "         [1415274391520610, 1415359786267570, 1415359789649330, ...,\n",
       "          1418284055197910, 1418284058319490, 1418284061796850],\n",
       "         ...,\n",
       "         [1383053222137240, 1383291906985430, 1383292015057650, ...,\n",
       "          1385608461241130, 1385608480564880, 1385608511455420],\n",
       "         [1396406749485430, 1396406762716330, 1396406768898060, ...,\n",
       "          1396498768316610, 1396498770419520, 1396498773811570],\n",
       "         [1400141679249380, 1400141685053060, 1400141725203410, ...,\n",
       "          1400144032532620, 1400144058154810, 1400144082079140]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 0, 0, 0],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1]])),\n",
       " (array([[1388215936768510, 1388215942078970, 1388216198711300, ...,\n",
       "          1388217501570060, 1388217504525890, 1388217506956230],\n",
       "         [1413512377482100, 1413512444131430, 1413512466165500, ...,\n",
       "          1415261321315760, 1415261328825620, 1415261382866270],\n",
       "         [1413464515966950, 1413464609427480, 1413464643936290, ...,\n",
       "          1414505543893970, 1414505575395110, 1414505682737430],\n",
       "         ...,\n",
       "         [1399625459457220, 1399625466001450, 1399625482264910, ...,\n",
       "          1411720753725100, 1411720756538310, 1411720762985500],\n",
       "         [1392257107676940, 1392257114244710, 1392257145563440, ...,\n",
       "          1392862049138750, 1392862052277720, 1392862055161060],\n",
       "         [1389702361579740, 1389702468659020, 1389702514315620, ...,\n",
       "          1410786129251650, 1410786152357360, 1410786171525410]]),\n",
       "  array([[1, 1, 0, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 0, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 0]])),\n",
       " (array([[1391561783952830, 1391561815902050, 1391561839599450, ...,\n",
       "          1393072677461770, 1393072686402890, 1393072699466770],\n",
       "         [1418972774110920, 1418972777141880, 1418972780163480, ...,\n",
       "          1419994507047550, 1419994509512400, 1419994512002150],\n",
       "         [1406262433983770, 1406262446789820, 1406262466976860, ...,\n",
       "          1406268003316990, 1406268008160650, 1406268013935350],\n",
       "         ...,\n",
       "         [1390315099024350, 1390315102400520, 1390315105434590, ...,\n",
       "          1390315955036660, 1390315957161170, 1390315959980410],\n",
       "         [1359382408203000, 1359382416123070, 1359382428107510, ...,\n",
       "          1359627481169900, 1360237261938960, 1360237278604390],\n",
       "         [1412843245726740, 1412843253052480, 1412843261478680, ...,\n",
       "          1412845181148230, 1412845184862030, 1412845187451660]]),\n",
       "  array([[0, 0, 1, ..., 0, 0, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1397045312662780, 1397045317485480, 1397045321374520, ...,\n",
       "          1402714004604980, 1402714008605110, 1402714013898830],\n",
       "         [1393825481169780, 1393825490677230, 1393825505661380, ...,\n",
       "          1396949383552740, 1396949388108730, 1396949391129260],\n",
       "         [1389847840949020, 1389847848333300, 1389847854871660, ...,\n",
       "          1392614275827730, 1392614280697750, 1392614284911010],\n",
       "         ...,\n",
       "         [1416481181265580, 1416481200138270, 1416481224441960, ...,\n",
       "          1416567481860740, 1416567489398450, 1416567494318870],\n",
       "         [1382153065599520, 1382153078215100, 1382153090701390, ...,\n",
       "          1385341488509150, 1385341501620010, 1385341508267270],\n",
       "         [1395366764700540, 1395366943421690, 1395366953962650, ...,\n",
       "          1400641071014470, 1400641073782040, 1400641083911970]]),\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 0, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 1, 1, 0],\n",
       "         [0, 0, 1, ..., 0, 1, 0],\n",
       "         [0, 1, 1, ..., 1, 1, 1]])),\n",
       " (array([[1410335624118600, 1410335635740720, 1410335658477780, ...,\n",
       "          1412141538419850, 1412141598359520, 1412141612366100],\n",
       "         [1393901269267120, 1393901275671700, 1393901311048650, ...,\n",
       "          1399968902540760, 1399968908812180, 1399968922811730],\n",
       "         [1417511665384470, 1417511678488570, 1417511686138960, ...,\n",
       "          1419828430150710, 1419828436171760, 1419828443938880],\n",
       "         ...,\n",
       "         [1406172907974420, 1406173511825840, 1406173517285810, ...,\n",
       "          1406778431447940, 1406778433515470, 1406778487008260],\n",
       "         [1378864873837180, 1381282770265150, 1381282795730840, ...,\n",
       "          1381728391056830, 1381728403786080, 1381728415866210],\n",
       "         [1417767827695430, 1417767836227480, 1417767843565990, ...,\n",
       "          1418113680932810, 1418113682185880, 1418113687670370]]),\n",
       "  array([[1, 1, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 0, ..., 0, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 0, 1]])),\n",
       " (array([[1417570417645410, 1417570425328870, 1417570439478580, ...,\n",
       "          1418354003094180, 1418354006632920, 1418354009678830],\n",
       "         [1391825567205580, 1391825572048600, 1391825575986350, ...,\n",
       "          1406005182673910, 1406005184919340, 1406005187843420],\n",
       "         [1417268655579510, 1417268665231470, 1417569400065520, ...,\n",
       "          1420519717541990, 1420519722929300, 1420519729141280],\n",
       "         ...,\n",
       "         [1412167971540070, 1412168037913490, 1413007365999370, ...,\n",
       "          1413103370886130, 1413103379258040, 1413103386938460],\n",
       "         [1384346695356390, 1384346700860110, 1384346709076950, ...,\n",
       "          1386161495425470, 1386161500091250, 1386161503215220],\n",
       "         [1412421897214860, 1412421956053160, 1412421970222570, ...,\n",
       "          1418170775845790, 1418170780586960, 1418170787832520]]),\n",
       "  array([[1, 1, 0, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [0, 0, 1, ..., 1, 1, 1],\n",
       "         [0, 1, 1, ..., 1, 1, 1]]))]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################### rescale time data\n",
    "log_t_data = [] # so that the log(diff(t_data)) = diff(log_t_data)\n",
    "dt = torch.log(torch.diff(t_data))\n",
    "log_t_data.append(torch.zeros_like(dt[:,0]))\n",
    "for i in range(0, dt.shape[-1]):\n",
    "    log_t_data.append(log_t_data[-1] + dt[:, i])\n",
    "log_t_data = torch.stack(log_t_data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349049a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5cf552b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ou_estimator import OrnsteinUhlenbeckEstimator\n",
    "log_t_data = [] # so that the log(diff(t_data)) = diff(log_t_data)\n",
    "dt = torch.log(torch.diff(t_data))\n",
    "log_t_data.append(torch.zeros_like(dt[:,0]))\n",
    "for i in range(0, dt.shape[-1]):\n",
    "    log_t_data.append(log_t_data[-1] + dt[:, i])\n",
    "log_t_data = torch.stack(log_t_data, -1)\n",
    "\n",
    "numpy_data = [(time_seq.cpu().numpy(), correct_seq.cpu().numpy()) for _, (_, time_seq, correct_seq, _) in enumerate(train_loader)]\n",
    "estimator = OrnsteinUhlenbeckEstimator(numpy_data, n_it=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4737bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = 0.8482042530182574\n",
      "eta = 1.0496364139222869e-06\n",
      "sigma^2 = 7.670892715022106e-10\n"
     ]
    }
   ],
   "source": [
    "print(f'mu = {estimator.mu}')\n",
    "print(f'eta = {estimator.eta}')\n",
    "print(f'sigma^2 = {estimator.sigma_sq()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "50e56962",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.7005, 0.6999,  ..., 0.7054, 0.7035, 0.7008]],\n",
      "\n",
      "        [[0.7311, 0.6998, 0.7010,  ..., 0.7025, 0.6974, 0.6971]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.6979,  ..., 0.6967, 0.7042, 0.7036]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6979, 0.7005,  ..., 0.7010, 0.6992, 0.6994]],\n",
      "\n",
      "        [[0.7311, 0.7069, 0.7021,  ..., 0.7040, 0.7029, 0.6989]],\n",
      "\n",
      "        [[0.5000, 0.7013, 0.6955,  ..., 0.7017, 0.6999, 0.6994]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4826, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7038, 0.7051,  ..., 0.6985, 0.6984, 0.6967]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.6960,  ..., 0.6984, 0.6914, 0.7047]],\n",
      "\n",
      "        [[0.7311, 0.6949, 0.6984,  ..., 0.7038, 0.6962, 0.7001]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6976, 0.7017,  ..., 0.6930, 0.7010, 0.7008]],\n",
      "\n",
      "        [[0.7311, 0.7022, 0.7039,  ..., 0.7013, 0.7045, 0.6977]],\n",
      "\n",
      "        [[0.7311, 0.7046, 0.7007,  ..., 0.7034, 0.6980, 0.6964]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5595, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6976, 0.7008,  ..., 0.6988, 0.7027, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.6998, 0.6997,  ..., 0.7013, 0.7036, 0.7024]],\n",
      "\n",
      "        [[0.7311, 0.6937, 0.7044,  ..., 0.6947, 0.6972, 0.7032]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6951, 0.7030,  ..., 0.7013, 0.7029, 0.7043]],\n",
      "\n",
      "        [[0.5000, 0.7046, 0.7001,  ..., 0.6981, 0.7038, 0.6970]],\n",
      "\n",
      "        [[0.5000, 0.7043, 0.6999,  ..., 0.7043, 0.7055, 0.6971]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4491, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6963, 0.6989,  ..., 0.7012, 0.7055, 0.6953]],\n",
      "\n",
      "        [[0.7311, 0.6939, 0.7059,  ..., 0.6970, 0.7043, 0.6997]],\n",
      "\n",
      "        [[0.5000, 0.6982, 0.7018,  ..., 0.6989, 0.6972, 0.6930]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6958, 0.7003,  ..., 0.7054, 0.7003, 0.6963]],\n",
      "\n",
      "        [[0.7311, 0.7018, 0.6986,  ..., 0.6977, 0.7056, 0.7003]],\n",
      "\n",
      "        [[0.7311, 0.7000, 0.6982,  ..., 0.7012, 0.6983, 0.6913]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4928, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6868, 0.6978,  ..., 0.7002, 0.7031, 0.6973]],\n",
      "\n",
      "        [[0.7311, 0.7037, 0.7007,  ..., 0.7038, 0.6983, 0.6975]],\n",
      "\n",
      "        [[0.7311, 0.7018, 0.7048,  ..., 0.7012, 0.6979, 0.7026]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6962,  ..., 0.7033, 0.6958, 0.6977]],\n",
      "\n",
      "        [[0.7311, 0.7037, 0.7017,  ..., 0.7034, 0.7011, 0.7021]],\n",
      "\n",
      "        [[0.7311, 0.6981, 0.6976,  ..., 0.6984, 0.6969, 0.7011]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4722, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6968, 0.6974,  ..., 0.6992, 0.7007, 0.7022]],\n",
      "\n",
      "        [[0.5000, 0.7057, 0.7042,  ..., 0.7064, 0.7011, 0.6981]],\n",
      "\n",
      "        [[0.5000, 0.6999, 0.7053,  ..., 0.7014, 0.6977, 0.7074]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7020, 0.6966,  ..., 0.7001, 0.7022, 0.7078]],\n",
      "\n",
      "        [[0.5000, 0.6995, 0.7023,  ..., 0.6997, 0.7008, 0.6972]],\n",
      "\n",
      "        [[0.7311, 0.7028, 0.7017,  ..., 0.7021, 0.7013, 0.6974]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5525, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7040, 0.6951,  ..., 0.7009, 0.6991, 0.6903]],\n",
      "\n",
      "        [[0.7311, 0.7014, 0.7015,  ..., 0.7027, 0.6990, 0.7025]],\n",
      "\n",
      "        [[0.5000, 0.7011, 0.7025,  ..., 0.7024, 0.7047, 0.7004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6985, 0.6949,  ..., 0.7013, 0.7055, 0.6966]],\n",
      "\n",
      "        [[0.5000, 0.7029, 0.7005,  ..., 0.6991, 0.6945, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.6985, 0.6986,  ..., 0.7017, 0.7001, 0.6936]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4616, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6920, 0.7003,  ..., 0.7014, 0.7055, 0.6958]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.7000,  ..., 0.7008, 0.7042, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.6979, 0.6962,  ..., 0.7010, 0.6982, 0.7048]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7002, 0.6956,  ..., 0.6961, 0.6991, 0.6952]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.6928,  ..., 0.6996, 0.7038, 0.6940]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.7042,  ..., 0.7000, 0.7049, 0.7032]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4518, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6980, 0.6987,  ..., 0.6961, 0.7035, 0.7005]],\n",
      "\n",
      "        [[0.5000, 0.6985, 0.7009,  ..., 0.6971, 0.6954, 0.7010]],\n",
      "\n",
      "        [[0.7311, 0.7028, 0.6969,  ..., 0.7012, 0.7021, 0.6965]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7002, 0.7038,  ..., 0.6975, 0.6979, 0.7039]],\n",
      "\n",
      "        [[0.5000, 0.6950, 0.7000,  ..., 0.7015, 0.6980, 0.6984]],\n",
      "\n",
      "        [[0.7311, 0.7005, 0.7030,  ..., 0.7012, 0.7056, 0.7039]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4548, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7052, 0.7009,  ..., 0.7095, 0.7034, 0.6989]],\n",
      "\n",
      "        [[0.7311, 0.6977, 0.7011,  ..., 0.6971, 0.6957, 0.6996]],\n",
      "\n",
      "        [[0.7311, 0.7019, 0.7005,  ..., 0.7019, 0.6964, 0.6972]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7027, 0.7035,  ..., 0.6943, 0.7007, 0.6956]],\n",
      "\n",
      "        [[0.7311, 0.6975, 0.7052,  ..., 0.7039, 0.7087, 0.7015]],\n",
      "\n",
      "        [[0.7311, 0.7031, 0.7051,  ..., 0.6994, 0.6939, 0.7037]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4213, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6983, 0.6957,  ..., 0.6964, 0.6928, 0.6993]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.7050,  ..., 0.7034, 0.7017, 0.6996]],\n",
      "\n",
      "        [[0.7311, 0.6987, 0.7027,  ..., 0.6995, 0.7037, 0.6990]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6973, 0.6998,  ..., 0.7027, 0.7027, 0.7001]],\n",
      "\n",
      "        [[0.7311, 0.6969, 0.6973,  ..., 0.7002, 0.7000, 0.7004]],\n",
      "\n",
      "        [[0.7311, 0.7003, 0.7023,  ..., 0.7021, 0.7023, 0.7013]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4200, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7033, 0.6937,  ..., 0.6966, 0.7035, 0.7033]],\n",
      "\n",
      "        [[0.5000, 0.7011, 0.6922,  ..., 0.7048, 0.7010, 0.7004]],\n",
      "\n",
      "        [[0.7311, 0.6981, 0.7010,  ..., 0.7009, 0.6977, 0.6936]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6978, 0.7002,  ..., 0.6976, 0.6939, 0.7055]],\n",
      "\n",
      "        [[0.5000, 0.7023, 0.6961,  ..., 0.6993, 0.7027, 0.7026]],\n",
      "\n",
      "        [[0.5000, 0.7026, 0.7048,  ..., 0.6967, 0.6968, 0.6954]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5779, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7020, 0.7042,  ..., 0.7021, 0.7012, 0.7010]],\n",
      "\n",
      "        [[0.7311, 0.7042, 0.6974,  ..., 0.7002, 0.6978, 0.6994]],\n",
      "\n",
      "        [[0.5000, 0.6993, 0.6968,  ..., 0.6936, 0.7013, 0.6952]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7085, 0.7007,  ..., 0.7018, 0.6981, 0.6946]],\n",
      "\n",
      "        [[0.7311, 0.6954, 0.6984,  ..., 0.7011, 0.7034, 0.6982]],\n",
      "\n",
      "        [[0.7311, 0.6999, 0.7004,  ..., 0.6996, 0.6990, 0.6996]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4431, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7022, 0.7044,  ..., 0.6986, 0.6993, 0.7005]],\n",
      "\n",
      "        [[0.7311, 0.6980, 0.7010,  ..., 0.7026, 0.7026, 0.6917]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.6939,  ..., 0.6975, 0.6976, 0.6989]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6967, 0.7019,  ..., 0.7012, 0.7011, 0.6973]],\n",
      "\n",
      "        [[0.5000, 0.7012, 0.7067,  ..., 0.6988, 0.6980, 0.7039]],\n",
      "\n",
      "        [[0.7311, 0.6978, 0.6971,  ..., 0.7039, 0.7003, 0.7012]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4465, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7004, 0.6970,  ..., 0.6997, 0.6972, 0.6992]],\n",
      "\n",
      "        [[0.7311, 0.6962, 0.7003,  ..., 0.7010, 0.6979, 0.6935]],\n",
      "\n",
      "        [[0.7311, 0.6994, 0.7074,  ..., 0.7066, 0.7043, 0.7019]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7027, 0.7031,  ..., 0.6958, 0.7025, 0.6984]],\n",
      "\n",
      "        [[0.7311, 0.6930, 0.6997,  ..., 0.6902, 0.6963, 0.7021]],\n",
      "\n",
      "        [[0.5000, 0.7108, 0.7030,  ..., 0.6959, 0.7018, 0.7039]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4739, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7013, 0.7034,  ..., 0.7017, 0.6994, 0.6962]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6993,  ..., 0.7005, 0.7002, 0.6982]],\n",
      "\n",
      "        [[0.5000, 0.7018, 0.7018,  ..., 0.6990, 0.7002, 0.7053]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7005, 0.7018,  ..., 0.6998, 0.7022, 0.7033]],\n",
      "\n",
      "        [[0.7311, 0.7048, 0.7007,  ..., 0.6999, 0.7013, 0.6984]],\n",
      "\n",
      "        [[0.5000, 0.6988, 0.7026,  ..., 0.6969, 0.6981, 0.7023]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5476, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7016, 0.6985,  ..., 0.7064, 0.6971, 0.6992]],\n",
      "\n",
      "        [[0.7311, 0.6961, 0.7006,  ..., 0.7024, 0.7028, 0.6997]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.6931,  ..., 0.6974, 0.7032, 0.7028]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6999, 0.7063,  ..., 0.6982, 0.7064, 0.7041]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.7001,  ..., 0.6975, 0.6999, 0.6959]],\n",
      "\n",
      "        [[0.7311, 0.7006, 0.6945,  ..., 0.7023, 0.7071, 0.6993]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4504, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7034, 0.6977,  ..., 0.6987, 0.7002, 0.7042]],\n",
      "\n",
      "        [[0.7311, 0.6999, 0.7032,  ..., 0.7064, 0.7048, 0.7009]],\n",
      "\n",
      "        [[0.7311, 0.7038, 0.6927,  ..., 0.7021, 0.7030, 0.6985]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7021, 0.7032,  ..., 0.7006, 0.7011, 0.7003]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.6999,  ..., 0.6952, 0.7026, 0.7040]],\n",
      "\n",
      "        [[0.7311, 0.7042, 0.7000,  ..., 0.7008, 0.7038, 0.6971]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4512, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.6951, 0.7011,  ..., 0.7017, 0.7045, 0.7022]],\n",
      "\n",
      "        [[0.7311, 0.7050, 0.7014,  ..., 0.7020, 0.6954, 0.7042]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.7041,  ..., 0.6930, 0.6985, 0.6997]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6990, 0.6994,  ..., 0.6982, 0.6952, 0.7038]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7033,  ..., 0.7024, 0.7042, 0.7016]],\n",
      "\n",
      "        [[0.5000, 0.7036, 0.7002,  ..., 0.7002, 0.7031, 0.6949]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4707, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6959, 0.7035,  ..., 0.6999, 0.6986, 0.7023]],\n",
      "\n",
      "        [[0.7311, 0.6981, 0.6995,  ..., 0.6939, 0.6945, 0.6981]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6929,  ..., 0.7016, 0.7067, 0.6976]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6983, 0.7013,  ..., 0.6976, 0.6975, 0.6991]],\n",
      "\n",
      "        [[0.5000, 0.7006, 0.7018,  ..., 0.7037, 0.7030, 0.7037]],\n",
      "\n",
      "        [[0.7311, 0.6998, 0.7052,  ..., 0.6968, 0.7013, 0.7026]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4947, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7009, 0.6971,  ..., 0.6979, 0.7018, 0.6971]],\n",
      "\n",
      "        [[0.7311, 0.6905, 0.6994,  ..., 0.7067, 0.6995, 0.6981]],\n",
      "\n",
      "        [[0.5000, 0.7024, 0.7043,  ..., 0.6981, 0.6961, 0.7001]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6948, 0.7030,  ..., 0.6971, 0.6987, 0.6978]],\n",
      "\n",
      "        [[0.5000, 0.7011, 0.7005,  ..., 0.6965, 0.7009, 0.7029]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.6984,  ..., 0.7008, 0.6982, 0.7023]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5149, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6940, 0.7008,  ..., 0.6966, 0.7051, 0.7007]],\n",
      "\n",
      "        [[0.7311, 0.7011, 0.6941,  ..., 0.7007, 0.6949, 0.6901]],\n",
      "\n",
      "        [[0.7311, 0.6946, 0.6952,  ..., 0.7023, 0.7069, 0.6994]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7026, 0.7014,  ..., 0.7000, 0.7043, 0.7036]],\n",
      "\n",
      "        [[0.7311, 0.6970, 0.7011,  ..., 0.7009, 0.6958, 0.7017]],\n",
      "\n",
      "        [[0.5000, 0.6955, 0.7005,  ..., 0.7063, 0.6991, 0.6982]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5619, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6933, 0.7008,  ..., 0.7006, 0.7007, 0.6930]],\n",
      "\n",
      "        [[0.7311, 0.7013, 0.6956,  ..., 0.6988, 0.7034, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.6997, 0.7000,  ..., 0.6972, 0.7016, 0.7013]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7002, 0.6977,  ..., 0.6972, 0.6984, 0.6970]],\n",
      "\n",
      "        [[0.5000, 0.6966, 0.6989,  ..., 0.7027, 0.7064, 0.6958]],\n",
      "\n",
      "        [[0.5000, 0.6958, 0.7001,  ..., 0.7012, 0.6984, 0.6995]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4608, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6963, 0.7044,  ..., 0.7079, 0.7003, 0.6956]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.7017,  ..., 0.7024, 0.6984, 0.6958]],\n",
      "\n",
      "        [[0.5000, 0.7036, 0.6970,  ..., 0.7011, 0.7077, 0.6925]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7038, 0.6984,  ..., 0.6976, 0.7013, 0.6984]],\n",
      "\n",
      "        [[0.7311, 0.6955, 0.7007,  ..., 0.7026, 0.6982, 0.7000]],\n",
      "\n",
      "        [[0.5000, 0.6964, 0.7041,  ..., 0.7029, 0.6974, 0.6967]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4984, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7001, 0.7013,  ..., 0.7005, 0.6937, 0.6999]],\n",
      "\n",
      "        [[0.7311, 0.6989, 0.7037,  ..., 0.7101, 0.7081, 0.6976]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.6982,  ..., 0.7026, 0.7013, 0.6962]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6984, 0.6984,  ..., 0.6987, 0.7068, 0.7007]],\n",
      "\n",
      "        [[0.7311, 0.7025, 0.6973,  ..., 0.6998, 0.6990, 0.6928]],\n",
      "\n",
      "        [[0.5000, 0.6973, 0.6978,  ..., 0.6937, 0.6980, 0.7002]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4674, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7033, 0.6981,  ..., 0.6988, 0.7052, 0.7024]],\n",
      "\n",
      "        [[0.7311, 0.6956, 0.6987,  ..., 0.7007, 0.7010, 0.6962]],\n",
      "\n",
      "        [[0.5000, 0.7056, 0.7036,  ..., 0.7018, 0.7010, 0.7009]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7065, 0.7014,  ..., 0.6973, 0.6969, 0.6986]],\n",
      "\n",
      "        [[0.7311, 0.7000, 0.6951,  ..., 0.6957, 0.6970, 0.7008]],\n",
      "\n",
      "        [[0.7311, 0.7023, 0.6995,  ..., 0.6973, 0.6986, 0.7027]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4513, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6999, 0.6983,  ..., 0.7028, 0.7021, 0.7011]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.7072,  ..., 0.7013, 0.7000, 0.7031]],\n",
      "\n",
      "        [[0.7311, 0.6995, 0.6965,  ..., 0.6987, 0.7054, 0.7011]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7017, 0.7025,  ..., 0.6998, 0.6930, 0.6961]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.7009,  ..., 0.7003, 0.6996, 0.7034]],\n",
      "\n",
      "        [[0.5000, 0.6945, 0.7021,  ..., 0.7027, 0.7002, 0.7013]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4551, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7031, 0.6955,  ..., 0.6998, 0.7042, 0.6976]],\n",
      "\n",
      "        [[0.7311, 0.7037, 0.7031,  ..., 0.6956, 0.7032, 0.6961]],\n",
      "\n",
      "        [[0.7311, 0.7003, 0.7002,  ..., 0.6936, 0.6979, 0.7001]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7063, 0.7003,  ..., 0.6992, 0.7048, 0.6965]],\n",
      "\n",
      "        [[0.5000, 0.7006, 0.6977,  ..., 0.6919, 0.6997, 0.6907]],\n",
      "\n",
      "        [[0.5000, 0.7029, 0.7012,  ..., 0.6942, 0.7010, 0.7003]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.6014, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7002, 0.7004,  ..., 0.6995, 0.6986, 0.6975]],\n",
      "\n",
      "        [[0.7311, 0.6946, 0.7013,  ..., 0.6968, 0.7017, 0.7037]],\n",
      "\n",
      "        [[0.7311, 0.6990, 0.7012,  ..., 0.7047, 0.6991, 0.6965]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6978, 0.7023,  ..., 0.7016, 0.6956, 0.7018]],\n",
      "\n",
      "        [[0.7311, 0.6999, 0.6972,  ..., 0.7017, 0.6958, 0.6993]],\n",
      "\n",
      "        [[0.5000, 0.7034, 0.6952,  ..., 0.6978, 0.7026, 0.7045]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4423, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7045, 0.7004,  ..., 0.6984, 0.6991, 0.7073]],\n",
      "\n",
      "        [[0.7311, 0.7000, 0.6966,  ..., 0.7062, 0.7001, 0.6986]],\n",
      "\n",
      "        [[0.7311, 0.6970, 0.6952,  ..., 0.7043, 0.6963, 0.6943]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7039, 0.6979,  ..., 0.6974, 0.6967, 0.7015]],\n",
      "\n",
      "        [[0.5000, 0.6990, 0.7033,  ..., 0.6958, 0.7002, 0.7004]],\n",
      "\n",
      "        [[0.7311, 0.7054, 0.6985,  ..., 0.6996, 0.7042, 0.6953]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4411, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6983, 0.6936,  ..., 0.7017, 0.6991, 0.7049]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6968,  ..., 0.7033, 0.7010, 0.7029]],\n",
      "\n",
      "        [[0.7311, 0.6981, 0.6972,  ..., 0.7013, 0.7031, 0.6998]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6984, 0.7002,  ..., 0.7007, 0.6952, 0.7002]],\n",
      "\n",
      "        [[0.7311, 0.7029, 0.7009,  ..., 0.6971, 0.6996, 0.7075]],\n",
      "\n",
      "        [[0.7311, 0.6998, 0.7013,  ..., 0.6981, 0.6971, 0.6995]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4440, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7044, 0.7067,  ..., 0.7002, 0.6982, 0.6968]],\n",
      "\n",
      "        [[0.7311, 0.6990, 0.6980,  ..., 0.7053, 0.7021, 0.7002]],\n",
      "\n",
      "        [[0.7311, 0.7009, 0.7003,  ..., 0.7030, 0.6998, 0.7002]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7035, 0.7050,  ..., 0.7008, 0.6986, 0.7067]],\n",
      "\n",
      "        [[0.5000, 0.6953, 0.7044,  ..., 0.6979, 0.7015, 0.6925]],\n",
      "\n",
      "        [[0.7311, 0.7008, 0.6931,  ..., 0.7047, 0.7035, 0.6984]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5262, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6964, 0.6961,  ..., 0.7023, 0.6963, 0.6975]],\n",
      "\n",
      "        [[0.5000, 0.7030, 0.7052,  ..., 0.6979, 0.7021, 0.7031]],\n",
      "\n",
      "        [[0.7311, 0.7024, 0.6977,  ..., 0.7030, 0.6967, 0.6972]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7004, 0.6988,  ..., 0.6994, 0.6986, 0.7017]],\n",
      "\n",
      "        [[0.7311, 0.6946, 0.7033,  ..., 0.7072, 0.6989, 0.7059]],\n",
      "\n",
      "        [[0.7311, 0.6985, 0.7017,  ..., 0.6997, 0.7060, 0.7015]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4575, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7040, 0.7000,  ..., 0.7021, 0.6915, 0.7002]],\n",
      "\n",
      "        [[0.5000, 0.7008, 0.6987,  ..., 0.7034, 0.6997, 0.7056]],\n",
      "\n",
      "        [[0.7311, 0.7020, 0.6982,  ..., 0.7064, 0.7023, 0.7002]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7129, 0.7042,  ..., 0.7028, 0.7024, 0.7022]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6949,  ..., 0.7024, 0.6960, 0.6968]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.7052,  ..., 0.7010, 0.6958, 0.7013]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4985, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6923, 0.7030,  ..., 0.7004, 0.6976, 0.6963]],\n",
      "\n",
      "        [[0.7311, 0.6957, 0.7008,  ..., 0.6942, 0.7033, 0.6996]],\n",
      "\n",
      "        [[0.5000, 0.6996, 0.6978,  ..., 0.7004, 0.7008, 0.6994]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7009, 0.6998,  ..., 0.7044, 0.6995, 0.6981]],\n",
      "\n",
      "        [[0.7311, 0.7035, 0.6991,  ..., 0.6996, 0.7055, 0.6959]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6962,  ..., 0.7006, 0.7031, 0.7036]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4460, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7008, 0.7036,  ..., 0.6982, 0.6978, 0.6929]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.6979,  ..., 0.6899, 0.7037, 0.6918]],\n",
      "\n",
      "        [[0.7311, 0.6994, 0.6944,  ..., 0.7082, 0.7001, 0.7047]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7036, 0.6997,  ..., 0.7051, 0.6980, 0.7000]],\n",
      "\n",
      "        [[0.7311, 0.7034, 0.6967,  ..., 0.6980, 0.7018, 0.7021]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.7087,  ..., 0.6939, 0.6949, 0.7004]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4789, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.7007, 0.6979,  ..., 0.6987, 0.7007, 0.6989]],\n",
      "\n",
      "        [[0.7311, 0.7022, 0.6917,  ..., 0.6952, 0.6982, 0.7011]],\n",
      "\n",
      "        [[0.7311, 0.7010, 0.7029,  ..., 0.7011, 0.6971, 0.6981]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7039, 0.6994,  ..., 0.6962, 0.7031, 0.6971]],\n",
      "\n",
      "        [[0.7311, 0.7008, 0.7004,  ..., 0.7028, 0.7004, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.7056, 0.6994,  ..., 0.7030, 0.6974, 0.6997]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4651, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7067, 0.7015,  ..., 0.7024, 0.6995, 0.6962]],\n",
      "\n",
      "        [[0.5000, 0.6898, 0.6994,  ..., 0.7040, 0.6959, 0.7011]],\n",
      "\n",
      "        [[0.7311, 0.7038, 0.7024,  ..., 0.7033, 0.7069, 0.7044]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7007, 0.6975,  ..., 0.7053, 0.7015, 0.6981]],\n",
      "\n",
      "        [[0.7311, 0.7000, 0.7020,  ..., 0.7039, 0.6991, 0.7034]],\n",
      "\n",
      "        [[0.7311, 0.6974, 0.6991,  ..., 0.6997, 0.7025, 0.6999]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4531, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7025, 0.6969,  ..., 0.6999, 0.7023, 0.7071]],\n",
      "\n",
      "        [[0.7311, 0.6989, 0.6957,  ..., 0.7043, 0.6950, 0.6951]],\n",
      "\n",
      "        [[0.7311, 0.7038, 0.6991,  ..., 0.6961, 0.7005, 0.7001]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7009, 0.7034,  ..., 0.7022, 0.7007, 0.7006]],\n",
      "\n",
      "        [[0.7311, 0.7004, 0.7030,  ..., 0.7040, 0.6987, 0.6968]],\n",
      "\n",
      "        [[0.7311, 0.7045, 0.7046,  ..., 0.7008, 0.7027, 0.7019]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4912, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7015, 0.6982,  ..., 0.7016, 0.7024, 0.6931]],\n",
      "\n",
      "        [[0.7311, 0.6969, 0.6996,  ..., 0.7012, 0.6986, 0.6977]],\n",
      "\n",
      "        [[0.5000, 0.7011, 0.6985,  ..., 0.7000, 0.7028, 0.7030]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7034, 0.6993,  ..., 0.6998, 0.7000, 0.6992]],\n",
      "\n",
      "        [[0.7311, 0.6959, 0.7011,  ..., 0.6954, 0.6972, 0.6973]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7012,  ..., 0.7028, 0.7004, 0.7014]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5707, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6998, 0.6986,  ..., 0.6980, 0.6988, 0.6996]],\n",
      "\n",
      "        [[0.5000, 0.6960, 0.7017,  ..., 0.7050, 0.7007, 0.7063]],\n",
      "\n",
      "        [[0.5000, 0.6975, 0.7035,  ..., 0.7039, 0.6954, 0.6966]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7003, 0.7057,  ..., 0.6995, 0.7018, 0.7035]],\n",
      "\n",
      "        [[0.5000, 0.6988, 0.6978,  ..., 0.7010, 0.6994, 0.7024]],\n",
      "\n",
      "        [[0.5000, 0.7022, 0.6982,  ..., 0.7072, 0.7042, 0.6983]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5278, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7033, 0.7019,  ..., 0.6995, 0.7035, 0.7036]],\n",
      "\n",
      "        [[0.5000, 0.7003, 0.6990,  ..., 0.7039, 0.6984, 0.6999]],\n",
      "\n",
      "        [[0.5000, 0.7022, 0.6934,  ..., 0.6997, 0.6990, 0.6944]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7083, 0.7013,  ..., 0.7071, 0.6972, 0.6958]],\n",
      "\n",
      "        [[0.7311, 0.7043, 0.7019,  ..., 0.7012, 0.6998, 0.6988]],\n",
      "\n",
      "        [[0.5000, 0.7011, 0.6998,  ..., 0.7030, 0.6986, 0.7011]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4811, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7078, 0.6977,  ..., 0.7011, 0.7026, 0.6972]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.6987,  ..., 0.7006, 0.7103, 0.6964]],\n",
      "\n",
      "        [[0.5000, 0.7030, 0.7041,  ..., 0.7021, 0.6985, 0.7043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7022, 0.7007,  ..., 0.7020, 0.6972, 0.7010]],\n",
      "\n",
      "        [[0.5000, 0.7038, 0.6998,  ..., 0.6975, 0.6963, 0.7015]],\n",
      "\n",
      "        [[0.7311, 0.6972, 0.7046,  ..., 0.7006, 0.7030, 0.6988]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4519, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7058, 0.7004,  ..., 0.7041, 0.7024, 0.7018]],\n",
      "\n",
      "        [[0.7311, 0.7017, 0.6972,  ..., 0.6971, 0.6959, 0.7023]],\n",
      "\n",
      "        [[0.7311, 0.7015, 0.7031,  ..., 0.6984, 0.7002, 0.7054]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7041, 0.6997,  ..., 0.7027, 0.6986, 0.6988]],\n",
      "\n",
      "        [[0.7311, 0.6956, 0.7072,  ..., 0.7062, 0.6984, 0.7022]],\n",
      "\n",
      "        [[0.5000, 0.6986, 0.7026,  ..., 0.6993, 0.6992, 0.6983]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4497, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7015, 0.6999,  ..., 0.7016, 0.6991, 0.7027]],\n",
      "\n",
      "        [[0.5000, 0.7094, 0.6984,  ..., 0.6987, 0.6976, 0.7031]],\n",
      "\n",
      "        [[0.7311, 0.6961, 0.7011,  ..., 0.7024, 0.7035, 0.7018]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6987, 0.7017,  ..., 0.7045, 0.6993, 0.6960]],\n",
      "\n",
      "        [[0.7311, 0.6983, 0.7034,  ..., 0.7051, 0.7020, 0.6969]],\n",
      "\n",
      "        [[0.5000, 0.7035, 0.6944,  ..., 0.6972, 0.7046, 0.7015]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5307, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6999, 0.6974,  ..., 0.6996, 0.6977, 0.7012]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.7017,  ..., 0.7016, 0.6973, 0.6943]],\n",
      "\n",
      "        [[0.7311, 0.7049, 0.7027,  ..., 0.7031, 0.6989, 0.7045]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7014, 0.6975,  ..., 0.7092, 0.6971, 0.7026]],\n",
      "\n",
      "        [[0.5000, 0.6952, 0.6984,  ..., 0.6950, 0.7030, 0.6962]],\n",
      "\n",
      "        [[0.7311, 0.6992, 0.6973,  ..., 0.7004, 0.7035, 0.7058]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4203, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7043, 0.7001,  ..., 0.6945, 0.7008, 0.7005]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.7041,  ..., 0.6927, 0.6998, 0.7007]],\n",
      "\n",
      "        [[0.7311, 0.6978, 0.6962,  ..., 0.7032, 0.7012, 0.7035]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7047, 0.7044,  ..., 0.7000, 0.7042, 0.7045]],\n",
      "\n",
      "        [[0.5000, 0.6951, 0.7000,  ..., 0.6955, 0.6966, 0.7005]],\n",
      "\n",
      "        [[0.7311, 0.7010, 0.7017,  ..., 0.6985, 0.6993, 0.7071]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5287, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6984, 0.7026,  ..., 0.7018, 0.6898, 0.7007]],\n",
      "\n",
      "        [[0.7311, 0.6967, 0.7009,  ..., 0.6989, 0.7022, 0.6980]],\n",
      "\n",
      "        [[0.5000, 0.7000, 0.7029,  ..., 0.7055, 0.7028, 0.7021]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6994, 0.6981,  ..., 0.6988, 0.7053, 0.7017]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.7019,  ..., 0.7049, 0.6976, 0.7013]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.6961,  ..., 0.7006, 0.6975, 0.6973]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5585, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7016, 0.6997,  ..., 0.6988, 0.6936, 0.6970]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.7050,  ..., 0.7033, 0.6950, 0.7011]],\n",
      "\n",
      "        [[0.5000, 0.7010, 0.6990,  ..., 0.6965, 0.6999, 0.7029]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6954, 0.7019,  ..., 0.7000, 0.7010, 0.6988]],\n",
      "\n",
      "        [[0.7311, 0.7040, 0.6993,  ..., 0.7011, 0.7010, 0.6942]],\n",
      "\n",
      "        [[0.7311, 0.7029, 0.6987,  ..., 0.7014, 0.7018, 0.7025]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4930, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7018, 0.7006,  ..., 0.7016, 0.6998, 0.6963]],\n",
      "\n",
      "        [[0.7311, 0.6973, 0.7037,  ..., 0.7003, 0.6994, 0.7020]],\n",
      "\n",
      "        [[0.5000, 0.7013, 0.6992,  ..., 0.6997, 0.6993, 0.6961]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7029, 0.6934,  ..., 0.6998, 0.6965, 0.6940]],\n",
      "\n",
      "        [[0.5000, 0.7011, 0.6966,  ..., 0.7007, 0.7005, 0.7019]],\n",
      "\n",
      "        [[0.7311, 0.7041, 0.7045,  ..., 0.7012, 0.6982, 0.6972]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4884, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7004, 0.7026,  ..., 0.6990, 0.7021, 0.6954]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.6998,  ..., 0.6965, 0.6993, 0.7014]],\n",
      "\n",
      "        [[0.5000, 0.7000, 0.7004,  ..., 0.7036, 0.7006, 0.6964]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6986, 0.6986,  ..., 0.6978, 0.6999, 0.7002]],\n",
      "\n",
      "        [[0.7311, 0.6951, 0.6953,  ..., 0.7012, 0.7008, 0.6981]],\n",
      "\n",
      "        [[0.7311, 0.7038, 0.6945,  ..., 0.7030, 0.6998, 0.6988]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4461, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6949, 0.7042,  ..., 0.6993, 0.6979, 0.7026]],\n",
      "\n",
      "        [[0.5000, 0.6983, 0.6987,  ..., 0.7001, 0.6988, 0.7010]],\n",
      "\n",
      "        [[0.7311, 0.6975, 0.6970,  ..., 0.6990, 0.7020, 0.7014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7016, 0.6933,  ..., 0.6993, 0.6970, 0.7012]],\n",
      "\n",
      "        [[0.5000, 0.6968, 0.7035,  ..., 0.6973, 0.7006, 0.6966]],\n",
      "\n",
      "        [[0.7311, 0.7012, 0.6966,  ..., 0.6975, 0.7018, 0.6938]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4772, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7065, 0.7001,  ..., 0.7037, 0.6998, 0.6984]],\n",
      "\n",
      "        [[0.5000, 0.7025, 0.7049,  ..., 0.7032, 0.7010, 0.7035]],\n",
      "\n",
      "        [[0.5000, 0.7003, 0.6999,  ..., 0.7085, 0.6940, 0.6996]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7096, 0.6972,  ..., 0.7005, 0.6996, 0.7009]],\n",
      "\n",
      "        [[0.7311, 0.6981, 0.7000,  ..., 0.6999, 0.6976, 0.6983]],\n",
      "\n",
      "        [[0.5000, 0.7002, 0.7030,  ..., 0.6973, 0.7089, 0.6997]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5355, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7035, 0.7016,  ..., 0.6998, 0.7025, 0.6993]],\n",
      "\n",
      "        [[0.7311, 0.7085, 0.6986,  ..., 0.7002, 0.6946, 0.6998]],\n",
      "\n",
      "        [[0.7311, 0.6904, 0.6971,  ..., 0.7019, 0.7017, 0.6957]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7007, 0.7025,  ..., 0.7016, 0.6962, 0.7013]],\n",
      "\n",
      "        [[0.7311, 0.6999, 0.6984,  ..., 0.6976, 0.7049, 0.7053]],\n",
      "\n",
      "        [[0.5000, 0.7020, 0.6955,  ..., 0.7002, 0.7037, 0.6984]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5142, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.6980, 0.6958,  ..., 0.6979, 0.6957, 0.6941]],\n",
      "\n",
      "        [[0.7311, 0.6943, 0.7052,  ..., 0.7004, 0.7019, 0.7014]],\n",
      "\n",
      "        [[0.7311, 0.7000, 0.6941,  ..., 0.6969, 0.6984, 0.6950]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7008, 0.6978,  ..., 0.7020, 0.7023, 0.6926]],\n",
      "\n",
      "        [[0.7311, 0.6973, 0.7050,  ..., 0.6990, 0.6999, 0.6978]],\n",
      "\n",
      "        [[0.5000, 0.7011, 0.7036,  ..., 0.7002, 0.6974, 0.7030]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4614, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6941, 0.7025,  ..., 0.6965, 0.6997, 0.7002]],\n",
      "\n",
      "        [[0.5000, 0.7019, 0.6999,  ..., 0.6952, 0.7023, 0.6974]],\n",
      "\n",
      "        [[0.7311, 0.6990, 0.6985,  ..., 0.7000, 0.7018, 0.6976]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7033, 0.6974,  ..., 0.7041, 0.6991, 0.7001]],\n",
      "\n",
      "        [[0.7311, 0.6989, 0.6984,  ..., 0.6987, 0.7001, 0.6980]],\n",
      "\n",
      "        [[0.5000, 0.6941, 0.6989,  ..., 0.6981, 0.7017, 0.7062]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5189, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7013, 0.6996,  ..., 0.6979, 0.6992, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.6949,  ..., 0.6961, 0.7057, 0.7053]],\n",
      "\n",
      "        [[0.7311, 0.7015, 0.7021,  ..., 0.6972, 0.6987, 0.7048]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7030, 0.6972,  ..., 0.7017, 0.7025, 0.6939]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.6947,  ..., 0.7042, 0.7022, 0.7004]],\n",
      "\n",
      "        [[0.7311, 0.7002, 0.7041,  ..., 0.7034, 0.7019, 0.7033]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4910, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6985, 0.7041,  ..., 0.7031, 0.6934, 0.7045]],\n",
      "\n",
      "        [[0.7311, 0.6968, 0.7012,  ..., 0.6965, 0.6996, 0.6957]],\n",
      "\n",
      "        [[0.7311, 0.7051, 0.6989,  ..., 0.6976, 0.7024, 0.6982]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6992, 0.6981,  ..., 0.6955, 0.7029, 0.7017]],\n",
      "\n",
      "        [[0.7311, 0.6956, 0.7043,  ..., 0.7011, 0.6983, 0.7039]],\n",
      "\n",
      "        [[0.5000, 0.6905, 0.7084,  ..., 0.6969, 0.7061, 0.7006]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5842, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7004, 0.7016,  ..., 0.6982, 0.7040, 0.7029]],\n",
      "\n",
      "        [[0.5000, 0.6988, 0.7026,  ..., 0.7018, 0.7015, 0.7050]],\n",
      "\n",
      "        [[0.7311, 0.7025, 0.7023,  ..., 0.7030, 0.7019, 0.7024]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7049, 0.7034,  ..., 0.7038, 0.7049, 0.7094]],\n",
      "\n",
      "        [[0.7311, 0.7069, 0.6955,  ..., 0.6960, 0.7014, 0.7033]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.7005,  ..., 0.6990, 0.7045, 0.7004]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4768, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7035, 0.7033,  ..., 0.7023, 0.7017, 0.6982]],\n",
      "\n",
      "        [[0.7311, 0.6960, 0.7007,  ..., 0.7034, 0.7031, 0.7010]],\n",
      "\n",
      "        [[0.5000, 0.6920, 0.6968,  ..., 0.7034, 0.6985, 0.6951]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7008, 0.6986,  ..., 0.7034, 0.7036, 0.6952]],\n",
      "\n",
      "        [[0.7311, 0.6995, 0.7003,  ..., 0.7005, 0.7018, 0.7006]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.6975,  ..., 0.7016, 0.7045, 0.7036]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4689, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7011, 0.6962,  ..., 0.6999, 0.6945, 0.6956]],\n",
      "\n",
      "        [[0.5000, 0.7006, 0.6985,  ..., 0.7066, 0.7037, 0.7007]],\n",
      "\n",
      "        [[0.5000, 0.6947, 0.6979,  ..., 0.6985, 0.6969, 0.6983]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6920, 0.6985,  ..., 0.6972, 0.7028, 0.7010]],\n",
      "\n",
      "        [[0.7311, 0.7000, 0.7032,  ..., 0.7005, 0.6941, 0.6996]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.6974,  ..., 0.7020, 0.6981, 0.6993]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5260, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7037, 0.6996,  ..., 0.7029, 0.6986, 0.6968]],\n",
      "\n",
      "        [[0.7311, 0.7009, 0.6964,  ..., 0.6996, 0.6960, 0.7024]],\n",
      "\n",
      "        [[0.7311, 0.7019, 0.7058,  ..., 0.6971, 0.7027, 0.6992]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6975, 0.7057,  ..., 0.6982, 0.6987, 0.6972]],\n",
      "\n",
      "        [[0.5000, 0.6981, 0.7003,  ..., 0.6971, 0.7040, 0.6967]],\n",
      "\n",
      "        [[0.7311, 0.7020, 0.6997,  ..., 0.6973, 0.6966, 0.6951]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.6179, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6975, 0.7003,  ..., 0.6998, 0.6985, 0.6975]],\n",
      "\n",
      "        [[0.5000, 0.7005, 0.6972,  ..., 0.7050, 0.7062, 0.6958]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.7072,  ..., 0.6986, 0.6957, 0.7014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6979, 0.6935,  ..., 0.7004, 0.6990, 0.6993]],\n",
      "\n",
      "        [[0.5000, 0.7064, 0.6980,  ..., 0.6975, 0.7015, 0.7040]],\n",
      "\n",
      "        [[0.5000, 0.7025, 0.7005,  ..., 0.6996, 0.7035, 0.7016]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5192, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6958, 0.7035,  ..., 0.6977, 0.6977, 0.6971]],\n",
      "\n",
      "        [[0.5000, 0.6941, 0.7008,  ..., 0.6985, 0.7023, 0.6990]],\n",
      "\n",
      "        [[0.7311, 0.7020, 0.7023,  ..., 0.7015, 0.7018, 0.7009]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7015, 0.7032,  ..., 0.6988, 0.6982, 0.6968]],\n",
      "\n",
      "        [[0.7311, 0.6963, 0.7050,  ..., 0.7017, 0.7055, 0.6945]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.6978,  ..., 0.6983, 0.6952, 0.7015]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4803, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7019, 0.7026,  ..., 0.7016, 0.6976, 0.7072]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.7026,  ..., 0.7020, 0.7028, 0.7047]],\n",
      "\n",
      "        [[0.7311, 0.7029, 0.7065,  ..., 0.6996, 0.6973, 0.7098]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6989, 0.7006,  ..., 0.6954, 0.6979, 0.7014]],\n",
      "\n",
      "        [[0.7311, 0.7014, 0.7021,  ..., 0.6985, 0.7007, 0.7058]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.7027,  ..., 0.6991, 0.7058, 0.6993]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5097, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6982, 0.6979,  ..., 0.6923, 0.7010, 0.6998]],\n",
      "\n",
      "        [[0.7311, 0.7069, 0.6977,  ..., 0.7022, 0.6995, 0.7016]],\n",
      "\n",
      "        [[0.5000, 0.6993, 0.6898,  ..., 0.7038, 0.7049, 0.6923]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6987, 0.7008,  ..., 0.6987, 0.6977, 0.6949]],\n",
      "\n",
      "        [[0.5000, 0.7023, 0.7020,  ..., 0.7019, 0.6977, 0.7015]],\n",
      "\n",
      "        [[0.7311, 0.6947, 0.7029,  ..., 0.7029, 0.7004, 0.6984]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4987, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6942, 0.7016,  ..., 0.6988, 0.7006, 0.6945]],\n",
      "\n",
      "        [[0.7311, 0.6920, 0.6952,  ..., 0.7052, 0.7022, 0.6969]],\n",
      "\n",
      "        [[0.7311, 0.6990, 0.7007,  ..., 0.7007, 0.7007, 0.7005]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7009, 0.7000,  ..., 0.7004, 0.7049, 0.7022]],\n",
      "\n",
      "        [[0.5000, 0.6985, 0.7002,  ..., 0.7005, 0.7010, 0.7065]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.7010,  ..., 0.6978, 0.6977, 0.7029]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4477, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7034, 0.6974,  ..., 0.6986, 0.7044, 0.6989]],\n",
      "\n",
      "        [[0.7311, 0.7056, 0.6978,  ..., 0.6971, 0.6975, 0.6998]],\n",
      "\n",
      "        [[0.7311, 0.6956, 0.6988,  ..., 0.7034, 0.7028, 0.7014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6990, 0.7026,  ..., 0.6995, 0.6992, 0.6965]],\n",
      "\n",
      "        [[0.5000, 0.6996, 0.6983,  ..., 0.6980, 0.6982, 0.7017]],\n",
      "\n",
      "        [[0.5000, 0.7024, 0.6982,  ..., 0.7006, 0.6959, 0.6982]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4494, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6959, 0.7000,  ..., 0.7002, 0.6985, 0.7008]],\n",
      "\n",
      "        [[0.7311, 0.7023, 0.6982,  ..., 0.6985, 0.6940, 0.7007]],\n",
      "\n",
      "        [[0.7311, 0.7003, 0.6981,  ..., 0.7010, 0.6978, 0.7041]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6947, 0.7042,  ..., 0.7024, 0.6917, 0.6977]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.7018,  ..., 0.7019, 0.6967, 0.6950]],\n",
      "\n",
      "        [[0.7311, 0.6969, 0.7003,  ..., 0.6972, 0.7037, 0.7024]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4626, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7024, 0.7003,  ..., 0.7056, 0.7003, 0.6999]],\n",
      "\n",
      "        [[0.5000, 0.7011, 0.7011,  ..., 0.7049, 0.7000, 0.7001]],\n",
      "\n",
      "        [[0.7311, 0.6977, 0.7008,  ..., 0.6990, 0.7016, 0.6985]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7009, 0.6990,  ..., 0.7043, 0.6977, 0.6988]],\n",
      "\n",
      "        [[0.7311, 0.6969, 0.7010,  ..., 0.7042, 0.7042, 0.7025]],\n",
      "\n",
      "        [[0.5000, 0.6999, 0.6989,  ..., 0.6960, 0.7040, 0.6977]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4769, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7010, 0.7005,  ..., 0.7047, 0.7008, 0.7018]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.6992,  ..., 0.7017, 0.7020, 0.7014]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.6955,  ..., 0.7018, 0.7004, 0.7020]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7045, 0.6974,  ..., 0.6964, 0.7018, 0.7015]],\n",
      "\n",
      "        [[0.7311, 0.7004, 0.6966,  ..., 0.6972, 0.7051, 0.6991]],\n",
      "\n",
      "        [[0.7311, 0.7062, 0.6990,  ..., 0.6993, 0.7001, 0.7021]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4850, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6987, 0.6993,  ..., 0.7006, 0.7013, 0.7007]],\n",
      "\n",
      "        [[0.5000, 0.6975, 0.6975,  ..., 0.7005, 0.6991, 0.7038]],\n",
      "\n",
      "        [[0.7311, 0.6975, 0.6966,  ..., 0.6985, 0.7036, 0.7032]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6973, 0.6995,  ..., 0.6980, 0.7021, 0.6999]],\n",
      "\n",
      "        [[0.5000, 0.7013, 0.7037,  ..., 0.6971, 0.7019, 0.7056]],\n",
      "\n",
      "        [[0.7311, 0.6992, 0.6981,  ..., 0.6977, 0.7001, 0.7038]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4537, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.7070, 0.6994,  ..., 0.6998, 0.6997, 0.7021]],\n",
      "\n",
      "        [[0.7311, 0.6955, 0.7011,  ..., 0.7019, 0.6988, 0.7011]],\n",
      "\n",
      "        [[0.5000, 0.7031, 0.7029,  ..., 0.7057, 0.7013, 0.6996]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6970, 0.6999,  ..., 0.6991, 0.6975, 0.7005]],\n",
      "\n",
      "        [[0.5000, 0.6957, 0.7016,  ..., 0.6957, 0.6957, 0.6975]],\n",
      "\n",
      "        [[0.7311, 0.7021, 0.6999,  ..., 0.6964, 0.6995, 0.6962]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4926, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6999, 0.6969,  ..., 0.6950, 0.7007, 0.7066]],\n",
      "\n",
      "        [[0.5000, 0.7001, 0.7075,  ..., 0.6971, 0.6982, 0.7027]],\n",
      "\n",
      "        [[0.7311, 0.7035, 0.7021,  ..., 0.7023, 0.7023, 0.7024]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6976, 0.6996,  ..., 0.7045, 0.6971, 0.6978]],\n",
      "\n",
      "        [[0.7311, 0.7008, 0.7048,  ..., 0.7002, 0.6977, 0.7026]],\n",
      "\n",
      "        [[0.5000, 0.6964, 0.7001,  ..., 0.6965, 0.6980, 0.7023]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4989, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6977, 0.7034,  ..., 0.6972, 0.6987, 0.7035]],\n",
      "\n",
      "        [[0.5000, 0.6988, 0.7030,  ..., 0.6973, 0.7012, 0.7079]],\n",
      "\n",
      "        [[0.5000, 0.7060, 0.6966,  ..., 0.6972, 0.6967, 0.6988]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7045, 0.6994,  ..., 0.7048, 0.7002, 0.7016]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.6996,  ..., 0.6936, 0.6994, 0.7015]],\n",
      "\n",
      "        [[0.7311, 0.7016, 0.6963,  ..., 0.7001, 0.7010, 0.6956]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5428, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7011, 0.7045,  ..., 0.7025, 0.6945, 0.7009]],\n",
      "\n",
      "        [[0.7311, 0.7022, 0.6950,  ..., 0.6978, 0.7016, 0.7017]],\n",
      "\n",
      "        [[0.7311, 0.7059, 0.6966,  ..., 0.7006, 0.6993, 0.7038]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7054, 0.6965,  ..., 0.7061, 0.6996, 0.7019]],\n",
      "\n",
      "        [[0.5000, 0.7068, 0.7037,  ..., 0.7028, 0.6979, 0.7044]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.7038,  ..., 0.6989, 0.6975, 0.7018]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5468, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6935, 0.6996,  ..., 0.7007, 0.6963, 0.7038]],\n",
      "\n",
      "        [[0.5000, 0.7004, 0.6956,  ..., 0.7040, 0.6993, 0.7017]],\n",
      "\n",
      "        [[0.7311, 0.6893, 0.7083,  ..., 0.6992, 0.7005, 0.7004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6992, 0.7079,  ..., 0.6984, 0.6997, 0.7002]],\n",
      "\n",
      "        [[0.7311, 0.7014, 0.7074,  ..., 0.6927, 0.6989, 0.7008]],\n",
      "\n",
      "        [[0.5000, 0.6944, 0.6965,  ..., 0.6965, 0.6998, 0.7007]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5343, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7027, 0.6977,  ..., 0.7028, 0.7032, 0.6941]],\n",
      "\n",
      "        [[0.7311, 0.7086, 0.7014,  ..., 0.7005, 0.6997, 0.7011]],\n",
      "\n",
      "        [[0.7311, 0.6998, 0.6963,  ..., 0.7044, 0.7001, 0.7035]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7011, 0.7013,  ..., 0.6994, 0.6983, 0.6967]],\n",
      "\n",
      "        [[0.7311, 0.6999, 0.7011,  ..., 0.6979, 0.6955, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.7045,  ..., 0.6959, 0.7028, 0.7011]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4962, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7071, 0.6917,  ..., 0.6998, 0.7005, 0.7028]],\n",
      "\n",
      "        [[0.5000, 0.6973, 0.7009,  ..., 0.6993, 0.6969, 0.7001]],\n",
      "\n",
      "        [[0.5000, 0.7017, 0.6994,  ..., 0.7000, 0.7048, 0.6949]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7010, 0.7017,  ..., 0.7039, 0.6990, 0.6976]],\n",
      "\n",
      "        [[0.5000, 0.6990, 0.6964,  ..., 0.7031, 0.6976, 0.7066]],\n",
      "\n",
      "        [[0.7311, 0.7012, 0.6945,  ..., 0.7003, 0.6979, 0.7019]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5188, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6983, 0.6999,  ..., 0.6976, 0.7015, 0.6983]],\n",
      "\n",
      "        [[0.5000, 0.6942, 0.6984,  ..., 0.6952, 0.6985, 0.6986]],\n",
      "\n",
      "        [[0.7311, 0.7038, 0.7049,  ..., 0.7016, 0.7002, 0.6966]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7036, 0.7028,  ..., 0.7037, 0.6996, 0.7040]],\n",
      "\n",
      "        [[0.7311, 0.6969, 0.6973,  ..., 0.7037, 0.6976, 0.7016]],\n",
      "\n",
      "        [[0.7311, 0.6984, 0.6964,  ..., 0.7016, 0.6949, 0.7012]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4598, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7045, 0.7049,  ..., 0.7002, 0.7008, 0.7048]],\n",
      "\n",
      "        [[0.7311, 0.7021, 0.6990,  ..., 0.7024, 0.7061, 0.7007]],\n",
      "\n",
      "        [[0.7311, 0.7035, 0.7035,  ..., 0.7022, 0.7003, 0.6997]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7018, 0.7033,  ..., 0.7012, 0.6952, 0.6991]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.6962,  ..., 0.7011, 0.7026, 0.6993]],\n",
      "\n",
      "        [[0.7311, 0.7064, 0.6998,  ..., 0.6956, 0.6988, 0.6998]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5061, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7000, 0.6977,  ..., 0.7000, 0.7013, 0.6968]],\n",
      "\n",
      "        [[0.7311, 0.7033, 0.7021,  ..., 0.6910, 0.6965, 0.7004]],\n",
      "\n",
      "        [[0.7311, 0.7002, 0.7036,  ..., 0.6985, 0.7027, 0.7075]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6997, 0.6993,  ..., 0.6996, 0.7015, 0.7032]],\n",
      "\n",
      "        [[0.7311, 0.7036, 0.7045,  ..., 0.6970, 0.6960, 0.7038]],\n",
      "\n",
      "        [[0.7311, 0.7028, 0.6984,  ..., 0.6980, 0.7008, 0.6939]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5017, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7054, 0.7034,  ..., 0.6980, 0.6967, 0.7030]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.6971,  ..., 0.6996, 0.7031, 0.7057]],\n",
      "\n",
      "        [[0.7311, 0.6990, 0.7031,  ..., 0.7014, 0.7030, 0.6964]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7041, 0.7011,  ..., 0.7008, 0.7007, 0.6980]],\n",
      "\n",
      "        [[0.7311, 0.7072, 0.6982,  ..., 0.7029, 0.6989, 0.7026]],\n",
      "\n",
      "        [[0.7311, 0.7018, 0.7014,  ..., 0.6961, 0.7022, 0.6927]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5614, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6949, 0.7012,  ..., 0.7040, 0.7018, 0.7008]],\n",
      "\n",
      "        [[0.7311, 0.6945, 0.7023,  ..., 0.7010, 0.6956, 0.6985]],\n",
      "\n",
      "        [[0.7311, 0.6993, 0.7011,  ..., 0.6969, 0.6981, 0.7010]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6965, 0.7021,  ..., 0.6998, 0.6920, 0.7014]],\n",
      "\n",
      "        [[0.7311, 0.6972, 0.6969,  ..., 0.6985, 0.7029, 0.6953]],\n",
      "\n",
      "        [[0.5000, 0.6970, 0.7014,  ..., 0.6990, 0.7020, 0.6977]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4568, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7031, 0.7057,  ..., 0.7006, 0.6989, 0.7014]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.7002,  ..., 0.7024, 0.7065, 0.6971]],\n",
      "\n",
      "        [[0.7311, 0.7002, 0.6995,  ..., 0.6979, 0.6987, 0.7040]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7027, 0.6989,  ..., 0.6977, 0.6972, 0.6953]],\n",
      "\n",
      "        [[0.5000, 0.6982, 0.6939,  ..., 0.7001, 0.6994, 0.6982]],\n",
      "\n",
      "        [[0.7311, 0.6975, 0.6995,  ..., 0.6984, 0.6996, 0.6965]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5031, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7042, 0.7004,  ..., 0.6974, 0.6942, 0.7025]],\n",
      "\n",
      "        [[0.5000, 0.7035, 0.7034,  ..., 0.6942, 0.6990, 0.7006]],\n",
      "\n",
      "        [[0.5000, 0.6986, 0.7038,  ..., 0.6998, 0.7011, 0.6986]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7029, 0.6995,  ..., 0.7015, 0.7008, 0.7003]],\n",
      "\n",
      "        [[0.7311, 0.7059, 0.7014,  ..., 0.7002, 0.7008, 0.7029]],\n",
      "\n",
      "        [[0.7311, 0.7023, 0.6982,  ..., 0.6987, 0.6946, 0.6997]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5089, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7080, 0.7019,  ..., 0.7004, 0.6976, 0.7045]],\n",
      "\n",
      "        [[0.7311, 0.7019, 0.6944,  ..., 0.7056, 0.7018, 0.6964]],\n",
      "\n",
      "        [[0.7311, 0.6946, 0.6982,  ..., 0.6982, 0.6999, 0.6998]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6980, 0.6989,  ..., 0.6996, 0.7003, 0.6987]],\n",
      "\n",
      "        [[0.5000, 0.7042, 0.6945,  ..., 0.7006, 0.7043, 0.7024]],\n",
      "\n",
      "        [[0.7311, 0.6984, 0.7013,  ..., 0.6940, 0.7029, 0.6965]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4400, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6936, 0.6979,  ..., 0.7019, 0.7030, 0.7012]],\n",
      "\n",
      "        [[0.5000, 0.7070, 0.7040,  ..., 0.7039, 0.6985, 0.6994]],\n",
      "\n",
      "        [[0.5000, 0.6975, 0.7023,  ..., 0.6936, 0.6967, 0.6983]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7034, 0.6999,  ..., 0.6989, 0.7006, 0.6968]],\n",
      "\n",
      "        [[0.5000, 0.6929, 0.6991,  ..., 0.6985, 0.7015, 0.6966]],\n",
      "\n",
      "        [[0.7311, 0.6986, 0.7023,  ..., 0.6988, 0.7007, 0.6976]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4954, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7043, 0.7081,  ..., 0.7048, 0.7019, 0.6993]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.6969,  ..., 0.6974, 0.6990, 0.7008]],\n",
      "\n",
      "        [[0.5000, 0.6992, 0.6964,  ..., 0.6945, 0.6993, 0.7021]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6983, 0.6989,  ..., 0.6992, 0.7003, 0.6976]],\n",
      "\n",
      "        [[0.7311, 0.7043, 0.6993,  ..., 0.7059, 0.6956, 0.6961]],\n",
      "\n",
      "        [[0.5000, 0.6992, 0.7018,  ..., 0.6982, 0.7000, 0.6982]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5604, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6987, 0.6991,  ..., 0.6969, 0.6996, 0.6964]],\n",
      "\n",
      "        [[0.7311, 0.7013, 0.6989,  ..., 0.7077, 0.6992, 0.7001]],\n",
      "\n",
      "        [[0.7311, 0.6995, 0.6986,  ..., 0.7026, 0.6969, 0.7030]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6989, 0.6980,  ..., 0.6998, 0.6986, 0.7043]],\n",
      "\n",
      "        [[0.7311, 0.6997, 0.7000,  ..., 0.6974, 0.6995, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.7003, 0.6991,  ..., 0.6926, 0.7027, 0.6994]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4692, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6965, 0.6994,  ..., 0.7005, 0.6954, 0.7027]],\n",
      "\n",
      "        [[0.5000, 0.7044, 0.6991,  ..., 0.6970, 0.6963, 0.6994]],\n",
      "\n",
      "        [[0.5000, 0.7072, 0.7040,  ..., 0.7059, 0.6999, 0.6992]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7003, 0.7023,  ..., 0.7033, 0.6966, 0.6936]],\n",
      "\n",
      "        [[0.7311, 0.6953, 0.6991,  ..., 0.7004, 0.6989, 0.7007]],\n",
      "\n",
      "        [[0.5000, 0.7001, 0.7020,  ..., 0.6996, 0.7021, 0.7009]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4512, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7053, 0.6977,  ..., 0.7054, 0.6993, 0.6918]],\n",
      "\n",
      "        [[0.7311, 0.6952, 0.6996,  ..., 0.6991, 0.7017, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.6999, 0.7039,  ..., 0.7033, 0.6963, 0.6988]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7029, 0.6970,  ..., 0.6949, 0.6986, 0.7068]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.6982,  ..., 0.6994, 0.7001, 0.7023]],\n",
      "\n",
      "        [[0.5000, 0.6995, 0.6988,  ..., 0.7050, 0.6969, 0.6942]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5390, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7042, 0.6980,  ..., 0.6958, 0.7030, 0.7062]],\n",
      "\n",
      "        [[0.7311, 0.6995, 0.6996,  ..., 0.7015, 0.6996, 0.7015]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.6945,  ..., 0.6934, 0.7005, 0.7042]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7003, 0.6989,  ..., 0.7040, 0.7059, 0.7038]],\n",
      "\n",
      "        [[0.7311, 0.7020, 0.6972,  ..., 0.7077, 0.6991, 0.7024]],\n",
      "\n",
      "        [[0.7311, 0.7004, 0.6997,  ..., 0.7007, 0.7036, 0.6952]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4229, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7028, 0.7030,  ..., 0.7065, 0.6988, 0.7023]],\n",
      "\n",
      "        [[0.5000, 0.6985, 0.7033,  ..., 0.6968, 0.7043, 0.7005]],\n",
      "\n",
      "        [[0.5000, 0.7000, 0.6997,  ..., 0.7013, 0.6992, 0.6985]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6994, 0.6950,  ..., 0.6971, 0.7014, 0.7001]],\n",
      "\n",
      "        [[0.7311, 0.7029, 0.7078,  ..., 0.6993, 0.6994, 0.6976]],\n",
      "\n",
      "        [[0.7311, 0.7017, 0.7035,  ..., 0.6973, 0.6971, 0.7047]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4529, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.6942, 0.6988,  ..., 0.6968, 0.7019, 0.6983]],\n",
      "\n",
      "        [[0.7311, 0.6964, 0.7041,  ..., 0.6979, 0.6936, 0.6977]],\n",
      "\n",
      "        [[0.5000, 0.6997, 0.6972,  ..., 0.7037, 0.6995, 0.6994]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7023, 0.7028,  ..., 0.6946, 0.7017, 0.6988]],\n",
      "\n",
      "        [[0.7311, 0.7021, 0.6931,  ..., 0.6977, 0.6948, 0.7049]],\n",
      "\n",
      "        [[0.7311, 0.6949, 0.6997,  ..., 0.7007, 0.7006, 0.7023]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4468, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6997, 0.7039,  ..., 0.6995, 0.7017, 0.6930]],\n",
      "\n",
      "        [[0.5000, 0.7013, 0.7027,  ..., 0.7033, 0.6975, 0.7049]],\n",
      "\n",
      "        [[0.7311, 0.6933, 0.6949,  ..., 0.7026, 0.7005, 0.7083]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6967, 0.7010,  ..., 0.6963, 0.7001, 0.6957]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7032,  ..., 0.7074, 0.7001, 0.6989]],\n",
      "\n",
      "        [[0.7311, 0.7015, 0.7040,  ..., 0.6985, 0.7060, 0.7022]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4872, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7040, 0.6965,  ..., 0.6980, 0.7071, 0.6984]],\n",
      "\n",
      "        [[0.5000, 0.7028, 0.7054,  ..., 0.7007, 0.7010, 0.7056]],\n",
      "\n",
      "        [[0.5000, 0.6944, 0.6985,  ..., 0.6999, 0.6988, 0.7026]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7034, 0.7080,  ..., 0.7021, 0.7009, 0.7046]],\n",
      "\n",
      "        [[0.7311, 0.7002, 0.7026,  ..., 0.7055, 0.6996, 0.6998]],\n",
      "\n",
      "        [[0.7311, 0.7045, 0.7043,  ..., 0.7005, 0.7001, 0.7015]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4519, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7058, 0.7004,  ..., 0.7053, 0.6912, 0.7004]],\n",
      "\n",
      "        [[0.5000, 0.6974, 0.7034,  ..., 0.6964, 0.7007, 0.7047]],\n",
      "\n",
      "        [[0.5000, 0.6994, 0.6975,  ..., 0.7001, 0.6960, 0.6980]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6948, 0.7034,  ..., 0.7034, 0.6967, 0.7006]],\n",
      "\n",
      "        [[0.7311, 0.6992, 0.6983,  ..., 0.7009, 0.6993, 0.6976]],\n",
      "\n",
      "        [[0.7311, 0.7039, 0.7011,  ..., 0.6955, 0.6995, 0.6976]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5039, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7065, 0.7016,  ..., 0.6991, 0.6963, 0.7011]],\n",
      "\n",
      "        [[0.7311, 0.7002, 0.6991,  ..., 0.7042, 0.6980, 0.7047]],\n",
      "\n",
      "        [[0.5000, 0.6967, 0.7018,  ..., 0.6994, 0.6939, 0.6948]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7055, 0.7012,  ..., 0.6985, 0.6924, 0.6971]],\n",
      "\n",
      "        [[0.7311, 0.7058, 0.7017,  ..., 0.6975, 0.6991, 0.6977]],\n",
      "\n",
      "        [[0.7311, 0.7040, 0.7019,  ..., 0.6973, 0.7006, 0.6997]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4670, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7000, 0.7017,  ..., 0.7076, 0.7015, 0.7053]],\n",
      "\n",
      "        [[0.5000, 0.6985, 0.6990,  ..., 0.6970, 0.6990, 0.7006]],\n",
      "\n",
      "        [[0.7311, 0.6985, 0.7000,  ..., 0.7028, 0.7066, 0.7098]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7013, 0.7002,  ..., 0.7018, 0.6964, 0.7034]],\n",
      "\n",
      "        [[0.7311, 0.7086, 0.6976,  ..., 0.7043, 0.6960, 0.7005]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7050,  ..., 0.7006, 0.7031, 0.7008]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4349, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7017, 0.6996,  ..., 0.7051, 0.6978, 0.6973]],\n",
      "\n",
      "        [[0.5000, 0.6982, 0.7047,  ..., 0.7005, 0.7039, 0.7069]],\n",
      "\n",
      "        [[0.7311, 0.7009, 0.7013,  ..., 0.6996, 0.6981, 0.6959]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6983, 0.6992,  ..., 0.6993, 0.7005, 0.7036]],\n",
      "\n",
      "        [[0.7311, 0.7017, 0.7009,  ..., 0.6983, 0.7035, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.6995, 0.6987,  ..., 0.7043, 0.7033, 0.7015]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4590, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7030, 0.7065,  ..., 0.6991, 0.6997, 0.7068]],\n",
      "\n",
      "        [[0.7311, 0.6952, 0.7019,  ..., 0.7047, 0.7053, 0.6997]],\n",
      "\n",
      "        [[0.7311, 0.6950, 0.7054,  ..., 0.7018, 0.6996, 0.7014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6947, 0.7041,  ..., 0.6998, 0.7031, 0.6977]],\n",
      "\n",
      "        [[0.7311, 0.7020, 0.6934,  ..., 0.6983, 0.7033, 0.7033]],\n",
      "\n",
      "        [[0.7311, 0.7036, 0.7063,  ..., 0.7093, 0.6988, 0.6998]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4528, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7017, 0.6971,  ..., 0.6984, 0.7066, 0.7023]],\n",
      "\n",
      "        [[0.7311, 0.7014, 0.7033,  ..., 0.7007, 0.6995, 0.6936]],\n",
      "\n",
      "        [[0.5000, 0.6929, 0.7007,  ..., 0.7046, 0.7054, 0.7028]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6995, 0.7072,  ..., 0.7013, 0.7046, 0.6991]],\n",
      "\n",
      "        [[0.7311, 0.7033, 0.7047,  ..., 0.7012, 0.7035, 0.7001]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.7036,  ..., 0.7045, 0.7013, 0.6985]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4301, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7103, 0.7021,  ..., 0.7012, 0.7003, 0.6987]],\n",
      "\n",
      "        [[0.7311, 0.7012, 0.6960,  ..., 0.7005, 0.7007, 0.6985]],\n",
      "\n",
      "        [[0.5000, 0.7025, 0.6983,  ..., 0.7045, 0.7018, 0.6960]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6993, 0.6959,  ..., 0.6977, 0.6983, 0.6996]],\n",
      "\n",
      "        [[0.5000, 0.7008, 0.7063,  ..., 0.6992, 0.7014, 0.6999]],\n",
      "\n",
      "        [[0.7311, 0.6989, 0.6972,  ..., 0.7071, 0.7023, 0.7018]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4956, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6972, 0.7061,  ..., 0.6932, 0.6999, 0.6985]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6995,  ..., 0.6977, 0.6983, 0.6928]],\n",
      "\n",
      "        [[0.7311, 0.7035, 0.7036,  ..., 0.7051, 0.7038, 0.7040]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7009, 0.7011,  ..., 0.6983, 0.7007, 0.7004]],\n",
      "\n",
      "        [[0.7311, 0.6980, 0.7033,  ..., 0.7016, 0.7009, 0.7064]],\n",
      "\n",
      "        [[0.7311, 0.7005, 0.6949,  ..., 0.7022, 0.6977, 0.7027]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5062, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7082, 0.6974,  ..., 0.7029, 0.7031, 0.6951]],\n",
      "\n",
      "        [[0.7311, 0.7043, 0.7018,  ..., 0.7003, 0.6989, 0.7038]],\n",
      "\n",
      "        [[0.7311, 0.6975, 0.6987,  ..., 0.7005, 0.7054, 0.7073]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6972, 0.6997,  ..., 0.6963, 0.6964, 0.6934]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.7001,  ..., 0.7048, 0.6958, 0.7027]],\n",
      "\n",
      "        [[0.7311, 0.6994, 0.7022,  ..., 0.7016, 0.6923, 0.6972]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4685, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7043, 0.6965,  ..., 0.7019, 0.6996, 0.6984]],\n",
      "\n",
      "        [[0.7311, 0.6967, 0.6980,  ..., 0.7016, 0.7002, 0.7013]],\n",
      "\n",
      "        [[0.7311, 0.6954, 0.6999,  ..., 0.6992, 0.7013, 0.6923]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7000, 0.6959,  ..., 0.6959, 0.7005, 0.7060]],\n",
      "\n",
      "        [[0.7311, 0.6971, 0.7002,  ..., 0.7024, 0.6993, 0.7020]],\n",
      "\n",
      "        [[0.7311, 0.7069, 0.7014,  ..., 0.7030, 0.6972, 0.7003]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.3999, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7015, 0.6969,  ..., 0.6967, 0.7062, 0.6957]],\n",
      "\n",
      "        [[0.7311, 0.6986, 0.6961,  ..., 0.7000, 0.6978, 0.6991]],\n",
      "\n",
      "        [[0.5000, 0.6933, 0.6948,  ..., 0.7005, 0.7037, 0.7006]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6922, 0.6958,  ..., 0.7037, 0.6988, 0.7021]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.6984,  ..., 0.7007, 0.6984, 0.6892]],\n",
      "\n",
      "        [[0.5000, 0.7068, 0.7040,  ..., 0.7028, 0.7007, 0.6967]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4434, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7036, 0.6998,  ..., 0.7031, 0.7026, 0.7035]],\n",
      "\n",
      "        [[0.5000, 0.7010, 0.7007,  ..., 0.7042, 0.7033, 0.6972]],\n",
      "\n",
      "        [[0.5000, 0.7009, 0.7049,  ..., 0.7022, 0.7009, 0.7016]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6959, 0.7001,  ..., 0.6987, 0.7045, 0.6959]],\n",
      "\n",
      "        [[0.7311, 0.7003, 0.7039,  ..., 0.7003, 0.6996, 0.7002]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.6989,  ..., 0.7021, 0.7003, 0.6930]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4740, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6960, 0.7026,  ..., 0.7023, 0.6956, 0.7016]],\n",
      "\n",
      "        [[0.7311, 0.6974, 0.7045,  ..., 0.7026, 0.6976, 0.7044]],\n",
      "\n",
      "        [[0.5000, 0.6943, 0.7020,  ..., 0.6972, 0.7031, 0.7033]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6973, 0.6948,  ..., 0.6987, 0.6965, 0.6989]],\n",
      "\n",
      "        [[0.5000, 0.6987, 0.6964,  ..., 0.6975, 0.7061, 0.7024]],\n",
      "\n",
      "        [[0.7311, 0.6979, 0.7027,  ..., 0.7007, 0.6984, 0.7007]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5062, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6985, 0.7038,  ..., 0.6998, 0.6985, 0.6993]],\n",
      "\n",
      "        [[0.7311, 0.7043, 0.6965,  ..., 0.6975, 0.7047, 0.7036]],\n",
      "\n",
      "        [[0.5000, 0.6995, 0.7078,  ..., 0.7002, 0.6986, 0.7026]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7010, 0.6939,  ..., 0.6990, 0.7020, 0.7009]],\n",
      "\n",
      "        [[0.7311, 0.6926, 0.6981,  ..., 0.6944, 0.6991, 0.7011]],\n",
      "\n",
      "        [[0.5000, 0.6478, 0.6972,  ..., 0.7044, 0.6951, 0.7003]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4960, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6938, 0.7033,  ..., 0.6965, 0.7062, 0.6992]],\n",
      "\n",
      "        [[0.7311, 0.7013, 0.7050,  ..., 0.6995, 0.7025, 0.6973]],\n",
      "\n",
      "        [[0.5000, 0.6987, 0.7027,  ..., 0.7029, 0.7073, 0.6982]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6982, 0.7013,  ..., 0.7037, 0.7000, 0.6952]],\n",
      "\n",
      "        [[0.7311, 0.7003, 0.6986,  ..., 0.7025, 0.7059, 0.6986]],\n",
      "\n",
      "        [[0.5000, 0.6992, 0.6994,  ..., 0.7043, 0.7051, 0.6991]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4766, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.6976, 0.6981,  ..., 0.7033, 0.7041, 0.7024]],\n",
      "\n",
      "        [[0.7311, 0.6949, 0.6984,  ..., 0.6944, 0.6970, 0.6939]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.7045,  ..., 0.6963, 0.6960, 0.6998]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6976, 0.6992,  ..., 0.7028, 0.7025, 0.7038]],\n",
      "\n",
      "        [[0.5000, 0.7029, 0.7051,  ..., 0.7006, 0.6961, 0.6987]],\n",
      "\n",
      "        [[0.5000, 0.7057, 0.6959,  ..., 0.7023, 0.6983, 0.7008]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5182, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6998, 0.6960,  ..., 0.6989, 0.7024, 0.7026]],\n",
      "\n",
      "        [[0.7311, 0.6962, 0.6996,  ..., 0.7031, 0.7017, 0.6986]],\n",
      "\n",
      "        [[0.5000, 0.6981, 0.7022,  ..., 0.7009, 0.6988, 0.7039]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6990, 0.7069,  ..., 0.6995, 0.7038, 0.6956]],\n",
      "\n",
      "        [[0.7311, 0.6987, 0.7016,  ..., 0.6996, 0.7042, 0.7015]],\n",
      "\n",
      "        [[0.7311, 0.7022, 0.6998,  ..., 0.7053, 0.6965, 0.7033]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4894, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6986, 0.7007,  ..., 0.6985, 0.7029, 0.7009]],\n",
      "\n",
      "        [[0.7311, 0.7046, 0.6983,  ..., 0.7005, 0.6993, 0.6938]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.6971,  ..., 0.7041, 0.7055, 0.7018]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7003, 0.7045,  ..., 0.6921, 0.7007, 0.6993]],\n",
      "\n",
      "        [[0.7311, 0.7037, 0.6962,  ..., 0.7023, 0.6972, 0.7034]],\n",
      "\n",
      "        [[0.5000, 0.7023, 0.6994,  ..., 0.6982, 0.6955, 0.6982]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5127, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7043, 0.7055,  ..., 0.7037, 0.7008, 0.7015]],\n",
      "\n",
      "        [[0.7311, 0.6975, 0.6987,  ..., 0.6978, 0.7046, 0.6965]],\n",
      "\n",
      "        [[0.7311, 0.7029, 0.6967,  ..., 0.6983, 0.7012, 0.6987]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6969, 0.6954,  ..., 0.7020, 0.7032, 0.6977]],\n",
      "\n",
      "        [[0.7311, 0.7041, 0.6990,  ..., 0.6999, 0.7003, 0.6969]],\n",
      "\n",
      "        [[0.7311, 0.7031, 0.6983,  ..., 0.7023, 0.7052, 0.7026]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4806, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7048, 0.6978,  ..., 0.6988, 0.6980, 0.6973]],\n",
      "\n",
      "        [[0.7311, 0.7031, 0.6980,  ..., 0.6995, 0.7012, 0.6987]],\n",
      "\n",
      "        [[0.7311, 0.7043, 0.7013,  ..., 0.7023, 0.7043, 0.6963]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7036, 0.7032,  ..., 0.6967, 0.7008, 0.7008]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7039,  ..., 0.6992, 0.7004, 0.7020]],\n",
      "\n",
      "        [[0.7311, 0.6978, 0.6973,  ..., 0.6988, 0.6982, 0.7009]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4759, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7008, 0.6984,  ..., 0.7004, 0.6979, 0.7003]],\n",
      "\n",
      "        [[0.7311, 0.7070, 0.7013,  ..., 0.6995, 0.7008, 0.7034]],\n",
      "\n",
      "        [[0.7311, 0.7062, 0.6979,  ..., 0.6968, 0.6970, 0.6950]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6952, 0.6894,  ..., 0.6997, 0.6992, 0.7006]],\n",
      "\n",
      "        [[0.7311, 0.7031, 0.7068,  ..., 0.6999, 0.6978, 0.6971]],\n",
      "\n",
      "        [[0.5000, 0.7003, 0.6994,  ..., 0.7002, 0.7000, 0.6998]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4613, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7025, 0.7008,  ..., 0.7003, 0.7013, 0.6972]],\n",
      "\n",
      "        [[0.7311, 0.6979, 0.6949,  ..., 0.7012, 0.6975, 0.7019]],\n",
      "\n",
      "        [[0.7311, 0.7006, 0.7011,  ..., 0.6920, 0.6944, 0.7006]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7032, 0.6991,  ..., 0.7010, 0.6974, 0.6993]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.7053,  ..., 0.6967, 0.6970, 0.7001]],\n",
      "\n",
      "        [[0.7311, 0.7020, 0.7009,  ..., 0.7015, 0.6984, 0.6963]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4895, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6941, 0.7036,  ..., 0.7008, 0.6995, 0.6971]],\n",
      "\n",
      "        [[0.5000, 0.7003, 0.7004,  ..., 0.7008, 0.7022, 0.6945]],\n",
      "\n",
      "        [[0.7311, 0.7029, 0.7057,  ..., 0.7042, 0.7007, 0.7058]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7062, 0.6981,  ..., 0.6985, 0.7022, 0.7017]],\n",
      "\n",
      "        [[0.5000, 0.7052, 0.6987,  ..., 0.7018, 0.6966, 0.7039]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.6985,  ..., 0.7045, 0.7042, 0.7035]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5246, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7051, 0.7015,  ..., 0.6985, 0.7033, 0.6989]],\n",
      "\n",
      "        [[0.7311, 0.6943, 0.6985,  ..., 0.7003, 0.6974, 0.6969]],\n",
      "\n",
      "        [[0.5000, 0.7023, 0.7016,  ..., 0.6987, 0.7005, 0.6998]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6968, 0.7014,  ..., 0.7010, 0.7048, 0.6980]],\n",
      "\n",
      "        [[0.5000, 0.7021, 0.6998,  ..., 0.6990, 0.7019, 0.7032]],\n",
      "\n",
      "        [[0.7311, 0.7045, 0.6995,  ..., 0.6980, 0.7035, 0.7004]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5026, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6964, 0.7014,  ..., 0.6928, 0.6971, 0.7048]],\n",
      "\n",
      "        [[0.7311, 0.6997, 0.7017,  ..., 0.7012, 0.7022, 0.7011]],\n",
      "\n",
      "        [[0.5000, 0.6968, 0.7012,  ..., 0.7043, 0.7008, 0.6996]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7038,  ..., 0.7026, 0.6995, 0.6994]],\n",
      "\n",
      "        [[0.7311, 0.6994, 0.7009,  ..., 0.6954, 0.6953, 0.6949]],\n",
      "\n",
      "        [[0.7311, 0.6994, 0.7004,  ..., 0.7001, 0.6950, 0.7028]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5341, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6960, 0.6996,  ..., 0.7052, 0.7017, 0.7042]],\n",
      "\n",
      "        [[0.7311, 0.7016, 0.7001,  ..., 0.7065, 0.6986, 0.7026]],\n",
      "\n",
      "        [[0.7311, 0.6947, 0.6992,  ..., 0.7023, 0.7052, 0.7009]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7036, 0.7016,  ..., 0.6997, 0.7004, 0.7027]],\n",
      "\n",
      "        [[0.5000, 0.7012, 0.7039,  ..., 0.6994, 0.7043, 0.7069]],\n",
      "\n",
      "        [[0.5000, 0.7020, 0.7035,  ..., 0.6984, 0.7046, 0.7081]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4302, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6980, 0.7010,  ..., 0.6969, 0.7023, 0.7000]],\n",
      "\n",
      "        [[0.7311, 0.7035, 0.7015,  ..., 0.6978, 0.6976, 0.7008]],\n",
      "\n",
      "        [[0.7311, 0.7018, 0.6970,  ..., 0.6979, 0.7057, 0.6998]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7016, 0.6995,  ..., 0.6969, 0.7006, 0.7037]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.6969,  ..., 0.7012, 0.7012, 0.7026]],\n",
      "\n",
      "        [[0.5000, 0.6989, 0.7002,  ..., 0.7009, 0.7046, 0.6997]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4780, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6939, 0.7030,  ..., 0.7020, 0.6934, 0.6955]],\n",
      "\n",
      "        [[0.7311, 0.6990, 0.7049,  ..., 0.6941, 0.6981, 0.7028]],\n",
      "\n",
      "        [[0.5000, 0.7017, 0.6964,  ..., 0.7024, 0.7073, 0.7013]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7004, 0.6962,  ..., 0.7010, 0.7009, 0.7033]],\n",
      "\n",
      "        [[0.5000, 0.6982, 0.6937,  ..., 0.6985, 0.7001, 0.6967]],\n",
      "\n",
      "        [[0.5000, 0.6942, 0.7021,  ..., 0.6992, 0.6981, 0.6987]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5502, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6998, 0.6999,  ..., 0.7020, 0.6973, 0.6991]],\n",
      "\n",
      "        [[0.7311, 0.6938, 0.6928,  ..., 0.7034, 0.6992, 0.6962]],\n",
      "\n",
      "        [[0.7311, 0.7031, 0.7067,  ..., 0.6928, 0.6997, 0.7017]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7034,  ..., 0.7005, 0.7020, 0.6974]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.7013,  ..., 0.7014, 0.7051, 0.6935]],\n",
      "\n",
      "        [[0.7311, 0.6999, 0.6959,  ..., 0.7040, 0.6940, 0.6960]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4919, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6999, 0.7018,  ..., 0.7009, 0.7051, 0.7004]],\n",
      "\n",
      "        [[0.5000, 0.7022, 0.7054,  ..., 0.7031, 0.6991, 0.6982]],\n",
      "\n",
      "        [[0.5000, 0.6991, 0.7018,  ..., 0.7035, 0.7009, 0.6962]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6979, 0.7075,  ..., 0.7026, 0.6982, 0.7054]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6996,  ..., 0.6984, 0.7012, 0.7029]],\n",
      "\n",
      "        [[0.7311, 0.6970, 0.7040,  ..., 0.6961, 0.6981, 0.6968]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5510, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6989, 0.6983,  ..., 0.7025, 0.7006, 0.6966]],\n",
      "\n",
      "        [[0.5000, 0.6970, 0.6957,  ..., 0.7002, 0.6999, 0.6994]],\n",
      "\n",
      "        [[0.5000, 0.7032, 0.7020,  ..., 0.7022, 0.6953, 0.7014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6991, 0.7032,  ..., 0.6977, 0.6974, 0.7045]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.6984,  ..., 0.6998, 0.7013, 0.6977]],\n",
      "\n",
      "        [[0.7311, 0.6989, 0.6970,  ..., 0.6974, 0.6986, 0.7087]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4985, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7012, 0.6999,  ..., 0.7033, 0.6950, 0.6984]],\n",
      "\n",
      "        [[0.7311, 0.7029, 0.7006,  ..., 0.7055, 0.7016, 0.6916]],\n",
      "\n",
      "        [[0.5000, 0.6975, 0.7012,  ..., 0.7016, 0.7021, 0.7030]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7025, 0.7056,  ..., 0.6983, 0.6967, 0.7015]],\n",
      "\n",
      "        [[0.7311, 0.7035, 0.7010,  ..., 0.6990, 0.6970, 0.7011]],\n",
      "\n",
      "        [[0.7311, 0.7038, 0.6999,  ..., 0.6959, 0.6985, 0.7015]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4513, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7013, 0.7010,  ..., 0.6956, 0.6980, 0.7044]],\n",
      "\n",
      "        [[0.7311, 0.7036, 0.7013,  ..., 0.7070, 0.6997, 0.7020]],\n",
      "\n",
      "        [[0.5000, 0.7029, 0.6995,  ..., 0.6957, 0.7070, 0.7017]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6963, 0.7009,  ..., 0.7023, 0.7064, 0.6950]],\n",
      "\n",
      "        [[0.5000, 0.7022, 0.6984,  ..., 0.7024, 0.6932, 0.6964]],\n",
      "\n",
      "        [[0.7311, 0.7057, 0.7062,  ..., 0.7055, 0.7033, 0.7016]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5234, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.7098, 0.7002,  ..., 0.7039, 0.7040, 0.7009]],\n",
      "\n",
      "        [[0.5000, 0.7033, 0.7006,  ..., 0.6979, 0.6992, 0.7038]],\n",
      "\n",
      "        [[0.7311, 0.6972, 0.6969,  ..., 0.6922, 0.6955, 0.7014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6950, 0.6967,  ..., 0.7041, 0.6970, 0.6998]],\n",
      "\n",
      "        [[0.5000, 0.6955, 0.6995,  ..., 0.7021, 0.7033, 0.6988]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.7042,  ..., 0.7011, 0.7030, 0.6981]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4420, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6994, 0.7017,  ..., 0.7020, 0.7015, 0.6986]],\n",
      "\n",
      "        [[0.7311, 0.7006, 0.6921,  ..., 0.6982, 0.7042, 0.7025]],\n",
      "\n",
      "        [[0.7311, 0.6962, 0.6995,  ..., 0.7034, 0.7064, 0.7046]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7008, 0.6978,  ..., 0.7000, 0.7037, 0.6962]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.7026,  ..., 0.7003, 0.6991, 0.6983]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.6945,  ..., 0.6942, 0.7025, 0.6991]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5158, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7087, 0.6972,  ..., 0.7040, 0.6999, 0.7016]],\n",
      "\n",
      "        [[0.5000, 0.6951, 0.7065,  ..., 0.7037, 0.6973, 0.6955]],\n",
      "\n",
      "        [[0.5000, 0.7004, 0.6980,  ..., 0.6996, 0.6969, 0.7027]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7057, 0.6967,  ..., 0.6964, 0.6968, 0.7004]],\n",
      "\n",
      "        [[0.5000, 0.6986, 0.7049,  ..., 0.7021, 0.6981, 0.6957]],\n",
      "\n",
      "        [[0.5000, 0.7054, 0.7007,  ..., 0.6989, 0.6962, 0.6937]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5117, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7050, 0.6985,  ..., 0.6990, 0.7010, 0.7035]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.7006,  ..., 0.6940, 0.6976, 0.6968]],\n",
      "\n",
      "        [[0.7311, 0.7012, 0.6989,  ..., 0.6985, 0.6950, 0.7013]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6996, 0.6982,  ..., 0.7016, 0.7014, 0.6945]],\n",
      "\n",
      "        [[0.5000, 0.7020, 0.6963,  ..., 0.7027, 0.7019, 0.6951]],\n",
      "\n",
      "        [[0.7311, 0.7033, 0.7007,  ..., 0.6987, 0.7060, 0.6983]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4835, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6985, 0.7032,  ..., 0.7012, 0.6989, 0.7037]],\n",
      "\n",
      "        [[0.7311, 0.6992, 0.6982,  ..., 0.6940, 0.7018, 0.7048]],\n",
      "\n",
      "        [[0.7311, 0.7033, 0.7040,  ..., 0.6971, 0.7042, 0.7006]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6941, 0.7020,  ..., 0.7017, 0.6922, 0.7006]],\n",
      "\n",
      "        [[0.7311, 0.6941, 0.6953,  ..., 0.6976, 0.7021, 0.6975]],\n",
      "\n",
      "        [[0.5000, 0.7031, 0.7007,  ..., 0.6969, 0.7019, 0.7042]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4899, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7000, 0.7040,  ..., 0.6958, 0.7040, 0.7037]],\n",
      "\n",
      "        [[0.5000, 0.7037, 0.6969,  ..., 0.7008, 0.7002, 0.6983]],\n",
      "\n",
      "        [[0.5000, 0.6979, 0.7067,  ..., 0.6979, 0.7069, 0.6929]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7025, 0.6984,  ..., 0.7049, 0.6974, 0.6950]],\n",
      "\n",
      "        [[0.7311, 0.6994, 0.7022,  ..., 0.6964, 0.6986, 0.6972]],\n",
      "\n",
      "        [[0.7311, 0.7029, 0.7011,  ..., 0.6960, 0.7005, 0.7012]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4529, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6989, 0.7076,  ..., 0.7076, 0.6985, 0.7021]],\n",
      "\n",
      "        [[0.7311, 0.7027, 0.6956,  ..., 0.7053, 0.6956, 0.7039]],\n",
      "\n",
      "        [[0.7311, 0.7012, 0.6978,  ..., 0.6992, 0.7013, 0.6964]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6938, 0.7001,  ..., 0.7031, 0.6986, 0.7011]],\n",
      "\n",
      "        [[0.5000, 0.7010, 0.6944,  ..., 0.7070, 0.7000, 0.6978]],\n",
      "\n",
      "        [[0.5000, 0.7000, 0.7043,  ..., 0.7042, 0.7009, 0.7060]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4976, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6979, 0.7049,  ..., 0.7024, 0.7005, 0.6993]],\n",
      "\n",
      "        [[0.5000, 0.7005, 0.7036,  ..., 0.6986, 0.7031, 0.7001]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.6991,  ..., 0.6983, 0.7003, 0.6980]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7059, 0.7026,  ..., 0.6998, 0.7039, 0.7006]],\n",
      "\n",
      "        [[0.5000, 0.7055, 0.6985,  ..., 0.6977, 0.7038, 0.7052]],\n",
      "\n",
      "        [[0.5000, 0.7024, 0.6998,  ..., 0.6936, 0.6994, 0.6942]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4868, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7035, 0.6975,  ..., 0.7007, 0.7028, 0.6977]],\n",
      "\n",
      "        [[0.7311, 0.7036, 0.6930,  ..., 0.6974, 0.6993, 0.6963]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.7032,  ..., 0.7023, 0.6975, 0.6987]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6974, 0.7061,  ..., 0.7026, 0.6995, 0.7027]],\n",
      "\n",
      "        [[0.7311, 0.6980, 0.6975,  ..., 0.7022, 0.7012, 0.7006]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7031,  ..., 0.6998, 0.6996, 0.6955]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5189, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7040, 0.7041,  ..., 0.6965, 0.6990, 0.6980]],\n",
      "\n",
      "        [[0.5000, 0.6976, 0.6971,  ..., 0.7047, 0.7066, 0.6979]],\n",
      "\n",
      "        [[0.5000, 0.6967, 0.6960,  ..., 0.6968, 0.7078, 0.6991]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7036, 0.6945,  ..., 0.6996, 0.6996, 0.6985]],\n",
      "\n",
      "        [[0.7311, 0.6957, 0.7000,  ..., 0.6981, 0.6977, 0.7080]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6997,  ..., 0.6972, 0.6976, 0.7037]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4659, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6964, 0.6985,  ..., 0.7001, 0.7061, 0.6984]],\n",
      "\n",
      "        [[0.7311, 0.7013, 0.7039,  ..., 0.6972, 0.7003, 0.7006]],\n",
      "\n",
      "        [[0.7311, 0.7037, 0.6971,  ..., 0.6997, 0.6966, 0.6989]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7012, 0.6980,  ..., 0.6957, 0.7026, 0.7021]],\n",
      "\n",
      "        [[0.7311, 0.7080, 0.7017,  ..., 0.6937, 0.7003, 0.6985]],\n",
      "\n",
      "        [[0.7311, 0.6974, 0.6984,  ..., 0.7027, 0.6963, 0.6968]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4910, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7005, 0.7021,  ..., 0.7033, 0.6987, 0.7028]],\n",
      "\n",
      "        [[0.7311, 0.7034, 0.6976,  ..., 0.6914, 0.7061, 0.6964]],\n",
      "\n",
      "        [[0.7311, 0.7019, 0.6956,  ..., 0.6983, 0.6997, 0.7021]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7013, 0.7003,  ..., 0.6992, 0.7019, 0.7019]],\n",
      "\n",
      "        [[0.7311, 0.6990, 0.6987,  ..., 0.6982, 0.6933, 0.6944]],\n",
      "\n",
      "        [[0.5000, 0.7033, 0.6971,  ..., 0.7035, 0.6975, 0.7001]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4126, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6991, 0.7028,  ..., 0.7026, 0.6992, 0.6996]],\n",
      "\n",
      "        [[0.7311, 0.7050, 0.6958,  ..., 0.6981, 0.7038, 0.7077]],\n",
      "\n",
      "        [[0.5000, 0.6983, 0.6996,  ..., 0.7037, 0.6969, 0.7044]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6997, 0.6961,  ..., 0.7011, 0.7005, 0.7043]],\n",
      "\n",
      "        [[0.5000, 0.7008, 0.7002,  ..., 0.7005, 0.7031, 0.7026]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.7058,  ..., 0.7025, 0.7006, 0.6956]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5357, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7066, 0.6994,  ..., 0.7034, 0.7043, 0.6984]],\n",
      "\n",
      "        [[0.5000, 0.7040, 0.6994,  ..., 0.6944, 0.6935, 0.7004]],\n",
      "\n",
      "        [[0.7311, 0.7040, 0.6961,  ..., 0.6967, 0.6962, 0.7020]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7018, 0.6957,  ..., 0.6997, 0.7030, 0.6998]],\n",
      "\n",
      "        [[0.7311, 0.6981, 0.7014,  ..., 0.7004, 0.7000, 0.6971]],\n",
      "\n",
      "        [[0.5000, 0.7010, 0.6968,  ..., 0.7037, 0.6957, 0.7028]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4331, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6999, 0.7020,  ..., 0.7057, 0.6977, 0.7032]],\n",
      "\n",
      "        [[0.7311, 0.6985, 0.7018,  ..., 0.7023, 0.7025, 0.6899]],\n",
      "\n",
      "        [[0.5000, 0.7039, 0.6962,  ..., 0.7000, 0.7002, 0.6961]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6946, 0.7020,  ..., 0.7015, 0.7033, 0.6973]],\n",
      "\n",
      "        [[0.7311, 0.7006, 0.7018,  ..., 0.7061, 0.7003, 0.7002]],\n",
      "\n",
      "        [[0.7311, 0.6975, 0.7055,  ..., 0.7004, 0.6934, 0.7030]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4554, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6970, 0.6987,  ..., 0.6990, 0.6983, 0.6994]],\n",
      "\n",
      "        [[0.7311, 0.7059, 0.6989,  ..., 0.6970, 0.6965, 0.6980]],\n",
      "\n",
      "        [[0.5000, 0.6975, 0.7019,  ..., 0.6972, 0.7051, 0.6989]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6995, 0.6991,  ..., 0.6965, 0.7003, 0.7046]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.6980,  ..., 0.6972, 0.7007, 0.7031]],\n",
      "\n",
      "        [[0.7311, 0.6964, 0.7050,  ..., 0.7013, 0.6968, 0.6990]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4203, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7016, 0.7014,  ..., 0.7049, 0.7033, 0.6983]],\n",
      "\n",
      "        [[0.5000, 0.6977, 0.6988,  ..., 0.6996, 0.6996, 0.7007]],\n",
      "\n",
      "        [[0.5000, 0.7036, 0.7022,  ..., 0.6965, 0.6986, 0.7105]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6967, 0.7027,  ..., 0.6978, 0.6977, 0.6953]],\n",
      "\n",
      "        [[0.7311, 0.6994, 0.7005,  ..., 0.6997, 0.7073, 0.6983]],\n",
      "\n",
      "        [[0.5000, 0.7032, 0.7049,  ..., 0.6998, 0.7055, 0.6963]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5070, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7000, 0.6941,  ..., 0.6972, 0.7025, 0.7029]],\n",
      "\n",
      "        [[0.7311, 0.6971, 0.6956,  ..., 0.7056, 0.6975, 0.6999]],\n",
      "\n",
      "        [[0.7311, 0.7075, 0.7044,  ..., 0.6983, 0.7025, 0.7008]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7000, 0.7003,  ..., 0.7010, 0.7028, 0.7019]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.6998,  ..., 0.6987, 0.6969, 0.6973]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.7021,  ..., 0.6987, 0.6970, 0.7020]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4496, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.7000, 0.7012,  ..., 0.6993, 0.6991, 0.6965]],\n",
      "\n",
      "        [[0.7311, 0.7013, 0.6982,  ..., 0.6960, 0.7000, 0.6949]],\n",
      "\n",
      "        [[0.7311, 0.6979, 0.7039,  ..., 0.6958, 0.6913, 0.7049]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7007, 0.7021,  ..., 0.7030, 0.7014, 0.7053]],\n",
      "\n",
      "        [[0.5000, 0.7012, 0.6953,  ..., 0.6948, 0.7010, 0.7037]],\n",
      "\n",
      "        [[0.7311, 0.6980, 0.6979,  ..., 0.6984, 0.6917, 0.6990]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5131, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6990, 0.6969,  ..., 0.6934, 0.6981, 0.7035]],\n",
      "\n",
      "        [[0.7311, 0.7018, 0.6983,  ..., 0.7026, 0.6992, 0.6976]],\n",
      "\n",
      "        [[0.5000, 0.6945, 0.7061,  ..., 0.6992, 0.7006, 0.6957]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6982, 0.7013,  ..., 0.6975, 0.7022, 0.6988]],\n",
      "\n",
      "        [[0.5000, 0.7012, 0.6935,  ..., 0.6995, 0.7017, 0.7005]],\n",
      "\n",
      "        [[0.5000, 0.6962, 0.7034,  ..., 0.7020, 0.6971, 0.6993]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4380, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7012, 0.6967,  ..., 0.6977, 0.6989, 0.6997]],\n",
      "\n",
      "        [[0.7311, 0.6975, 0.6933,  ..., 0.7020, 0.6967, 0.6995]],\n",
      "\n",
      "        [[0.7311, 0.7021, 0.6950,  ..., 0.6946, 0.7003, 0.6997]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7021, 0.6946,  ..., 0.7018, 0.7029, 0.6967]],\n",
      "\n",
      "        [[0.7311, 0.6978, 0.6989,  ..., 0.7013, 0.6976, 0.7046]],\n",
      "\n",
      "        [[0.7311, 0.7012, 0.6994,  ..., 0.6972, 0.6997, 0.6990]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4726, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7002, 0.6948,  ..., 0.7053, 0.7062, 0.6967]],\n",
      "\n",
      "        [[0.7311, 0.7006, 0.6958,  ..., 0.6997, 0.6973, 0.6985]],\n",
      "\n",
      "        [[0.5000, 0.7053, 0.6985,  ..., 0.6879, 0.6993, 0.7007]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7044, 0.7004,  ..., 0.6996, 0.7005, 0.7005]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.6987,  ..., 0.7044, 0.7045, 0.7042]],\n",
      "\n",
      "        [[0.5000, 0.6977, 0.6981,  ..., 0.7033, 0.6982, 0.6997]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5063, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7003, 0.6967,  ..., 0.7007, 0.6965, 0.6968]],\n",
      "\n",
      "        [[0.7311, 0.6994, 0.7034,  ..., 0.6984, 0.6951, 0.6961]],\n",
      "\n",
      "        [[0.7311, 0.7052, 0.7067,  ..., 0.7018, 0.7001, 0.6964]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7028, 0.6998,  ..., 0.7021, 0.7025, 0.6972]],\n",
      "\n",
      "        [[0.7311, 0.6974, 0.6968,  ..., 0.7010, 0.6993, 0.6988]],\n",
      "\n",
      "        [[0.7311, 0.7004, 0.7027,  ..., 0.7039, 0.7060, 0.6970]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5067, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7010, 0.6985,  ..., 0.7026, 0.6984, 0.6994]],\n",
      "\n",
      "        [[0.7311, 0.7123, 0.7048,  ..., 0.6967, 0.6947, 0.6983]],\n",
      "\n",
      "        [[0.7311, 0.7067, 0.6997,  ..., 0.7030, 0.6998, 0.7007]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7026, 0.6965,  ..., 0.6992, 0.7056, 0.6981]],\n",
      "\n",
      "        [[0.7311, 0.6978, 0.7043,  ..., 0.7051, 0.6964, 0.7035]],\n",
      "\n",
      "        [[0.5000, 0.6985, 0.7046,  ..., 0.7008, 0.6979, 0.6988]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4552, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7015, 0.6994,  ..., 0.6978, 0.7023, 0.7037]],\n",
      "\n",
      "        [[0.5000, 0.6984, 0.6982,  ..., 0.6998, 0.7007, 0.6991]],\n",
      "\n",
      "        [[0.7311, 0.7047, 0.6983,  ..., 0.7023, 0.6953, 0.6999]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7013, 0.6974,  ..., 0.7052, 0.6998, 0.7059]],\n",
      "\n",
      "        [[0.7311, 0.7017, 0.7037,  ..., 0.7018, 0.6986, 0.6990]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7025,  ..., 0.7046, 0.6989, 0.7029]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4566, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6943, 0.7031,  ..., 0.7036, 0.6987, 0.6961]],\n",
      "\n",
      "        [[0.7311, 0.6952, 0.7010,  ..., 0.6991, 0.7062, 0.7049]],\n",
      "\n",
      "        [[0.7311, 0.7045, 0.7050,  ..., 0.6972, 0.6960, 0.7023]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6957, 0.7010,  ..., 0.7019, 0.7037, 0.7018]],\n",
      "\n",
      "        [[0.7311, 0.6961, 0.7039,  ..., 0.7040, 0.6990, 0.7003]],\n",
      "\n",
      "        [[0.7311, 0.6997, 0.6994,  ..., 0.6954, 0.7049, 0.7014]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4526, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7000, 0.7023,  ..., 0.7029, 0.7049, 0.7000]],\n",
      "\n",
      "        [[0.7311, 0.7048, 0.7050,  ..., 0.7017, 0.7014, 0.7058]],\n",
      "\n",
      "        [[0.7311, 0.6974, 0.6994,  ..., 0.6994, 0.6961, 0.6987]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7017, 0.6995,  ..., 0.6932, 0.7029, 0.6971]],\n",
      "\n",
      "        [[0.7311, 0.7002, 0.6995,  ..., 0.7005, 0.6963, 0.6999]],\n",
      "\n",
      "        [[0.7311, 0.6960, 0.6953,  ..., 0.6980, 0.7030, 0.7005]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4909, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6972, 0.7012,  ..., 0.7008, 0.6955, 0.6983]],\n",
      "\n",
      "        [[0.7311, 0.7010, 0.6945,  ..., 0.6973, 0.6975, 0.6953]],\n",
      "\n",
      "        [[0.7311, 0.7030, 0.7037,  ..., 0.7036, 0.6989, 0.6979]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7041, 0.7001,  ..., 0.6982, 0.7019, 0.6967]],\n",
      "\n",
      "        [[0.5000, 0.6973, 0.7015,  ..., 0.6957, 0.6989, 0.7025]],\n",
      "\n",
      "        [[0.7311, 0.7004, 0.7009,  ..., 0.7028, 0.7037, 0.7022]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4557, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6983, 0.7038,  ..., 0.7002, 0.6960, 0.7094]],\n",
      "\n",
      "        [[0.5000, 0.7051, 0.7037,  ..., 0.6998, 0.7022, 0.7005]],\n",
      "\n",
      "        [[0.5000, 0.6920, 0.6925,  ..., 0.6993, 0.6968, 0.7023]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7088, 0.6985,  ..., 0.7070, 0.7020, 0.6954]],\n",
      "\n",
      "        [[0.7311, 0.6983, 0.7018,  ..., 0.7004, 0.7014, 0.6980]],\n",
      "\n",
      "        [[0.5000, 0.6962, 0.7068,  ..., 0.6924, 0.7036, 0.7017]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4700, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6982, 0.7040,  ..., 0.6987, 0.6990, 0.6929]],\n",
      "\n",
      "        [[0.7311, 0.7016, 0.6980,  ..., 0.7002, 0.6978, 0.7010]],\n",
      "\n",
      "        [[0.5000, 0.6967, 0.6999,  ..., 0.6967, 0.7002, 0.7050]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7031, 0.6981,  ..., 0.7034, 0.6984, 0.7020]],\n",
      "\n",
      "        [[0.7311, 0.7014, 0.6996,  ..., 0.6968, 0.6956, 0.6981]],\n",
      "\n",
      "        [[0.7311, 0.7010, 0.7002,  ..., 0.6977, 0.6980, 0.7031]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5452, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7045, 0.7020,  ..., 0.7038, 0.7017, 0.6967]],\n",
      "\n",
      "        [[0.7311, 0.6999, 0.7049,  ..., 0.7022, 0.6967, 0.7015]],\n",
      "\n",
      "        [[0.5000, 0.6996, 0.6973,  ..., 0.6964, 0.6975, 0.6996]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6993, 0.7020,  ..., 0.6994, 0.7003, 0.6992]],\n",
      "\n",
      "        [[0.7311, 0.6966, 0.7003,  ..., 0.7047, 0.6980, 0.6965]],\n",
      "\n",
      "        [[0.5000, 0.7063, 0.7023,  ..., 0.6989, 0.6998, 0.7087]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5364, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7005, 0.7022,  ..., 0.7011, 0.6997, 0.6988]],\n",
      "\n",
      "        [[0.7311, 0.7035, 0.6953,  ..., 0.7003, 0.6996, 0.6992]],\n",
      "\n",
      "        [[0.5000, 0.6978, 0.6968,  ..., 0.6970, 0.6952, 0.7052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7027, 0.7016,  ..., 0.6995, 0.6975, 0.6982]],\n",
      "\n",
      "        [[0.7311, 0.7080, 0.6968,  ..., 0.6979, 0.6988, 0.7023]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.6999,  ..., 0.6950, 0.6965, 0.7013]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4172, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6967, 0.6955,  ..., 0.6964, 0.6960, 0.6986]],\n",
      "\n",
      "        [[0.5000, 0.6983, 0.6990,  ..., 0.7016, 0.6965, 0.6935]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.7017,  ..., 0.7002, 0.7058, 0.6988]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6958, 0.7011,  ..., 0.6952, 0.7042, 0.6983]],\n",
      "\n",
      "        [[0.5000, 0.7084, 0.6988,  ..., 0.7028, 0.6995, 0.6983]],\n",
      "\n",
      "        [[0.7311, 0.7002, 0.6971,  ..., 0.6997, 0.7008, 0.6994]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5623, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7009, 0.6992,  ..., 0.7008, 0.6958, 0.7054]],\n",
      "\n",
      "        [[0.5000, 0.6933, 0.7034,  ..., 0.7044, 0.7007, 0.6987]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.7018,  ..., 0.7067, 0.6956, 0.7027]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6969, 0.7036,  ..., 0.6996, 0.6976, 0.7021]],\n",
      "\n",
      "        [[0.5000, 0.6993, 0.6986,  ..., 0.6976, 0.6992, 0.6946]],\n",
      "\n",
      "        [[0.7311, 0.7010, 0.7026,  ..., 0.7070, 0.6989, 0.7008]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4990, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6970, 0.7019,  ..., 0.6999, 0.6995, 0.6995]],\n",
      "\n",
      "        [[0.5000, 0.6992, 0.7052,  ..., 0.7032, 0.6945, 0.6976]],\n",
      "\n",
      "        [[0.5000, 0.7004, 0.7030,  ..., 0.7038, 0.6981, 0.7028]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7019, 0.7019,  ..., 0.6940, 0.6984, 0.6951]],\n",
      "\n",
      "        [[0.7311, 0.7018, 0.7016,  ..., 0.7023, 0.7005, 0.7034]],\n",
      "\n",
      "        [[0.7311, 0.7025, 0.7055,  ..., 0.7024, 0.6915, 0.6963]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4124, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7005, 0.6995,  ..., 0.7012, 0.6962, 0.7001]],\n",
      "\n",
      "        [[0.7311, 0.7004, 0.6979,  ..., 0.6975, 0.6942, 0.6990]],\n",
      "\n",
      "        [[0.7311, 0.6992, 0.6999,  ..., 0.6995, 0.7023, 0.6958]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7019, 0.6974,  ..., 0.7027, 0.6963, 0.7023]],\n",
      "\n",
      "        [[0.7311, 0.6972, 0.6958,  ..., 0.7000, 0.6967, 0.6981]],\n",
      "\n",
      "        [[0.5000, 0.6996, 0.7004,  ..., 0.7022, 0.6977, 0.6971]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4366, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.5000, 0.6988, 0.6976,  ..., 0.6994, 0.7026, 0.7026]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.6983,  ..., 0.6993, 0.7040, 0.7012]],\n",
      "\n",
      "        [[0.7311, 0.6998, 0.7015,  ..., 0.6950, 0.7030, 0.6997]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6927, 0.7010,  ..., 0.7019, 0.7014, 0.6948]],\n",
      "\n",
      "        [[0.5000, 0.7004, 0.7056,  ..., 0.7030, 0.7020, 0.6973]],\n",
      "\n",
      "        [[0.5000, 0.7019, 0.6993,  ..., 0.6989, 0.6986, 0.6985]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4693, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6994, 0.6968,  ..., 0.6961, 0.6986, 0.7031]],\n",
      "\n",
      "        [[0.7311, 0.7013, 0.7003,  ..., 0.6986, 0.7001, 0.7038]],\n",
      "\n",
      "        [[0.5000, 0.6980, 0.7027,  ..., 0.6950, 0.7041, 0.6981]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7020, 0.7001,  ..., 0.7013, 0.7023, 0.7041]],\n",
      "\n",
      "        [[0.5000, 0.6988, 0.7036,  ..., 0.6961, 0.7000, 0.7023]],\n",
      "\n",
      "        [[0.5000, 0.7008, 0.6989,  ..., 0.7022, 0.6992, 0.7054]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4855, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7020, 0.6988,  ..., 0.7031, 0.7046, 0.7019]],\n",
      "\n",
      "        [[0.7311, 0.7046, 0.6991,  ..., 0.6973, 0.7023, 0.7034]],\n",
      "\n",
      "        [[0.7311, 0.6985, 0.6987,  ..., 0.7014, 0.6996, 0.6958]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7019, 0.6976,  ..., 0.6950, 0.7013, 0.6980]],\n",
      "\n",
      "        [[0.7311, 0.6919, 0.7070,  ..., 0.7018, 0.7007, 0.6997]],\n",
      "\n",
      "        [[0.7311, 0.6996, 0.7041,  ..., 0.7013, 0.7027, 0.7029]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4829, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6993, 0.7021,  ..., 0.7044, 0.7045, 0.7030]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.7006,  ..., 0.7013, 0.7001, 0.7006]],\n",
      "\n",
      "        [[0.7311, 0.6990, 0.7018,  ..., 0.6949, 0.6954, 0.7030]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7018, 0.7078,  ..., 0.6982, 0.6953, 0.7088]],\n",
      "\n",
      "        [[0.7311, 0.6984, 0.6948,  ..., 0.7002, 0.7008, 0.7028]],\n",
      "\n",
      "        [[0.5000, 0.6994, 0.6987,  ..., 0.7001, 0.6992, 0.7003]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4856, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7050, 0.7020,  ..., 0.6980, 0.6969, 0.6971]],\n",
      "\n",
      "        [[0.7311, 0.7078, 0.6934,  ..., 0.7022, 0.7034, 0.7024]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.7057,  ..., 0.7029, 0.7035, 0.6988]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6884, 0.6958,  ..., 0.6952, 0.6970, 0.7009]],\n",
      "\n",
      "        [[0.5000, 0.7084, 0.7032,  ..., 0.7088, 0.7018, 0.7003]],\n",
      "\n",
      "        [[0.7311, 0.6977, 0.6985,  ..., 0.6982, 0.7022, 0.7004]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4853, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6999, 0.6948,  ..., 0.7009, 0.7032, 0.6970]],\n",
      "\n",
      "        [[0.5000, 0.6994, 0.6963,  ..., 0.7020, 0.6991, 0.7020]],\n",
      "\n",
      "        [[0.7311, 0.6944, 0.7002,  ..., 0.7067, 0.7027, 0.7039]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7027, 0.7048,  ..., 0.7004, 0.7007, 0.7013]],\n",
      "\n",
      "        [[0.7311, 0.7070, 0.7014,  ..., 0.6965, 0.7002, 0.6983]],\n",
      "\n",
      "        [[0.7311, 0.7033, 0.6968,  ..., 0.6989, 0.7027, 0.6991]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4643, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7015, 0.7025,  ..., 0.7053, 0.7036, 0.7005]],\n",
      "\n",
      "        [[0.5000, 0.7008, 0.7006,  ..., 0.7055, 0.7052, 0.7003]],\n",
      "\n",
      "        [[0.7311, 0.6944, 0.7046,  ..., 0.7010, 0.7046, 0.6986]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7057, 0.6972,  ..., 0.7019, 0.7035, 0.7045]],\n",
      "\n",
      "        [[0.7311, 0.7058, 0.7045,  ..., 0.7022, 0.7057, 0.7008]],\n",
      "\n",
      "        [[0.5000, 0.7003, 0.6949,  ..., 0.6974, 0.6964, 0.7088]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4535, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7034, 0.7002,  ..., 0.7029, 0.6989, 0.7010]],\n",
      "\n",
      "        [[0.7311, 0.6986, 0.7006,  ..., 0.6973, 0.6986, 0.7004]],\n",
      "\n",
      "        [[0.7311, 0.6960, 0.6996,  ..., 0.6990, 0.7008, 0.6980]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6996, 0.7025,  ..., 0.7017, 0.6998, 0.7064]],\n",
      "\n",
      "        [[0.7311, 0.6989, 0.7008,  ..., 0.6961, 0.6996, 0.6970]],\n",
      "\n",
      "        [[0.7311, 0.7027, 0.6994,  ..., 0.6969, 0.6946, 0.6950]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4139, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6972, 0.6995,  ..., 0.6959, 0.6985, 0.7065]],\n",
      "\n",
      "        [[0.5000, 0.7052, 0.7012,  ..., 0.7027, 0.6974, 0.6966]],\n",
      "\n",
      "        [[0.7311, 0.7025, 0.7014,  ..., 0.6951, 0.7008, 0.7004]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6970, 0.6986,  ..., 0.7018, 0.7004, 0.7043]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.6943,  ..., 0.6951, 0.7012, 0.7047]],\n",
      "\n",
      "        [[0.7311, 0.7032, 0.6984,  ..., 0.6987, 0.6944, 0.6972]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4789, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6977, 0.6984,  ..., 0.7070, 0.6965, 0.6933]],\n",
      "\n",
      "        [[0.7311, 0.7026, 0.7007,  ..., 0.7002, 0.6998, 0.7019]],\n",
      "\n",
      "        [[0.7311, 0.7035, 0.6964,  ..., 0.7001, 0.7018, 0.7011]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.7005, 0.6990,  ..., 0.6942, 0.7018, 0.6969]],\n",
      "\n",
      "        [[0.5000, 0.6940, 0.6984,  ..., 0.7043, 0.6989, 0.7003]],\n",
      "\n",
      "        [[0.7311, 0.6970, 0.6971,  ..., 0.6999, 0.6997, 0.6999]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5448, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6981, 0.6949,  ..., 0.7046, 0.6994, 0.7008]],\n",
      "\n",
      "        [[0.7311, 0.7048, 0.7008,  ..., 0.6985, 0.6977, 0.6943]],\n",
      "\n",
      "        [[0.7311, 0.6982, 0.7029,  ..., 0.7021, 0.7012, 0.6987]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7046, 0.6956,  ..., 0.7026, 0.6991, 0.6996]],\n",
      "\n",
      "        [[0.7311, 0.7025, 0.6969,  ..., 0.7029, 0.7056, 0.6976]],\n",
      "\n",
      "        [[0.5000, 0.7013, 0.7011,  ..., 0.6993, 0.6975, 0.6995]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4032, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.7005, 0.6986,  ..., 0.7016, 0.7006, 0.6953]],\n",
      "\n",
      "        [[0.7311, 0.7094, 0.7033,  ..., 0.7015, 0.6940, 0.7041]],\n",
      "\n",
      "        [[0.7311, 0.7029, 0.7048,  ..., 0.6999, 0.6969, 0.6986]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6988, 0.6924,  ..., 0.7054, 0.6903, 0.6980]],\n",
      "\n",
      "        [[0.7311, 0.6980, 0.7040,  ..., 0.7026, 0.6982, 0.6997]],\n",
      "\n",
      "        [[0.7311, 0.6977, 0.6984,  ..., 0.6987, 0.7007, 0.7067]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5622, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7094, 0.7010,  ..., 0.6994, 0.6971, 0.6976]],\n",
      "\n",
      "        [[0.7311, 0.6991, 0.7070,  ..., 0.6976, 0.7034, 0.7052]],\n",
      "\n",
      "        [[0.7311, 0.6939, 0.7007,  ..., 0.7003, 0.6973, 0.6992]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7009, 0.7037,  ..., 0.7043, 0.6948, 0.6959]],\n",
      "\n",
      "        [[0.7311, 0.6948, 0.6992,  ..., 0.7032, 0.6967, 0.7029]],\n",
      "\n",
      "        [[0.7311, 0.6966, 0.7012,  ..., 0.6979, 0.7079, 0.6968]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4850, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7032, 0.6969,  ..., 0.7038, 0.7043, 0.7028]],\n",
      "\n",
      "        [[0.5000, 0.6971, 0.7056,  ..., 0.7024, 0.7042, 0.6979]],\n",
      "\n",
      "        [[0.5000, 0.7006, 0.6974,  ..., 0.6957, 0.6956, 0.7052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6973, 0.7032,  ..., 0.6990, 0.6993, 0.7000]],\n",
      "\n",
      "        [[0.7311, 0.6998, 0.6994,  ..., 0.6988, 0.6999, 0.6952]],\n",
      "\n",
      "        [[0.5000, 0.6915, 0.7017,  ..., 0.6974, 0.6976, 0.7000]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4494, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.6966, 0.7016,  ..., 0.6972, 0.6944, 0.7036]],\n",
      "\n",
      "        [[0.7311, 0.7017, 0.6928,  ..., 0.7005, 0.6957, 0.7006]],\n",
      "\n",
      "        [[0.5000, 0.6960, 0.6982,  ..., 0.7020, 0.7037, 0.7065]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6975, 0.7000,  ..., 0.7029, 0.7043, 0.6964]],\n",
      "\n",
      "        [[0.7311, 0.7058, 0.7069,  ..., 0.7059, 0.7009, 0.7036]],\n",
      "\n",
      "        [[0.7311, 0.7031, 0.6970,  ..., 0.6987, 0.7054, 0.7011]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4360, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7029, 0.7000,  ..., 0.6977, 0.6963, 0.6915]],\n",
      "\n",
      "        [[0.7311, 0.6995, 0.7016,  ..., 0.6960, 0.7007, 0.6982]],\n",
      "\n",
      "        [[0.7311, 0.7021, 0.6993,  ..., 0.6997, 0.7025, 0.6989]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.6972, 0.6989,  ..., 0.6989, 0.6991, 0.6978]],\n",
      "\n",
      "        [[0.7311, 0.7006, 0.6999,  ..., 0.7017, 0.6976, 0.7040]],\n",
      "\n",
      "        [[0.5000, 0.7027, 0.7028,  ..., 0.6992, 0.7014, 0.7007]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4104, device='cuda:0')\n",
      "x_pred:  tensor([[[0.7311, 0.7017, 0.6995,  ..., 0.7004, 0.6968, 0.7004]],\n",
      "\n",
      "        [[0.7311, 0.6990, 0.6977,  ..., 0.7039, 0.7021, 0.6965]],\n",
      "\n",
      "        [[0.7311, 0.7073, 0.6989,  ..., 0.6995, 0.7001, 0.6975]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5000, 0.6994, 0.6993,  ..., 0.7049, 0.6946, 0.7054]],\n",
      "\n",
      "        [[0.7311, 0.7068, 0.6978,  ..., 0.7036, 0.6974, 0.6934]],\n",
      "\n",
      "        [[0.7311, 0.6988, 0.7046,  ..., 0.6961, 0.7031, 0.7027]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5038, device='cuda:0')\n",
      "x_pred:  tensor([[[0.5000, 0.6976, 0.7018,  ..., 0.6941, 0.6982, 0.6978]],\n",
      "\n",
      "        [[0.7311, 0.6993, 0.6990,  ..., 0.6973, 0.6969, 0.7002]],\n",
      "\n",
      "        [[0.7311, 0.6974, 0.7013,  ..., 0.7109, 0.7024, 0.7047]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7055, 0.6975,  ..., 0.7007, 0.7026, 0.7010]],\n",
      "\n",
      "        [[0.5000, 0.7021, 0.6995,  ..., 0.7040, 0.6959, 0.6955]],\n",
      "\n",
      "        [[0.7311, 0.7022, 0.6991,  ..., 0.6992, 0.7061, 0.6988]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.5312, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pred:  tensor([[[0.7311, 0.7020, 0.6994,  ..., 0.6989, 0.6986, 0.6998]],\n",
      "\n",
      "        [[0.5000, 0.6999, 0.7018,  ..., 0.7008, 0.7016, 0.6967]],\n",
      "\n",
      "        [[0.7311, 0.6970, 0.6988,  ..., 0.7008, 0.7031, 0.7032]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7311, 0.7063, 0.6972,  ..., 0.6975, 0.6984, 0.6993]],\n",
      "\n",
      "        [[0.7311, 0.7001, 0.7016,  ..., 0.7015, 0.7020, 0.6992]],\n",
      "\n",
      "        [[0.7311, 0.7007, 0.6981,  ..., 0.6989, 0.6985, 0.7010]]],\n",
      "       device='cuda:0')\n",
      "loss:  tensor(0.4900, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "modeltest = NologOU(mean_rev_speed=torch.tensor(1.0496364139222869e-06,device=device), \n",
    "                 mean_rev_level=torch.tensor(0.8482042530182574,device=device), \n",
    "                 vola=torch.sqrt(torch.tensor(7.670892715022106e-10,device=device)), mode='synthetic',device=device)\n",
    "\n",
    "for _, (user_id, time_seq, correct_seq, stats) in enumerate(train_loader):\n",
    "    # user_id [bs]\n",
    "    # time_seq [bs, max_time]\n",
    "    # correct_seq [bs, max_time]\n",
    "    # stats [bs, 1, 1, max_time, 3]\n",
    "    x0 = correct_seq[:, :1]\n",
    "    x_gt = correct_seq[:, 1:]\n",
    "    x_pred, params = modeltest.simulate_path(x0=x0, t=time_seq)\n",
    "    x_pred = torch.sigmoid(x_pred)\n",
    "\n",
    "    bceloss = loss_fn(x_pred[:,0,1:].float(), x_gt.float())\n",
    "    # optimizer.zero_grad()\n",
    "    # bceloss.backward(retain_graph=True)\n",
    "    # optimizer.step()\n",
    "\n",
    "    # for p in model.parameters():\n",
    "    #     p.data.clamp_(0)\n",
    "\n",
    "    print('x_pred: ', x_pred)\n",
    "    print('loss: ', bceloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f85d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7317f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba03a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3f44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "42a7cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NologOU(nn.Module):\n",
    "    def __init__(self, \n",
    "                 mean_rev_speed=None, \n",
    "                 mean_rev_level=None, \n",
    "                 vola=None, \n",
    "                 num_seq=1, \n",
    "                 num_node=1,\n",
    "                 mode='train', \n",
    "                 device='cpu'):\n",
    "        '''\n",
    "        Modified from \n",
    "            https://github.com/jwergieluk/ou_noise/tree/master/ou_noise\n",
    "            https://github.com/felix-clark/ornstein-uhlenbeck/blob/master/ornstein_uhlenbeck.py\n",
    "            https://github.com/369geofreeman/Ornstein_Uhlenbeck_Model/blob/main/research.ipynb\n",
    "        Args:\n",
    "            mean_rev_speed: [bs/1, 1] or scalar\n",
    "            mean_rev_level: [bs/1, 1] or scalar\n",
    "            vola: [bs/1, 1] or scalar\n",
    "            num_seq: when training mode, the num_seq will be automatically the number of batch size; \n",
    "                     when synthetic mode, the num_seq will be the number of sequences to generate\n",
    "            mode: can be 'training' or 'synthetic'\n",
    "            device:  \n",
    "        '''\n",
    "        \n",
    "        super(NologOU, self).__init__()\n",
    "        if mode == 'train': # TODO: for now it only considers parameters to optimize\n",
    "            speed = torch.rand((num_seq, 1), device=device).double()\n",
    "            # speed = torch.tensor(1e-5, device=device).double()\n",
    "            self.mean_rev_speed = nn.Parameter(speed, requires_grad=True)\n",
    "            \n",
    "            level = torch.rand((num_seq, 1), device=device)\n",
    "            self.mean_rev_level = nn.Parameter(level, requires_grad=True)\n",
    "            vola = torch.rand((num_seq, 1), device=device)\n",
    "            self.vola = nn.Parameter(vola, requires_grad=True)\n",
    "\n",
    "            # level = torch.tensor(0.64, device=device)\n",
    "            # self.mean_rev_level = nn.Parameter(level, requires_grad=False)\n",
    "            # vola = torch.tensor(1e-3, device=device).double()\n",
    "            # self.vola = torch.relu(nn.Parameter(vola, requires_grad=False))\n",
    "        elif mode == 'synthetic':\n",
    "            assert mean_rev_speed is not None\n",
    "            self.mean_rev_speed = mean_rev_speed\n",
    "            self.mean_rev_level = mean_rev_level\n",
    "            self.vola = vola\n",
    "        else:\n",
    "            raise Exception('It is not a compatible mode')\n",
    "            \n",
    "        self.num_seq = num_seq\n",
    "        self.device = device\n",
    "        assert self.mean_rev_speed >= 0\n",
    "        assert self.vola >= 0\n",
    "        \n",
    "\n",
    "    def variance(self, t, speed=None, vola=None):\n",
    "        '''\n",
    "        The variances introduced by the parameter vola, time difference and Wiener process (Gaussian noise)\n",
    "        Args:\n",
    "            t: \n",
    "        '''\n",
    "        speed = speed if speed is not None else self.mean_rev_speed\n",
    "        vola = vola if vola is not None else self.vola\n",
    "        return vola * vola * (1.0 - torch.exp(- 2.0 * speed * t)) / (2 * speed + 1e-6)\n",
    "\n",
    "    def std(self, t, speed=None, vola=None):\n",
    "        '''\n",
    "        Args:\n",
    "            t: [num_seq/bs, num_node, times] usually is the time difference of a sequence\n",
    "        '''\n",
    "        return torch.sqrt(self.variance(t, speed, vola))\n",
    "\n",
    "    def mean(self, x0, t, speed=None, level=None):\n",
    "        '''\n",
    "        Args:\n",
    "            x0: \n",
    "            t: \n",
    "        '''\n",
    "        speed = speed if speed is not None else self.mean_rev_speed\n",
    "        level = level if level is not None else self.mean_rev_level\n",
    "        return x0 * torch.exp(-speed * t) + (1.0 - torch.exp(- speed * t)) * level\n",
    "\n",
    "    def logll(self, x, t, speed=None, level=None, vola=None):\n",
    "        \"\"\"\n",
    "        Calculates log likelihood of a path\n",
    "        Args:\n",
    "            t: [num_seq/bs, time_step]\n",
    "            x: [num_seq/bs, time_step] it should be the same size as t\n",
    "        Return:\n",
    "            log_pdf: [num_seq/bs, 1]\n",
    "        \"\"\"\n",
    "        speed = speed if speed is not None else self.mean_rev_speed\n",
    "        level = level if level is not None else self.mean_rev_level\n",
    "        vola = vola if vola is not None else self.vola\n",
    "        \n",
    "        dt = torch.diff(t)\n",
    "        dt = torch.log(dt) # TODO\n",
    "        mu = self.mean(x, dt, speed, level)\n",
    "        sigma = self.std(dt, speed, vola)\n",
    "        var = self.variance(dt, speed, vola)\n",
    "\n",
    "        dist = torch.distributions.normal.Normal(loc=mu, scale=var)\n",
    "        log_pdf = dist.log_prob(x).sum(-1)\n",
    "        # log_scale = torch.log(sigma) / 2\n",
    "        # log_pdf = -((x - mu) ** 2) / (2 * var) - log_scale - torch.log(torch.sqrt(2 * torch.tensor(math.pi,device=device)))\n",
    "\n",
    "        return log_pdf\n",
    "\n",
    "    def simulate_path(self, x0, t, items=None):\n",
    "        \"\"\" \n",
    "        Simulates a sample path or forward based on the parameters (speed, level, vola)\n",
    "        dX = speed*(level-X)dt + vola*dB\n",
    "        ** the num_node here can be considered as multivariate case of OU process \n",
    "            while the correlations between nodes wdo not matter\n",
    "        Args:\n",
    "            x0: [num_seq/bs, num_node] the initial states for each node in each sequences\n",
    "            t: [num_seq/bs, time_step] the time points to sample (or interact);\n",
    "                It should be the same for all nodes\n",
    "            items: \n",
    "        Return: \n",
    "            x_pred: [num_seq/bs, num_node, time_step-1]\n",
    "        \"\"\"\n",
    "        assert len(t) > 0\n",
    "        num_seq, time_step = t.shape\n",
    "        num_node = x0.shape[1]\n",
    "\n",
    "        dt = torch.diff(t).unsqueeze(1) \n",
    "        dt = torch.tile(dt, (1, num_node, 1)) # [bs, num_node, time-1]\n",
    "        # dt = torch.log(dt) # TODO to find the right temperature of time difference in different real-world datasets\n",
    "\n",
    "        scale = self.std(dt) # [bs, num_node, t-1]\n",
    "        noise = torch.randn(size=scale.shape, device=self.device)\n",
    "        \n",
    "        x_last = x0 \n",
    "        x_pred = []\n",
    "        x_pred.append(x_last)\n",
    "        for i in range(1, time_step):\n",
    "            x_next = self.mean(x_last, dt[..., i-1])  # [bs, num_node]\n",
    "            x_next = x_next + noise[..., i-1] * scale[..., i-1]\n",
    "            x_pred.append(x_next)\n",
    "            \n",
    "            x_last = x_next\n",
    "        x_pred = torch.stack(x_pred, -1)\n",
    "        params = None\n",
    "        \n",
    "        return x_pred, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed27e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b725d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a9637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c031dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "import logging\n",
    "import numpy as np\n",
    "from nptyping import NDArray\n",
    "import scipy.optimize as opt\n",
    "\n",
    "class OrnsteinUhlenbeckEstimator:\n",
    "    \"\"\"\n",
    "    Convenience class to evaluate the Ornstein-Uhlenbeck parameters of multiple\n",
    "    sets of series.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the class.\n",
    "        data: List of tuples of (t, x) arrays\n",
    "        kwargs:\n",
    "          n_it: number of iterations to take (default 1)\n",
    "          init_mu: starting parameter for mu (default is mean of data)\n",
    "          init_eta: starting parameter for eta (default is a very rough guess)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        \n",
    "        n_iter = kwargs.pop(\"n_it\", 1)\n",
    "        self.n_iter = n_iter\n",
    "        if n_iter <= 0:\n",
    "            logging.warning(\n",
    "                \"Parameter estimates will not be accurate without at least one iteration.\"\n",
    "            )\n",
    "        # for t, x in data:\n",
    "        #     if t.size != x.shape[0]:\n",
    "        #         raise RuntimeError(\"Time and signal data must have the same length.\")\n",
    "        #     if t.size < 1:\n",
    "        #         raise RuntimeError(\"Not enough data points in a set.\")\n",
    "        \n",
    "        # The effective number is one less than the length because it is the\n",
    "        # adjacent differences that are used.\n",
    "        self.ns = [ts.size - 1 for ts, _ in data]\n",
    "        self.mu = kwargs.pop(\n",
    "            \"init_mu\", sum([np.sum(x) for (_, x) in data]) / sum(self.ns)\n",
    "        )\n",
    "        self.eta = kwargs.pop(\n",
    "            \"init_eta\", np.average([eta_start(*tx) for tx in data], weights=self.ns),\n",
    "        )\n",
    "        self.variance = np.average(\n",
    "            [variance(t, x, self.eta, self.mu) for t, x in self.data], weights=self.ns\n",
    "        )\n",
    "        if kwargs:\n",
    "            logging.error(\"Unrecognized keyword arguments: {kwargs.keys()}\")\n",
    "            raise RuntimeError(\"Unrecognized keyword arguments\")\n",
    "    \n",
    "\n",
    "\n",
    "    def iterate(self, data) -> None:\n",
    "        \"\"\"\n",
    "        Do an iteration on eta then mu, using MLE for eta (at constant mu) then\n",
    "        updating mu exactly.\n",
    "        \"\"\"\n",
    "        n = self.n_iter\n",
    "        \n",
    "        while n > 0:\n",
    "            def func(eta: float) -> float:\n",
    "                return -2.0 * np.sum([likelihood(t, x, eta, self.mu) for t, x in data])\n",
    "\n",
    "            def grad(eta: float) -> float:\n",
    "                return np.array(\n",
    "                    np.sum(\n",
    "                        [-2.0 * deta_likelihood(t, x, eta, self.mu) for t, x in data],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # The bounds should be configurable; in principle eta can be > 1.0\n",
    "            fit = opt.minimize(func, self.eta, jac=grad, bounds=[(0.0, 1.0)])\n",
    "            if not fit.success:\n",
    "                print(\"Error: fit was not successful.\")\n",
    "                raise RuntimeError(fit.message)\n",
    "            self.eta = fit.x\n",
    "            # eta_err = np.sqrt(2.0 * fit.hess_inv * np.eye(1))\n",
    "            # print(f\"eta err = {eta_err}\")\n",
    "            \n",
    "            self.mu = mu_list(data, self.eta)\n",
    "\n",
    "            n -= 1\n",
    "        # The *average* variance (not the point-by-point expected variance)\n",
    "        self.variance = np.average(\n",
    "            [variance(t, x, self.eta, self.mu) for t, x in data], weights=self.ns\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def sigma_sq(self) -> float:\n",
    "        \"\"\"\n",
    "        Return the sigma-squared parameter (the variance per small change in\n",
    "        time) given the current estimates.\n",
    "        \"\"\"\n",
    "        return 2.0 * self.eta * self.variance\n",
    "\n",
    "    def deviations(\n",
    "        self, data=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Returns the weighted deviations at each point.\n",
    "        \"\"\"\n",
    "        the_data = data or self.data\n",
    "        return np.concatenate(\n",
    "            [deviations(t, x, self.eta, self.mu) for t, x in the_data]\n",
    "        )\n",
    "\n",
    "\n",
    "def eta_start(t, x) -> float:\n",
    "    \"\"\"\n",
    "    Returns a guesstimate of eta (totally unverified). This probably only holds\n",
    "    for equally-spaced steps. But it provides a reasonable start value around an\n",
    "    order of magnitude from the real one.\n",
    "    \"\"\"\n",
    "    dt = t[1:] - t[:-1]\n",
    "    dx = x[1:] - x[:-1]\n",
    "    xdx = (x[:-1] * dx).sum()\n",
    "    x2dt = (np.square(x[:-1]) * dt).sum()\n",
    "    eta = -xdx / (x2dt+1e-6) + 1e-6\n",
    "    if eta <= 0.0: eta = 1e-8\n",
    "    # assert eta >= 0.0, \"eta must be positive\"\n",
    "    return eta\n",
    "\n",
    "\n",
    "def likelihood(\n",
    "    t, x, eta: float, mu: float = 0.0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Returns the likelihood where sigma^2 has been replace by its MLE estimator\n",
    "    as a function of eta and mu. It diverges if eta == 0.\n",
    "    - (n/2) * (1 + log D) - (1/2) * sum log [1 - exp(-2*eta*dt)]\n",
    "    \"\"\"\n",
    "    dt = t[1:] - t[:-1]\n",
    "    nm1 = dt.size\n",
    "    dev = variance(t, x, eta, mu)\n",
    "\n",
    "    return (\n",
    "        -0.5 * nm1 * (1.0 + np.log(2.0 * np.pi * dev))\n",
    "        - 0.5 * np.log(-np.expm1(-2.0 * eta * dt)).sum()\n",
    "    )\n",
    "\n",
    "\n",
    "def deta_likelihood(\n",
    "    t, x, eta: float, mu: float = 0.0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    The gradient of the total likelihood with respect to eta.\n",
    "    \"\"\"\n",
    "    dt = t[1:] - t[:-1]\n",
    "    nm1 = dt.size\n",
    "    dev = variance(t, x, eta, mu)\n",
    "    deta_dev = deta_variance(t, x, eta, mu)\n",
    "    exp_2etadt = np.exp(-2 * eta * dt)\n",
    "    expm1_2etadt = np.expm1(-2 * eta * dt)\n",
    "    return -0.5 * nm1 * deta_dev / dev + np.sum(dt * exp_2etadt / expm1_2etadt)\n",
    "\n",
    "\n",
    "def opt_eta(t, x, mu: float = 0.0) -> float:\n",
    "    \"\"\"\n",
    "    Return the eta parameter estimated by maximum likelihood.\n",
    "    \"\"\"\n",
    "    eta_init = np.array([eta_start(t, x)])\n",
    "\n",
    "    def func(eta: float) -> float:\n",
    "        return -2.0 * likelihood(t, x, eta, mu)\n",
    "\n",
    "    def grad(eta: float) -> float:\n",
    "        return np.array([-2.0 * deta_likelihood(t, x, eta, mu)])\n",
    "\n",
    "    fit = opt.minimize(func, eta_init, jac=grad, bounds=[(0.0, 1.0)])\n",
    "    if not fit.success:\n",
    "        print(\"Error: fit was not successful. {fit.message}\")\n",
    "    # eta_err = np.sqrt(2.0 * fit.hess_inv * np.eye(1))\n",
    "    # print(f\"eta err = {eta_err}\")\n",
    "    return fit.x\n",
    "\n",
    "\n",
    "def deviations(\n",
    "    t, x, eta: float, mu: float = 0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns the appropriately-weighted unsigned deviations i.e. the difference\n",
    "    from predicted divided by the standard deviation.\n",
    "    \"\"\"\n",
    "    # the time (or position) steps\n",
    "    dt = t[1:] - t[:-1]\n",
    "    # the next and previous values offset by the mean\n",
    "    xn = x[1:] - mu\n",
    "    xp = x[:-1] - mu\n",
    "\n",
    "    # right now returning the signed version\n",
    "    return xn - xp * np.exp(-eta * dt) / np.sqrt(-np.expm1(-2.0 * eta * dt))\n",
    "\n",
    "\n",
    "def variance(\n",
    "    t, x, eta: float, mu: float = 0.0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Returns an analogue of the weighted average of squares.\n",
    "    D = (1/(n-1)) * sum { [(x_t - mu) - (x_{t-1} - mu)*exp(-eta*dt)] / (1 - exp(-2*eta*dt)) }\n",
    "    This is the variance of the stable distribution.\n",
    "    \"\"\"\n",
    "    # the time (or position) steps\n",
    "    dt = t[1:] - t[:-1]\n",
    "    # the next and previous values offset by the mean\n",
    "    xn = x[1:] - mu\n",
    "    xp = x[:-1] - mu\n",
    "\n",
    "    return np.mean(\n",
    "        np.square(xn - xp * np.exp(-eta * dt)) / (-np.expm1(-2.0 * eta * dt))\n",
    "    )\n",
    "\n",
    "\n",
    "def deta_variance(\n",
    "    t, x, eta: float, mu: float = 0.0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Returns the derivative of the `variance` function with respect to eta.\n",
    "    WARNING: there seem to be numerical issues at small eta, and eta will be small.\n",
    "    \"\"\"\n",
    "    dt = t[1:] - t[:-1]\n",
    "    xn = x[1:] - mu\n",
    "    xp = x[:-1] - mu\n",
    "    exp_etadt = np.exp(-eta * dt)\n",
    "    expm1_2etadt = np.expm1(-2.0 * eta * dt)\n",
    "\n",
    "    terms = (\n",
    "        2.0\n",
    "        * dt\n",
    "        * exp_etadt\n",
    "        * (xn - xp * exp_etadt)\n",
    "        * (xp - xn * exp_etadt)\n",
    "        / np.square(expm1_2etadt)\n",
    "    )\n",
    "    return terms.mean()\n",
    "\n",
    "\n",
    "def mu(t, x, eta: float) -> float:\n",
    "    \"\"\"\n",
    "    Returns the appropriately weighted mu given eta.\n",
    "    \"\"\"\n",
    "    num, den = _mu_one(t, x, eta)\n",
    "    return num / den\n",
    "\n",
    "\n",
    "def mu_list(data, eta) -> float:\n",
    "    \"\"\"\n",
    "    Returns the mu for a collection of samplings, properly weighting all together.\n",
    "    \"\"\"\n",
    "    nums, dens = zip(*[_mu_one(t, x, eta) for t, x in data])\n",
    "    return np.sum(nums) / np.sum(dens) + 1\n",
    "\n",
    "\n",
    "def _mu_one(t, x, eta: float) -> float:\n",
    "    \"\"\"\n",
    "    Returns the numerator and denominator of an appropriately weighted mu given\n",
    "    eta for a single t, x set\n",
    "    \"\"\"\n",
    "    dt = t[1:] - t[:-1]\n",
    "    xn, xp = x[1:], x[:-1]\n",
    "    exp_etadt = np.exp(-eta * dt)\n",
    "    expm1_etadt = np.expm1(-eta * dt)\n",
    "\n",
    "    num = (xn - xp * exp_etadt) / (1.0 + exp_etadt)\n",
    "    den = -expm1_etadt / (1.0 + exp_etadt)\n",
    "    return num.sum(), den.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03db6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83dab08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731c529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284b632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917066d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b315625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b36a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b130eef1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcd5f2e2280>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import imageio\n",
    "import ipdb\n",
    "\n",
    "\n",
    "\n",
    "path = x[0,:,0,0].numpy()\n",
    "times=time[0].numpy()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "color = cm.rainbow(np.linspace(0, 1, num_node))\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.xlabel('time t')\n",
    "plt.ylabel('recall_probability')\n",
    "plt.title(label='OU Model',\n",
    "        fontsize=20,\n",
    "        color=\"black\")\n",
    "\n",
    "plt.plot(scale, sigmoid(path), color=c, label='{}'.format(i), linewidth=4)\n",
    "\n",
    "plt.scatter(scale, x_data[1:], s=150, marker='*')\n",
    "    # plt.vlines(x=times[ind], ymin = np.min(path), ymax = np.max(path),\n",
    "            # colors = 'grey', linestyles='dashdot')# ,\n",
    "            # label = 'vline_multiple - full height')\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7448358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227b5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcdd836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d11fd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq, time_step = t.shape\n",
    "num_node = len(x0)\n",
    "\n",
    "dt = torch.diff(t).reshape(num_seq, -1, 1, 1)\n",
    "dt = torch.tile(dt, (1,1,num_node,1))\n",
    "dt = torch.log(dt)\n",
    "\n",
    "# x = torch.zeros((self.num_seq, time_step, num_node, 1), device=device)\n",
    "# x[:, 0] += x0\n",
    "\n",
    "noise = torch.randn(size=(num_seq, time_step, num_node, 1), device=device) \n",
    "scale = std(dt) # [bs, t-1, num_node, 1]\n",
    "# x[:, 1:] += noise[:, 1:] * scale\n",
    "x_last = x0\n",
    "\n",
    "x_pred = []\n",
    "for i in range(1, test_time):\n",
    "    # x[:, i] = self.mean(x[:, i-1], dt[:, i-1])\n",
    "    x_next = mean(x_last, dt[:, i-1]) + noise[:, i-1]\n",
    "    x_last = x_next\n",
    "    x_pred.append(x_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200e133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb5f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917276b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088bec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe6192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c9c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f5cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503dda7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adca0e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abffdc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5c3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73f911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343fb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31c53a36",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d5ad0e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>exercise</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>16</td>\n",
       "      <td>adding_and_subtracting_negative_numbers</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>52</td>\n",
       "      <td>alternate_exterior_angles</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>52</td>\n",
       "      <td>alternate_interior_angles</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>52</td>\n",
       "      <td>metric_weight_unit_conversion</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>64</td>\n",
       "      <td>reading_fractions_in_chinese</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288785</th>\n",
       "      <td>247492</td>\n",
       "      <td>multiplication_0.5</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288786</th>\n",
       "      <td>247492</td>\n",
       "      <td>multiplication_1</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288888</th>\n",
       "      <td>247507</td>\n",
       "      <td>subtraction_1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289046</th>\n",
       "      <td>247529</td>\n",
       "      <td>addition_1</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289368</th>\n",
       "      <td>247569</td>\n",
       "      <td>divisibility_0.5</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id                                 exercise  count\n",
       "98            16  adding_and_subtracting_negative_numbers    118\n",
       "387           52                alternate_exterior_angles    119\n",
       "388           52                alternate_interior_angles    101\n",
       "492           52            metric_weight_unit_conversion    136\n",
       "654           64             reading_fractions_in_chinese    148\n",
       "...          ...                                      ...    ...\n",
       "2288785   247492                       multiplication_0.5    741\n",
       "2288786   247492                         multiplication_1    266\n",
       "2288888   247507                            subtraction_1    113\n",
       "2289046   247529                               addition_1    119\n",
       "2289368   247569                         divisibility_0.5    201\n",
       "\n",
       "[15060 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "624f564d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14124295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24336948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf69154d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e2a8432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0e9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa5ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97903d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454bbd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af561a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e15c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e325425",
   "metadata": {},
   "source": [
    "# HLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "97e787c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc12847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7c689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc626e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39ef40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba48dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5872dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e33b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a141b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f8a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c4b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a2b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc09c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb205be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf3fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d5bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f1172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba31f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0aba28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e65b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "f99d5b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69ce26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27bc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2eecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23344605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfb0c25",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>exercise</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1144894</th>\n",
       "      <td>123793</td>\n",
       "      <td>writing_fractions_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993027</th>\n",
       "      <td>107307</td>\n",
       "      <td>rounding_numbers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993028</th>\n",
       "      <td>107307</td>\n",
       "      <td>same_side_interior_angles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993039</th>\n",
       "      <td>107307</td>\n",
       "      <td>the_fundamental_theorem_of_arithmetic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993043</th>\n",
       "      <td>107307</td>\n",
       "      <td>understanding_comparing_angle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009433</th>\n",
       "      <td>217320</td>\n",
       "      <td>sides_and_angles_of_simple_shapes</td>\n",
       "      <td>3035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537355</th>\n",
       "      <td>58228</td>\n",
       "      <td>sides_and_angles_of_simple_shapes</td>\n",
       "      <td>3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486600</th>\n",
       "      <td>52504</td>\n",
       "      <td>radical_equations</td>\n",
       "      <td>3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819423</th>\n",
       "      <td>88703</td>\n",
       "      <td>time_units_transformation_1</td>\n",
       "      <td>3297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819421</th>\n",
       "      <td>88703</td>\n",
       "      <td>telling_time_comparing</td>\n",
       "      <td>5174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2289789 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id                               exercise  count\n",
       "1144894   123793                    writing_fractions_1      1\n",
       "993027    107307                       rounding_numbers      1\n",
       "993028    107307              same_side_interior_angles      1\n",
       "993039    107307  the_fundamental_theorem_of_arithmetic      1\n",
       "993043    107307          understanding_comparing_angle      1\n",
       "...          ...                                    ...    ...\n",
       "2009433   217320      sides_and_angles_of_simple_shapes   3035\n",
       "537355     58228      sides_and_angles_of_simple_shapes   3127\n",
       "486600     52504                      radical_equations   3128\n",
       "819423     88703            time_units_transformation_1   3297\n",
       "819421     88703                 telling_time_comparing   5174\n",
       "\n",
       "[2289789 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c979094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0361c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec60ba90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb1da46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_path = '/mnt/qb/work/mlcolab/hzhou52/kt/Duolingo/learning_traces.csv'\n",
    "log = pd.read_csv(bath_path, encoding = \"utf-8\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ceb4b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>76390c1350a8dac31186187e2fe1e178</td>\n",
       "      <td>lernt/lernen&lt;vblex&gt;&lt;pri&gt;&lt;p3&gt;&lt;sg&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>7dfd7086f3671685e2cf1c1da72796d7</td>\n",
       "      <td>die/die&lt;det&gt;&lt;def&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>35a54c25a2cda8127343f6a82e6f6b7d</td>\n",
       "      <td>mann/mann&lt;n&gt;&lt;m&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>0cf63ffe3dda158bc3dbd55682b355ae</td>\n",
       "      <td>frau/frau&lt;n&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>84920990d78044db53c1b012f5bf9ab5</td>\n",
       "      <td>das/das&lt;det&gt;&lt;def&gt;&lt;nt&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_recall   timestamp     delta user_id learning_language ui_language  \\\n",
       "0       1.0  1362076081  27649635    u:FO                de          en   \n",
       "1       0.5  1362076081  27649635    u:FO                de          en   \n",
       "2       1.0  1362076081  27649635    u:FO                de          en   \n",
       "3       0.5  1362076081  27649635    u:FO                de          en   \n",
       "4       1.0  1362076081  27649635    u:FO                de          en   \n",
       "\n",
       "                          lexeme_id                     lexeme_string  \\\n",
       "0  76390c1350a8dac31186187e2fe1e178  lernt/lernen<vblex><pri><p3><sg>   \n",
       "1  7dfd7086f3671685e2cf1c1da72796d7     die/die<det><def><f><sg><nom>   \n",
       "2  35a54c25a2cda8127343f6a82e6f6b7d          mann/mann<n><m><sg><nom>   \n",
       "3  0cf63ffe3dda158bc3dbd55682b355ae          frau/frau<n><f><sg><nom>   \n",
       "4  84920990d78044db53c1b012f5bf9ab5    das/das<det><def><nt><sg><nom>   \n",
       "\n",
       "   history_seen  history_correct  session_seen  session_correct  \n",
       "0             6                4             2                2  \n",
       "1             4                4             2                1  \n",
       "2             5                4             1                1  \n",
       "3             6                5             2                1  \n",
       "4             4                4             1                1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8905ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u:--N</td>\n",
       "      <td>01a14ea3963721a9d545dce1acc30f2f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544992</th>\n",
       "      <td>u:hqtH</td>\n",
       "      <td>eb94d71d2ab1d501b230eee9d287fe73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544993</th>\n",
       "      <td>u:hqtH</td>\n",
       "      <td>ec2421cd46a8a5886683b084aa8e2c5d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544994</th>\n",
       "      <td>u:hqtH</td>\n",
       "      <td>ede6ab035e42c5f5523c73f955f036ac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544995</th>\n",
       "      <td>u:hqtH</td>\n",
       "      <td>eee8e3c0843d6ace41d204202f197909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269756</th>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>97e922f780d628eac638bea7a02bf496</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269685</th>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>827a8ecb89f9b59ac5c29b620a5d3ed6</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269409</th>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>33a7fd42f74b2d2b1110f1b0c8b6db38</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269600</th>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>6d4c572af8022cb4784ce0f8898d1905</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269333</th>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>1e1f8d730c4ba99ad2873a7608324cf6</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5861629 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                         lexeme_id  count\n",
       "0         u:--N  01a14ea3963721a9d545dce1acc30f2f      1\n",
       "3544992  u:hqtH  eb94d71d2ab1d501b230eee9d287fe73      1\n",
       "3544993  u:hqtH  ec2421cd46a8a5886683b084aa8e2c5d      1\n",
       "3544994  u:hqtH  ede6ab035e42c5f5523c73f955f036ac      1\n",
       "3544995  u:hqtH  eee8e3c0843d6ace41d204202f197909      1\n",
       "...         ...                               ...    ...\n",
       "269756   u:bcH_  97e922f780d628eac638bea7a02bf496    278\n",
       "269685   u:bcH_  827a8ecb89f9b59ac5c29b620a5d3ed6    295\n",
       "269409   u:bcH_  33a7fd42f74b2d2b1110f1b0c8b6db38    316\n",
       "269600   u:bcH_  6d4c572af8022cb4784ce0f8898d1905    328\n",
       "269333   u:bcH_  1e1f8d730c4ba99ad2873a7608324cf6    352\n",
       "\n",
       "[5861629 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = log.groupby(['user_id', 'lexeme_id']).size().reset_index(name='count')\n",
    "users.sort_values('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5ef72ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193803</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1362092353</td>\n",
       "      <td>61015</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>55f383178cf0fdc463ef1ebf91bd288d</td>\n",
       "      <td>milk/milk&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>157</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193804</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1362092353</td>\n",
       "      <td>83142</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>a5acd980d17d726d1c99e7b974d3f52d</td>\n",
       "      <td>for/for&lt;pr&gt;</td>\n",
       "      <td>750</td>\n",
       "      <td>481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193805</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1362092353</td>\n",
       "      <td>83951</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>9eedd98a29691237d18c127468452836</td>\n",
       "      <td>music/music&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>181</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193806</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1362092353</td>\n",
       "      <td>61191</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>4adf5cd40d521b02a9cc241bf3adc6bb</td>\n",
       "      <td>have/have&lt;vblex&gt;&lt;inf&gt;</td>\n",
       "      <td>913</td>\n",
       "      <td>583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193807</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1362092353</td>\n",
       "      <td>83951</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>b830ca5fa936b0cff94fe712d6847f29</td>\n",
       "      <td>listen/listen&lt;vblex&gt;&lt;pres&gt;</td>\n",
       "      <td>93</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504242</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1363066201</td>\n",
       "      <td>2678082</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>6e7589c6b19e910e6f24f8313ab231b9</td>\n",
       "      <td>these/this&lt;prn&gt;&lt;tn&gt;&lt;mf&gt;&lt;pl&gt;</td>\n",
       "      <td>43</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504243</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1363066201</td>\n",
       "      <td>144</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>32d10b7ed0bea958c60a915710434dfe</td>\n",
       "      <td>can/can&lt;vaux&gt;&lt;pres&gt;</td>\n",
       "      <td>1166</td>\n",
       "      <td>899</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504244</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1363066201</td>\n",
       "      <td>454</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>46a16bfbe06339264594d523fb04bf7a</td>\n",
       "      <td>restaurant/restaurant&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>470</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504245</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1363066201</td>\n",
       "      <td>144</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>1e1f8d730c4ba99ad2873a7608324cf6</td>\n",
       "      <td>my/my&lt;det&gt;&lt;pos&gt;&lt;sp&gt;</td>\n",
       "      <td>5589</td>\n",
       "      <td>3230</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504246</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1363066201</td>\n",
       "      <td>454</td>\n",
       "      <td>u:bcH_</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>b974624f112084b39586380fe4aaf32a</td>\n",
       "      <td>man/man&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>361</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19194 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          p_recall   timestamp    delta user_id learning_language ui_language  \\\n",
       "193803         0.0  1362092353    61015  u:bcH_                en          es   \n",
       "193804         1.0  1362092353    83142  u:bcH_                en          es   \n",
       "193805         0.0  1362092353    83951  u:bcH_                en          es   \n",
       "193806         0.0  1362092353    61191  u:bcH_                en          es   \n",
       "193807         0.0  1362092353    83951  u:bcH_                en          es   \n",
       "...            ...         ...      ...     ...               ...         ...   \n",
       "12504242       1.0  1363066201  2678082  u:bcH_                en          es   \n",
       "12504243       1.0  1363066201      144  u:bcH_                en          es   \n",
       "12504244       0.0  1363066201      454  u:bcH_                en          es   \n",
       "12504245       0.5  1363066201      144  u:bcH_                en          es   \n",
       "12504246       0.0  1363066201      454  u:bcH_                en          es   \n",
       "\n",
       "                                 lexeme_id                 lexeme_string  \\\n",
       "193803    55f383178cf0fdc463ef1ebf91bd288d              milk/milk<n><sg>   \n",
       "193804    a5acd980d17d726d1c99e7b974d3f52d                   for/for<pr>   \n",
       "193805    9eedd98a29691237d18c127468452836            music/music<n><sg>   \n",
       "193806    4adf5cd40d521b02a9cc241bf3adc6bb         have/have<vblex><inf>   \n",
       "193807    b830ca5fa936b0cff94fe712d6847f29    listen/listen<vblex><pres>   \n",
       "...                                    ...                           ...   \n",
       "12504242  6e7589c6b19e910e6f24f8313ab231b9   these/this<prn><tn><mf><pl>   \n",
       "12504243  32d10b7ed0bea958c60a915710434dfe           can/can<vaux><pres>   \n",
       "12504244  46a16bfbe06339264594d523fb04bf7a  restaurant/restaurant<n><sg>   \n",
       "12504245  1e1f8d730c4ba99ad2873a7608324cf6           my/my<det><pos><sp>   \n",
       "12504246  b974624f112084b39586380fe4aaf32a                man/man<n><sg>   \n",
       "\n",
       "          history_seen  history_correct  session_seen  session_correct  \n",
       "193803             157              116             1                0  \n",
       "193804             750              481             1                1  \n",
       "193805             181              110             1                0  \n",
       "193806             913              583             1                0  \n",
       "193807              93               58             1                0  \n",
       "...                ...              ...           ...              ...  \n",
       "12504242            43               33             1                1  \n",
       "12504243          1166              899             1                1  \n",
       "12504244           470              241             1                0  \n",
       "12504245          5589             3230             2                1  \n",
       "12504246           361              258             1                0  \n",
       "\n",
       "[19194 rows x 12 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.loc[log.user_id == 'u:bcH_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a8f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
